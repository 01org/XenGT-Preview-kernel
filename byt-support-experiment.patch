diff --git a/drivers/gpu/drm/i915/i915_gem_execbuffer.c b/drivers/gpu/drm/i915/i915_gem_execbuffer.c
index 415b503..706a20c 100644
--- a/drivers/gpu/drm/i915/i915_gem_execbuffer.c
+++ b/drivers/gpu/drm/i915/i915_gem_execbuffer.c
@@ -1098,6 +1098,10 @@ i915_gem_do_execbuffer(struct drm_device *dev, void *data,
 
 	exec_start = batch_obj->gtt_offset + args->batch_start_offset;
 	exec_len = args->batch_len;
+	if(IS_VALLEYVIEW(dev) && (dev_priv->in_xen_vgt == true)) {
+		drm_clflush_sg(batch_obj->pages);
+	}
+
 	if (cliprects) {
 		for (i = 0; i < args->num_cliprects; i++) {
 			ret = i915_emit_box(dev, &cliprects[i],
diff --git a/drivers/gpu/drm/i915/i915_gem_gtt.c b/drivers/gpu/drm/i915/i915_gem_gtt.c
index 09d7454..b182f1f 100644
--- a/drivers/gpu/drm/i915/i915_gem_gtt.c
+++ b/drivers/gpu/drm/i915/i915_gem_gtt.c
@@ -292,6 +292,7 @@ static gen6_gtt_pte_t byt_pte_encode(struct drm_device *dev,
 				     dma_addr_t addr,
 				     enum i915_cache_level level)
 {
+	struct drm_i915_private *dev_priv = dev->dev_private;
 	gen6_gtt_pte_t pte = GEN6_PTE_VALID;
 	pte |= GEN6_PTE_ADDR_ENCODE(addr);
 
@@ -302,7 +303,9 @@ static gen6_gtt_pte_t byt_pte_encode(struct drm_device *dev,
 
 	if (level != I915_CACHE_NONE)
 		pte |= BYT_PTE_SNOOPED_BY_CPU_CACHES;
-
+	if(IS_VALLEYVIEW(dev) && (dev_priv->in_xen_vgt == true)) {
+		pte |= BYT_PTE_SNOOPED_BY_CPU_CACHES;
+	}
 	return pte;
 }
 
@@ -1063,6 +1066,10 @@ static int gen6_gmch_probe(struct drm_device *dev,
 	gtt_size = gen6_get_total_gtt_size(snb_gmch_ctl);
 
 	*stolen = gen6_get_stolen_size(snb_gmch_ctl);
+	if(IS_VALLEYVIEW(dev) && (dev_priv->in_xen_vgt == true)) {
+		*stolen = 0;
+	}
+
 	*gtt_total = (gtt_size / sizeof(gen6_gtt_pte_t)) << PAGE_SHIFT;
 
 	/* For Modern GENs the PTEs and register space are split in the BAR */
diff --git a/drivers/gpu/drm/i915/i915_gem_stolen.c b/drivers/gpu/drm/i915/i915_gem_stolen.c
index 982d473..592a294 100644
--- a/drivers/gpu/drm/i915/i915_gem_stolen.c
+++ b/drivers/gpu/drm/i915/i915_gem_stolen.c
@@ -266,7 +266,12 @@ _i915_gem_object_create_stolen(struct drm_device *dev,
 			       struct drm_mm_node *stolen)
 {
 	struct drm_i915_gem_object *obj;
+	struct drm_i915_private *dev_priv = dev->dev_private;
 
+	if(IS_VALLEYVIEW(dev) && (dev_priv->in_xen_vgt == true)) {
+		DRM_DEBUG("VGT in XenGT cannot use stolen memory - stolen disabled\n");
+		return NULL;
+	}
 	obj = i915_gem_object_alloc(dev);
 	if (obj == NULL)
 		return NULL;
diff --git a/drivers/gpu/drm/i915/i915_irq.c b/drivers/gpu/drm/i915/i915_irq.c
index 3933295..0f2cad5 100644
--- a/drivers/gpu/drm/i915/i915_irq.c
+++ b/drivers/gpu/drm/i915/i915_irq.c
@@ -426,6 +426,9 @@ static u32 gm45_get_vblank_counter(struct drm_device *dev, int pipe)
 {
 	drm_i915_private_t *dev_priv = (drm_i915_private_t *) dev->dev_private;
 	int reg = PIPE_FRMCOUNT_GM45(pipe);
+	
+	if(IS_VALLEYVIEW(dev))
+		reg = PIPEFRAME(pipe);
 
 	if (!i915_pipe_enabled(dev, pipe)) {
 		DRM_DEBUG_DRIVER("trying to get vblank count for disabled "
@@ -975,6 +978,11 @@ static irqreturn_t valleyview_irq_handler(int irq, void *arg)
 	int pipe;
 	u32 pipe_stats[I915_MAX_PIPES];
 
+#ifdef DRM_I915_VGT_SUPPORT
+        if (dev_priv->in_xen_vgt && vgt_check_busy(VGT_DELAY_IRQ))
+                return IRQ_HANDLED;
+#endif
+
 	atomic_inc(&dev_priv->irq_received);
 
 	while (true) {
@@ -2727,6 +2735,14 @@ static void valleyview_irq_preinstall(struct drm_device *dev)
 	I915_WRITE(VLV_IMR, 0xffffffff);
 	I915_WRITE(VLV_IER, 0x0);
 	POSTING_READ(VLV_IER);
+
+#ifdef DRM_I915_VGT_SUPPORT
+        /* a hacky hook to vGT driver */
+        printk("vGT: setup vGT irq hook in %s\n", __FUNCTION__);
+        if (dev_priv->in_xen_vgt)
+                vgt_install_irq(dev->pdev);
+#endif
+
 }
 
 static void ibx_hpd_irq_setup(struct drm_device *dev)
diff --git a/drivers/gpu/drm/i915/intel_crt.c b/drivers/gpu/drm/i915/intel_crt.c
index 3acec8c..3ed9bca 100644
--- a/drivers/gpu/drm/i915/intel_crt.c
+++ b/drivers/gpu/drm/i915/intel_crt.c
@@ -354,7 +354,7 @@ static bool valleyview_crt_detect_hotplug(struct drm_connector *connector)
 	DRM_DEBUG_KMS("valleyview hotplug adpa=0x%x, result %d\n", adpa, ret);
 
 	/* FIXME: debug force function and remove */
-	ret = true;
+	/*ret = true; This is a hack to always detect CRT - should be disabled by default */
 
 	return ret;
 }
diff --git a/drivers/gpu/drm/i915/intel_display.c b/drivers/gpu/drm/i915/intel_display.c
index 5cdda81..82a2923 100644
--- a/drivers/gpu/drm/i915/intel_display.c
+++ b/drivers/gpu/drm/i915/intel_display.c
@@ -7209,6 +7209,9 @@ void intel_prepare_page_flip(struct drm_device *dev, int plane)
 		to_intel_crtc(dev_priv->plane_to_crtc_mapping[plane]);
 	unsigned long flags;
 
+	if(!intel_crtc)
+		return;
+
 	/* NB: An MMIO update of the plane base pointer will also
 	 * generate a page-flip completion irq, i.e. every modeset
 	 * is also accompanied by a spurious intel_prepare_page_flip().
diff --git a/drivers/gpu/drm/i915/intel_pm.c b/drivers/gpu/drm/i915/intel_pm.c
index cad0482..24da46c 100644
--- a/drivers/gpu/drm/i915/intel_pm.c
+++ b/drivers/gpu/drm/i915/intel_pm.c
@@ -3498,6 +3498,14 @@ static void valleyview_setup_pctx(struct drm_device *dev)
 	pctx = i915_gem_object_create_stolen(dev, pctx_size);
 	if (!pctx) {
 		DRM_DEBUG("not enough stolen space for PCTX, disabling\n");
+		if((dev_priv->in_xen_vgt == true)) {
+			/* For Xen-VGT, we CANNOT seem to access stolen memory in Baytrail,
+			 * but the HW requires stolen memory location for the power context,
+			 * so lets hard-code this to a specific location for now - use 2MB 
+			 */
+			pctx_paddr = dev_priv->mm.stolen_base + (2*1024*1024);
+			I915_WRITE(VLV_PCBR, pctx_paddr);
+		}
 		return;
 	}
 
diff --git a/drivers/xen/vgt/cfg_space.c b/drivers/xen/vgt/cfg_space.c
index 5b33265..5aabbf7 100644
--- a/drivers/xen/vgt/cfg_space.c
+++ b/drivers/xen/vgt/cfg_space.c
@@ -39,7 +39,7 @@ typedef union _SCI_REG_DATA{
 static bool vgt_cfg_sci_read(struct vgt_device *vgt, unsigned int offset,
 	void *p_data, int bytes)
 {
-	printk("VM%d Read SCI Trigger Register, bytes=%d value=0x%x\n", vgt->vm_id, bytes, *(uint16_t*)p_data);
+	vgt_dbg(VGT_DBG_CFGSPACE, "VM%d Read SCI Trigger Register, bytes=%d value=0x%x\n", vgt->vm_id, bytes, *(uint16_t*)p_data);
 
 	return true;
 }
@@ -49,19 +49,19 @@ static bool vgt_cfg_sci_write(struct vgt_device *vgt, unsigned int offset,
 {
 	SCI_REG_DATA sci_reg;
 
-	printk("VM%d Write SCI Trigger Register, bytes=%d value=0x%x\n", vgt->vm_id, bytes, *(uint32_t*)p_data);
+	vgt_dbg(VGT_DBG_CFGSPACE, "VM%d Write SCI Trigger Register, bytes=%d value=0x%x\n", vgt->vm_id, bytes, *(uint32_t*)p_data);
 
 	if( (bytes == 2) || (bytes == 4)){
 		memcpy (&vgt->state.cfg_space[offset], p_data, bytes);
 	} else {
-		printk("Warning: VM%d vgt_cfg_sci_write invalid bytes=%d, ignore it\n", vgt->vm_id, bytes);
+		vgt_dbg(VGT_DBG_CFGSPACE, "Warning: VM%d vgt_cfg_sci_write invalid bytes=%d, ignore it\n", vgt->vm_id, bytes);
 		return false;
 	}
 
 	sci_reg.data = *(uint16_t*)(vgt->state.cfg_space + offset);
 	sci_reg.method = 1; /* set method to SCI */
 	if (sci_reg.trigger == 1){
-		printk("SW SCI Triggered by VM%d\n", vgt->vm_id);
+		vgt_dbg(VGT_DBG_CFGSPACE, "SW SCI Triggered by VM%d\n", vgt->vm_id);
 		/* TODO: add SCI emulation */
 		sci_reg.trigger = 0; /* SCI completion indicator */
 	}
@@ -87,6 +87,7 @@ static bool vgt_cfg_sci_write(struct vgt_device *vgt, unsigned int offset,
 		__ret;							\
 	})
 
+#ifndef NO_DEBUGS
 static const char *vgt_opregion_func_name(uint32_t func)
 {
 	const char *name = NULL;
@@ -156,6 +157,7 @@ static const char *vgt_opregion_subfunc_name(uint32_t subfunc)
 	}
 	return name;
 };
+#endif
 
 /* Only allowing capability queries */
 static bool vgt_opregion_is_capability_get(uint32_t scic)
@@ -276,7 +278,7 @@ bool vgt_emulate_cfg_write(struct vgt_device *vgt, unsigned int off,
 					vgt_hvm_set_trap_area(vgt);
 				}
 			} else {
-				vgt_dbg(VGT_DBG_GENERIC, "need to trap the PIO BAR? "
+				vgt_dbg(VGT_DBG_CFGSPACE, "need to trap the PIO BAR? "
 					"old_cmd=0x%x, cmd_changed=%0x",
 					old_cmd, cmd_changed);
 			}
@@ -287,7 +289,7 @@ bool vgt_emulate_cfg_write(struct vgt_device *vgt, unsigned int off,
 			ASSERT((bytes == 4) && (off & 3) == 0);
 
 			new = *(uint32_t *)p_data;
-			printk("Programming bar 0x%x with 0x%x\n", off, new);
+			vgt_dbg(VGT_DBG_CFGSPACE, "Programming bar 0x%x with 0x%x\n", off, new);
 			size = vgt->state.bar_size[(off - VGT_REG_CFG_SPACE_BAR0)/8];
 			if (new == 0xFFFFFFFF) {
 				/*
@@ -313,7 +315,7 @@ bool vgt_emulate_cfg_write(struct vgt_device *vgt, unsigned int off,
 			break;
 
 		case VGT_REG_CFG_SPACE_MSAC:
-			printk("Guest write MSAC %x, %d: Not supported yet\n",
+			vgt_dbg(VGT_DBG_CFGSPACE, "Guest write MSAC %x, %d: Not supported yet\n",
 					*(char *)p_data, bytes);
 			break;
 
@@ -351,7 +353,7 @@ bool vgt_emulate_cfg_write(struct vgt_device *vgt, unsigned int off,
 		case 0x90:
 		case 0x94:
 		case 0x98:
-			printk("vGT: write to MSI capa(%x) with val (%x)\n", off, *(uint32_t *)p_data);
+			vgt_dbg(VGT_DBG_CFGSPACE, "vGT: write to MSI capa(%x) with val (%x)\n", off, *(uint32_t *)p_data);
 		default:
 			memcpy (&vgt->state.cfg_space[off], p_data, bytes);
 			break;
@@ -367,7 +369,7 @@ bool vgt_emulate_cfg_write(struct vgt_device *vgt, unsigned int off,
 bool vgt_hvm_write_cf8_cfc(struct vgt_device *vgt,
 	unsigned int port, unsigned int bytes, unsigned long val)
 {
-	vgt_dbg(VGT_DBG_GENERIC, "vgt_hvm_write_cf8_cfc %x %d %lx\n", port, bytes, val);
+	vgt_dbg(VGT_DBG_CFGSPACE, "vgt_hvm_write_cf8_cfc %x %d %lx\n", port, bytes, val);
 	if ( (port & ~3) == 0xcf8 ) {
 		ASSERT (bytes == 4);
 		ASSERT ((port & 3) == 0);
@@ -400,7 +402,7 @@ bool vgt_hvm_read_cf8_cfc(struct vgt_device *vgt,
 					&data, bytes);
 		memcpy(val, &data, bytes);
 	}
-	vgt_dbg(VGT_DBG_GENERIC, "VGT: vgt_cfg_read_emul port %x bytes %x got %lx\n",
+	vgt_dbg(VGT_DBG_CFGSPACE, "VGT: vgt_cfg_read_emul port %x bytes %x got %lx\n",
 			port, bytes, *val);
 	return true;
 }
diff --git a/drivers/xen/vgt/cmd_parser.c b/drivers/xen/vgt/cmd_parser.c
index b62facc..656cc9c 100644
--- a/drivers/xen/vgt/cmd_parser.c
+++ b/drivers/xen/vgt/cmd_parser.c
@@ -462,12 +462,16 @@ uint32_t vgt_get_opcode(uint32_t cmd, int ring_id)
 {
 	struct decode_info * d_info;
 
-	if (ring_id >= MAX_ENGINES)
+	if (ring_id >= MAX_ENGINES) {
+		vgt_dbg(VGT_DBG_CMD, "vgt_get_opcode: r=%d !\n", ring_id);
 		return INVALID_OP;
+	}
 
 	d_info = ring_decode_info[ring_id][CMD_TYPE(cmd)];
-	if (d_info == NULL)
+	if (d_info == NULL) {
+		vgt_dbg(VGT_DBG_CMD, "vgt_get_opcode: r=%d CMD_TYPE=0x%x !\n", ring_id, CMD_TYPE(cmd));
 		return INVALID_OP;
+	}
 
 	return cmd >> (32 - d_info->op_len);
 }
@@ -489,9 +493,9 @@ static void vgt_print_opcode(uint32_t cmd, int ring_id)
 	if (d_info == NULL)
 		return;
 
-	vgt_err("opcode=0x%x %s sub_ops:", cmd >> (32 - d_info->op_len), d_info->name);
+	vgt_err("opcode=0x%x %s sub_ops: (%d)", cmd >> (32 - d_info->op_len), d_info->name,  d_info->nr_sub_op);
 	for (i=0; i< d_info->nr_sub_op; i++){
-		vgt_err("0x%x ", sub_op_val(cmd, d_info->sub_op[i].hi,  d_info->sub_op[i].low));
+		vgt_err("%d: 0x%x\n", i, sub_op_val(cmd, d_info->sub_op[i].hi,  d_info->sub_op[i].low));
 	}
 	vgt_err("\n");
 }
@@ -527,9 +531,9 @@ static void parser_exec_state_dump(struct parser_exec_state *s)
 			" ring_head(%08lx) ring_tail(%08lx)\n", s->vgt->vgt_id,
 			s->ring_id, s->ring_start, s->ring_start + s->ring_size, s->ring_head, s->ring_tail);
 
-	vgt_err("  %s %s ip_gma(%08lx) ",
+	vgt_err("  %s %s ip_gma(%08lx) ip_va=%p\n",
 			s->buf_type == RING_BUFFER_INSTRUCTION ? "RING_BUFFER": "BATCH_BUFFER",
-			s->buf_addr_type == GTT_BUFFER ? "GTT" : "PPGTT", s->ip_gma);
+			s->buf_addr_type == GTT_BUFFER ? "GTT" : "PPGTT", s->ip_gma, s->ip_va);
 
 	if (s->ip_va == NULL){
 		vgt_err(" ip_va(NULL)\n");
@@ -555,8 +559,12 @@ static int ip_gma_set(struct parser_exec_state *s, unsigned long ip_gma)
 	}
 
 	s->ip_gma = ip_gma;
-	s->ip_va = vgt_gma_to_va(s->vgt, ip_gma,
+	if (IS_VLV(s->vgt->pdev) && s->buf_type == RING_BUFFER_INSTRUCTION) {
+		s->ip_va = phys_aperture_vbase(s->vgt->pdev) + ip_gma;
+	} else {
+		s->ip_va = vgt_gma_to_va(s->vgt, ip_gma,
 			s->buf_addr_type == PPGTT_BUFFER);
+	}
 
 	if (s->ip_va == NULL){
 		vgt_err("ERROR: gma %lx is invalid, fail to set\n",s->ip_gma);
@@ -575,11 +583,14 @@ static int ip_gma_set(struct parser_exec_state *s, unsigned long ip_gma)
 	}else{
 		gma_next_page = ((ip_gma >> PAGE_SHIFT) + 1) << PAGE_SHIFT;
 	}
-	s->ip_va_next_page = vgt_gma_to_va(s->vgt, gma_next_page,
+	if (IS_VLV(s->vgt->pdev) && s->buf_type == RING_BUFFER_INSTRUCTION) {
+		s->ip_va_next_page = phys_aperture_vbase(s->vgt->pdev) + gma_next_page;
+	} else {
+		s->ip_va_next_page = vgt_gma_to_va(s->vgt, gma_next_page,
 			s->buf_addr_type == PPGTT_BUFFER);
-
+	}
 	if (s->ip_va_next_page == NULL){
-		vgt_err("ERROR: next page gma %lx is invalid, fail to set\n",gma_next_page);
+		vgt_err("ERROR: next page gma %lx is invalid, fail to set (ip_gma=%lx)\n", ip_gma, gma_next_page);
 		dump_stack();
 		parser_exec_state_dump(s);
 		return -EFAULT;
@@ -635,7 +646,7 @@ static int vgt_cmd_handler_mi_set_context(struct parser_exec_state* s)
 	struct vgt_device *vgt = s->vgt;
 
 	if (!vgt->has_context) {
-		printk("VM %d activate context\n", vgt->vm_id);
+		vgt_dbg(VGT_DBG_CMD, "VM %d activate context\n", vgt->vm_id);
 		vgt->has_context = 1;
 	}
 
@@ -766,6 +777,7 @@ static int vgt_cmd_handler_mi_batch_buffer_end(struct parser_exec_state *s)
 #define DISPLAY_FLIP_SPRITE_B  0x3
 #define DISPLAY_FLIP_PLANE_C  0x4
 #define DISPLAY_FLIP_SPRITE_C  0x5
+#define DISPLAY_FLIP_SPRITE_D  DISPLAY_FLIP_PLANE_C /*VLV only*/
 
 
 /* The NOOP for MI_DISPLAY_FLIP has below information stored in NOOP_ID:
@@ -777,7 +789,7 @@ static int vgt_cmd_handler_mi_batch_buffer_end(struct parser_exec_state *s)
 #define PLANE_INFO_SHIFT	8
 #define PLANE_INFO_MASK		(0x7 << PLANE_INFO_SHIFT)
 
-static bool display_flip_decode_plane_info(uint32_t  plane_code, enum vgt_pipe *pipe, enum vgt_plane_type *plane )
+static bool display_flip_decode_plane_info(struct pgt_device * pdev, uint32_t  plane_code, enum vgt_pipe *pipe, enum vgt_plane_type *plane )
 {
 	switch (plane_code) {
 		case DISPLAY_FLIP_PLANE_A:
@@ -793,16 +805,31 @@ static bool display_flip_decode_plane_info(uint32_t  plane_code, enum vgt_pipe *
 			*plane = SPRITE_PLANE;
 			break;
 		case DISPLAY_FLIP_SPRITE_B:
-			*pipe = PIPE_B;
-			*plane = SPRITE_PLANE;
+			if(IS_VLV(pdev)) {
+				*pipe = PIPE_A;
+				*plane = SPRITE_PLANE;
+			} else {
+				*pipe = PIPE_B;
+				*plane = SPRITE_PLANE;
+			}
 			break;
 		case DISPLAY_FLIP_PLANE_C:
-			*pipe = PIPE_C;
-			*plane = PRIMARY_PLANE;
+			if(IS_VLV(pdev)) {
+				*pipe = PIPE_B;
+				*plane = SPRITE_PLANE;
+			} else {
+				*pipe = PIPE_C;
+				*plane = PRIMARY_PLANE;
+			}
 			break;
 		case DISPLAY_FLIP_SPRITE_C:
-			*pipe = PIPE_C;
-			*plane = SPRITE_PLANE;
+			if(IS_VLV(pdev)) {
+				*pipe = PIPE_B;
+				*plane = SPRITE_PLANE;
+			} else {
+				*pipe = PIPE_C;
+				*plane = SPRITE_PLANE;
+			}
 			break;
 		default:
 			return false;
@@ -812,9 +839,14 @@ static bool display_flip_decode_plane_info(uint32_t  plane_code, enum vgt_pipe *
 
 }
 
-static bool display_flip_encode_plane_info(enum vgt_pipe pipe, enum vgt_plane_type plane, uint32_t * plane_code)
+static bool display_flip_encode_plane_info(struct pgt_device * pdev, enum vgt_pipe pipe, enum vgt_plane_type plane, uint32_t * plane_code)
 {
 
+
+	/* Baytrail NOTE: For now i am only focusing on the 1st sprites of *
+	 * each pipe for VLV so majority of the sprite pipe mapping      *
+     * codess and macro's are ignoring sprite-B and sprite-D         */
+
 	if(pipe == PIPE_A && plane == PRIMARY_PLANE)
 	{
 		*plane_code = DISPLAY_FLIP_PLANE_A;
@@ -829,7 +861,10 @@ static bool display_flip_encode_plane_info(enum vgt_pipe pipe, enum vgt_plane_ty
 	}
 	else if (pipe == PIPE_B && plane == SPRITE_PLANE)
 	{
-		*plane_code = DISPLAY_FLIP_SPRITE_B;
+		if(IS_VLV(pdev))
+			*plane_code = DISPLAY_FLIP_SPRITE_C;
+		else
+			*plane_code = DISPLAY_FLIP_SPRITE_B;
 	}
 	else if (pipe == PIPE_C && plane == PRIMARY_PLANE)
 	{
@@ -848,6 +883,25 @@ static bool display_flip_encode_plane_info(enum vgt_pipe pipe, enum vgt_plane_ty
 
 }
 
+
+#define VLV_GET_INFO_FOR_FLIP(pipe, plane, 					\
+			ctrl_reg, surf_reg, stride_reg, stride_mask)	\
+	do{                                                                     \
+	        if (plane == PRIMARY_PLANE) {                                   \
+	                ctrl_reg = VGT_VLV_DSPCNTR(pipe);                               \
+	                surf_reg = VGT_VLV_DSPSURF(pipe);                               \
+	                stride_reg = VGT_VLV_DSPSTRIDE(pipe);                   \
+	                stride_mask = _PRI_PLANE_STRIDE_MASK;                   \
+	        } else {                                                        \
+	                ASSERT (plane == SPRITE_PLANE);                         \
+	                ctrl_reg = VGT_VLV_SPRCTL(pipe);                                \
+	                surf_reg = VGT_VLV_SPRSURF(pipe);                               \
+	                stride_reg = VGT_VLV_SPRSTRIDE(pipe);                   \
+	                stride_mask = _SPRITE_STRIDE_MASK;                      \
+	        }                                                               \
+}while(0);
+
+
 #define GET_INFO_FOR_FLIP(pipe, plane, 					\
 			ctrl_reg, surf_reg, stride_reg, stride_mask)	\
 do{									\
@@ -878,11 +932,16 @@ static bool vgt_flip_parameter_check(struct parser_exec_state *s,
 	uint32_t tile_para, tile_in_ctrl;
 	bool async_flip;
 
-	if (!display_flip_decode_plane_info(plane_code, &pipe, &plane))
+	if (!display_flip_decode_plane_info(pdev, plane_code, &pipe, &plane))
 		return false;
 
-	GET_INFO_FOR_FLIP(pipe, plane,
+	if (IS_VLV(pdev)) {
+		VLV_GET_INFO_FOR_FLIP(pipe, plane,
+			ctrl_reg, surf_reg, stride_reg, stride_mask);
+	} else {
+		GET_INFO_FOR_FLIP(pipe, plane,
 			ctrl_reg, surf_reg, stride_reg, stride_mask);
+	}
 
 	async_flip = ((surf_val & FLIP_TYPE_MASK) == 0x1);
 	tile_para = ((stride_val & TILE_PARA_MASK) >> TILE_PARA_SHIFT);
@@ -931,6 +990,7 @@ static int vgt_handle_mi_display_flip(struct parser_exec_state *s, bool resubmit
 	int i, length, rc = 0;
 	struct fb_notify_msg msg;
 	uint32_t value;
+	struct pgt_device *pdev = s->vgt->pdev;
 
 	opcode = *(cmd_ptr(s, 0));
 	stride_val = *(cmd_ptr(s, 1));
@@ -945,7 +1005,7 @@ static int vgt_handle_mi_display_flip(struct parser_exec_state *s, bool resubmit
 	}
 
 
-	if(!display_flip_decode_plane_info(plane_code, &pipe, &plane)){
+	if(!display_flip_decode_plane_info(pdev, plane_code, &pipe, &plane)){
 		goto wrong_command;
 	}
 
@@ -969,8 +1029,13 @@ static int vgt_handle_mi_display_flip(struct parser_exec_state *s, bool resubmit
 			goto wrong_command;
 		}
 
-		GET_INFO_FOR_FLIP(pipe, plane,
-			ctrl_reg, surf_reg, stride_reg, stride_mask);
+		if (IS_VLV(pdev)) {
+			VLV_GET_INFO_FOR_FLIP(pipe, plane,
+				ctrl_reg, surf_reg, stride_reg, stride_mask);
+		} else {
+			GET_INFO_FOR_FLIP(pipe, plane,
+				ctrl_reg, surf_reg, stride_reg, stride_mask);
+		}
 		tile_para = ((stride_val & TILE_PARA_MASK) >> TILE_PARA_SHIFT);
 
 		__vreg(s->vgt, stride_reg) = (stride_val & stride_mask) |
@@ -990,7 +1055,7 @@ static int vgt_handle_mi_display_flip(struct parser_exec_state *s, bool resubmit
 	vgt_fb_notifier_call_chain(FB_DISPLAY_FLIP, &msg);
 
 	if ((s->vgt == current_foreground_vm(s->vgt->pdev)) && !resubmitted) {
-		if(!display_flip_encode_plane_info(real_pipe, plane, &real_plane_code))
+		if(!display_flip_encode_plane_info(pdev, real_pipe, plane, &real_plane_code))
 		{
 			goto wrong_command;
 		}
@@ -1188,8 +1253,8 @@ static int vgt_cmd_handler_mi_batch_buffer_start(struct parser_exec_state *s)
 		s->ret_ip_gma_bb = s->ip_gma + 2*sizeof(uint32_t);
 	 }
 
-	klog_printk("MI_BATCH_BUFFER_START: Addr=%x ClearCommandBufferEnable=%d\n",
-			cmd_val(s,1),  (cmd_val(s,0)>>11) & 1);
+	vgt_dbg(VGT_DBG_CMD, "MI_BATCH_BUFFER_START: Addr=%x ClearCommandBufferEnable=%d\n",
+		cmd_val(s,1),  (cmd_val(s,0)>>11) & 1);
 
 	address_fixup(s, 1);
 
@@ -1368,8 +1433,8 @@ static int vgt_cmd_handler_mi_noop(struct parser_exec_state* s)
 		if (cmd == OP_MI_DISPLAY_FLIP) {
 			vgt_handle_mi_display_flip(s, true);
 		} else {
-			vgt_err("VM %d: Guest reuse cmd buffer that is not handled!\n",
-					s->vgt->vm_id);
+			vgt_err("VM %d: Guest reuse cmd buffer that is not handled! (0x%x)\n",
+					s->vgt->vm_id, cmd);
 			parser_exec_state_dump(s);
 		}
 	}
@@ -2045,14 +2110,14 @@ static int vgt_cmd_parser_exec(struct parser_exec_state *s)
 {
 	struct cmd_info *info;
 
-	int rc = 0, i, cmd_len;
+	int rc = 0, i, cmd_len, cmd_trace_len;
 
 	info = vgt_get_cmd_info(*s->ip_va, s->ring_id);
 	if(info == NULL){
 		vgt_err("ERROR: unknown cmd 0x%x, opcode=0x%x\n", *s->ip_va,
 				vgt_get_opcode(*s->ip_va, s->ring_id));
 		parser_exec_state_dump(s);
-		klog_printk("ERROR: unknown cmd %x, ring%d[%lx,%lx] gma[%lx] va[%p]\n",
+		vgt_err("ERROR: unknown cmd %x, ring%d[%lx,%lx] gma[%lx] va[%p]\n",
 				*s->ip_va, s->ring_id, s->ring_start,
 				s->ring_start + s->ring_size, s->ip_gma, s->ip_va);
 
@@ -2060,6 +2125,11 @@ static int vgt_cmd_parser_exec(struct parser_exec_state *s)
 	}
 
 	s->info = info;
+	cmd_len = cmd_length(s); // need it now for calculating size
+	cmd_trace_len = cmd_len;
+
+	vgt_dbg(VGT_DBG_CMD, "info->name: %s L=%d ipgma_new=%lx\n",
+		info->name, cmd_len,  s->ip_gma+( cmd_len*4));
 
 #ifdef VGT_ENABLE_ADDRESS_FIX
 	{
@@ -2084,7 +2154,6 @@ static int vgt_cmd_parser_exec(struct parser_exec_state *s)
 	klog_printk("\n");
 #endif
 
-	cmd_len = cmd_length(s);
 	/* The chosen value of VGT_MAX_CMD_LENGTH are just based on
 	 * following two considerations:
 	 * 1) From observation, most common ring commands is not that long.
@@ -2095,12 +2164,15 @@ static int vgt_cmd_parser_exec(struct parser_exec_state *s)
 	 * We mgith shrink VGT_MAX_CMD_LENGTH or remove this trace event in
 	 * future for performance considerations.
 	 */
-	if (unlikely(cmd_len > VGT_MAX_CMD_LENGTH)) {
-		vgt_dbg(VGT_DBG_CMD, "cmd length exceed tracing limitation!\n");
-		cmd_len = VGT_MAX_CMD_LENGTH;
+
+	if (unlikely(cmd_trace_len > VGT_MAX_CMD_LENGTH)) {
+		vgt_dbg(VGT_DBG_CMD, "cmd length exceed tracing limitation! %d\n", cmd_trace_len);
+		cmd_trace_len = VGT_MAX_CMD_LENGTH;
 	}
-	for (i = 0; i < cmd_len; i++)
+	for (i = 0; i < cmd_trace_len; i++) {
 		cmd_trace_buf[i] = cmd_val(s, i);
+	}
+
 	trace_vgt_command(s->vgt->vm_id, s->ring_id, s->ip_gma, cmd_trace_buf,
 			cmd_len, s->buf_type == RING_BUFFER_INSTRUCTION);
 
@@ -2159,6 +2231,7 @@ static int __vgt_scan_vring(struct vgt_device *vgt, int ring_id, vgt_reg_t head,
 	int rc=0;
 	uint64_t cmd_nr = 0;
 	vgt_state_ring_t *rs = &vgt->rb[ring_id];
+	unsigned long dlt;
 
 	/* ring base is page aligned */
 	ASSERT((base & (PAGE_SIZE-1)) == 0);
@@ -2176,19 +2249,29 @@ static int __vgt_scan_vring(struct vgt_device *vgt, int ring_id, vgt_reg_t head,
 	s.ring_head = gma_head;
 	s.ring_tail = gma_tail;
 
+	if (s.ring_tail>s.ring_head) {
+		dlt =  (s.ring_tail-s.ring_head)/4;
+	} else {
+		dlt = (s.ring_size+s.ring_tail-s.ring_head)/4;
+	}
+
 	s.request_id = rs->request_id;
 
 	if (bypass_scan) {
+		vgt_dbg(VGT_DBG_CMD, "bypass-scan r=%d -> add_tail_entry / start=%lx end=%lx\n",
+			ring_id, gma_head, gma_tail);
 		add_tail_entry(&s, tail, 100, 0);
 		return 0;
 	}
 
 	rc = ip_gma_set(&s, base + head);
-	if (rc < 0)
+	if (rc < 0) {
+		vgt_err("_vgt_scan_vring r=%d rc=%d\n", ring_id, rc);
 		return rc;
+	}
+	vgt_dbg(VGT_DBG_CMD, "scan_start: r=%d  start=%lx end=%lx s.ip_gma=0x%lx bt=%d dlt=%lx\n",
+		ring_id, gma_head, gma_tail, s.ip_gma, s.buf_type, dlt);
 
-	klog_printk("ring buffer scan start on ring %d\n", ring_id);
-	vgt_dbg(VGT_DBG_CMD, "scan_start: start=%lx end=%lx\n", gma_head, gma_tail);
 	while(s.ip_gma != gma_tail){
 		if (s.buf_type == RING_BUFFER_INSTRUCTION){
 			ASSERT((s.ip_gma >= base) && (s.ip_gma < gma_bottom));
@@ -2211,9 +2294,9 @@ static int __vgt_scan_vring(struct vgt_device *vgt, int ring_id, vgt_reg_t head,
 		add_tail_entry(&s, tail, cmd_nr, 0);
 		rs->cmd_nr++;
 	}
+	vgt_dbg(VGT_DBG_CMD, "scan_end rc=%d r=%d start=%lx end=%lx cn=%lld cr=%lld\n",
+		rc, ring_id, s.ring_head, s.ring_tail, cmd_nr, rs->cmd_nr);
 
-	klog_printk("ring buffer scan end on ring %d\n", ring_id);
-	vgt_dbg(VGT_DBG_CMD, "scan_end\n");
 	return rc;
 }
 
diff --git a/drivers/xen/vgt/debugfs.c b/drivers/xen/vgt/debugfs.c
index 458bd67..862cabe 100644
--- a/drivers/xen/vgt/debugfs.c
+++ b/drivers/xen/vgt/debugfs.c
@@ -400,11 +400,20 @@ static int vgt_show_irqinfo(struct seq_file *m, void *data)
 		vgt = pdev->device[i];
 		vstat = &vgt->stat;
 
-		seq_printf(m, "....vreg (deier: %x, deiir: %x, deimr: %x, deisr: %x)\n",
-				__vreg(vgt, _REG_DEIER),
-				__vreg(vgt, _REG_DEIIR),
-				__vreg(vgt, _REG_DEIMR),
-				__vreg(vgt, _REG_DEISR));
+		if(IS_HSW(pdev) || IS_IVB(pdev) || IS_SNB(pdev)) {
+            seq_printf(m, "....vreg (deier: %x, deiir: %x, deimr: %x, deisr: %x)\n",
+                    __vreg(vgt, _REG_DEIER),
+                    __vreg(vgt, _REG_DEIIR),
+                    __vreg(vgt, _REG_DEIMR),
+                    __vreg(vgt, _REG_DEISR));
+		} else if(IS_VLV(pdev)){
+            seq_printf(m, "....vreg (gtlc_mir: %x, vlvier: %x, vlviir: %x, vlvimr: %x, vlvisr: %x)\n",
+                    __vreg(vgt, _REG_VLV_GTLC_MIR),
+                    __vreg(vgt, _REG_VLV_IER),
+                    __vreg(vgt, _REG_VLV_IIR),
+                    __vreg(vgt, _REG_VLV_IMR),
+                    __vreg(vgt, _REG_VLV_ISR));
+		}
 		seq_printf(m, "....vreg (gtier: %x, gtiir: %x, gtimr: %x, gtisr: %x)\n",
 				__vreg(vgt, _REG_GTIER),
 				__vreg(vgt, _REG_GTIIR),
@@ -904,6 +913,8 @@ struct dentry *vgt_init_debugfs(struct pgt_device *pdev)
 
 	temp_d = debugfs_create_file("irqinfo", 0444, d_vgt_debug,
 		pdev, &irqinfo_fops);
+	if (!temp_d)
+		return NULL;
 
 	temp_d = debugfs_create_file("dpyinfo", 0444, d_vgt_debug,
 		pdev, &phys_dpyinfo_fops);
diff --git a/drivers/xen/vgt/devtable.h b/drivers/xen/vgt/devtable.h
index d07070d..c1a7fb1 100644
--- a/drivers/xen/vgt/devtable.h
+++ b/drivers/xen/vgt/devtable.h
@@ -44,6 +44,25 @@ static inline int _is_sandybridge(int devid)
 	return ret;
 }
 
+static inline int _is_valleyview(int devid)
+{
+	int ret = 0;
+
+	switch (devid) {
+	case 0x0f30:
+	case 0x0f31:
+	case 0x0f32:
+	case 0x0f33:
+	case 0x0155:
+	case 0x0157:
+		ret = 1;
+		break;
+	default:
+		break;
+	}
+	return ret;
+}
+
 static inline int _is_ivybridge(int devid)
 {
 	int ret = 0;
diff --git a/drivers/xen/vgt/display.c b/drivers/xen/vgt/display.c
index 2c937ea..ff10983 100644
--- a/drivers/xen/vgt/display.c
+++ b/drivers/xen/vgt/display.c
@@ -43,23 +43,48 @@ static void vgt_restore_sreg(struct vgt_device *vgt,unsigned int reg)
 static int vgt_restore_state(struct vgt_device *vgt, enum vgt_pipe pipe)
 {
 #if 0
-	unsigned int pipe_ctrl = VGT_MMIO_READ(vgt->pdev, VGT_PIPECONF(pipe));
+	unsigned int pipe_ctrl=0;
+
+	if(IS_VLV(vgt->pdev)) {
+		pipe_ctrl = VGT_MMIO_READ(vgt->pdev, VGT_PIPECONF_VLV(pipe));
+	} else if (IS_SNB(vgt->pdev) || IS_IVB(vgt->pdev) ||IS_HSW(vgt->pdev)) {
+		pipe_ctrl = VGT_MMIO_READ(vgt->pdev, VGT_PIPECONF(pipe));
+	}
 	if (pipe_ctrl & _REGBIT_PIPE_ENABLE) {
 #endif
-		vgt_dbg (VGT_DBG_DPY, "start to restore pipe %d.\n", pipe + 1);
-		vgt_restore_sreg(vgt, VGT_DSPCNTR(pipe));
-		vgt_restore_sreg(vgt, VGT_DSPSTRIDE(pipe));
-		vgt_restore_sreg(vgt, VGT_DSPSURF(pipe));
-		vgt_restore_sreg(vgt, VGT_DSPTILEOFF(pipe));
-		vgt_restore_sreg(vgt, VGT_DSPLINOFF(pipe));
-
-		vgt_restore_sreg(vgt, VGT_CURPOS(pipe));
-		vgt_restore_sreg(vgt, VGT_CURCNTR(pipe));
-		vgt_restore_sreg(vgt, VGT_CURBASE(pipe));
-		vgt_dbg (VGT_DBG_DPY, "finished pipe %d restore.\n", pipe + 1);
+
+		if(IS_VLV(vgt->pdev)) {
+			if (pipe > PIPE_B) {
+				vgt_dbg (VGT_DBG_DPY, "VLV: only PIPE A & B\n");
+				return 0;
+			}
+			vgt_dbg (VGT_DBG_DPY, "start to restore pipe %d.\n", (int)pipe + 1);
+			vgt_restore_sreg(vgt, VGT_VLV_DSPCNTR(pipe));
+			vgt_restore_sreg(vgt, VGT_VLV_DSPSTRIDE(pipe));
+			vgt_restore_sreg(vgt, VGT_VLV_DSPSURF(pipe));
+			vgt_restore_sreg(vgt, VGT_VLV_DSPTILEOFF(pipe));
+			vgt_restore_sreg(vgt, VGT_VLV_DSPLINOFF(pipe));
+
+			vgt_restore_sreg(vgt, VGT_VLV_CURPOS(pipe));
+			vgt_restore_sreg(vgt, VGT_VLV_CURCNTR(pipe));
+			vgt_restore_sreg(vgt, VGT_VLV_CURBASE(pipe));
+			vgt_dbg (VGT_DBG_DPY, "finished pipe %d restore.\n", (int)pipe + 1);
+		} else if (IS_SNB(vgt->pdev) || IS_IVB(vgt->pdev) ||IS_HSW(vgt->pdev)) {
+			vgt_dbg (VGT_DBG_DPY, "start to restore pipe %d.\n", (int)pipe + 1);
+			vgt_restore_sreg(vgt, VGT_DSPCNTR(pipe));
+			vgt_restore_sreg(vgt, VGT_DSPSTRIDE(pipe));
+			vgt_restore_sreg(vgt, VGT_DSPSURF(pipe));
+			vgt_restore_sreg(vgt, VGT_DSPTILEOFF(pipe));
+			vgt_restore_sreg(vgt, VGT_DSPLINOFF(pipe));
+
+			vgt_restore_sreg(vgt, VGT_CURPOS(pipe));
+			vgt_restore_sreg(vgt, VGT_CURCNTR(pipe));
+			vgt_restore_sreg(vgt, VGT_CURBASE(pipe));
+			vgt_dbg (VGT_DBG_DPY, "finished pipe %d restore.\n", (int)pipe + 1);
+		}
 #if 0
 	} else {
-		vgt_dbg (VGT_DBG_DPY, "pipe %d is not enabled.\n", pipe + 1);
+		vgt_dbg (VGT_DBG_DPY, "pipe %d is not enabled.\n", (int)pipe + 1);
 	}
 #endif
 	return 0;
@@ -68,9 +93,15 @@ static int vgt_restore_state(struct vgt_device *vgt, enum vgt_pipe pipe)
 static int wait_for_vblank_atomic(struct pgt_device *pdev, enum vgt_pipe pipe)
 {
 	int ret;
-	unsigned int frmcnt_mmio = VGT_PIPE_FRMCOUNT(pipe);
-	vgt_reg_t frmcnt = VGT_MMIO_READ(pdev, frmcnt_mmio);
+	unsigned int frmcnt_mmio=0;
+	vgt_reg_t frmcnt;
 
+	if(IS_VLV(pdev)) {
+		frmcnt_mmio = VGT_VLV_PIPE_FRMCOUNT(pipe);
+	} else if (IS_SNB(pdev) || IS_IVB(pdev) ||IS_HSW(pdev)) {
+		frmcnt_mmio = VGT_PIPE_FRMCOUNT(pipe);
+	}
+	frmcnt = VGT_MMIO_READ(pdev, frmcnt_mmio);
 	ret = wait_for_atomic((VGT_MMIO_READ(pdev, frmcnt_mmio) != frmcnt),
 				VGT_VBLANK_TIMEOUT);
 	if (ret == -ETIMEDOUT) {
@@ -83,9 +114,14 @@ static int wait_for_vblanks_atomic(struct pgt_device *pdev)
 {
 	int ret = 0;
 	enum vgt_pipe pipe;
+	vgt_reg_t pipeconf=0;
 
 	for (pipe = PIPE_A; (pipe < I915_MAX_PIPES) && !ret; ++ pipe) {
-		vgt_reg_t pipeconf = VGT_MMIO_READ(pdev, VGT_PIPECONF(pipe));
+		if(IS_VLV(pdev)) {
+			pipeconf = VGT_MMIO_READ(pdev, VGT_VLV_PIPECONF(pipe));
+		} else if (IS_SNB(pdev) || IS_IVB(pdev) ||IS_HSW(pdev)) {
+			pipeconf = VGT_MMIO_READ(pdev, VGT_PIPECONF(pipe));
+		}
 		if (pipeconf & _REGBIT_PIPE_ENABLE) {
 			ret = wait_for_vblank_atomic(pdev, pipe);
 		}
@@ -129,8 +165,12 @@ void do_vgt_fast_display_switch(struct pgt_device *pdev)
 
 	for (pipe = PIPE_A; pipe < I915_MAX_PIPES; ++ pipe) {
 		vgt_restore_state(to_vgt, pipe);
-		if (_PRI_PLANE_ENABLE & __vreg(to_vgt, VGT_DSPCNTR(pipe))) {
-			set_panel_fitting(to_vgt, pipe);
+		if(IS_VLV(pdev)) {
+			if (_PRI_PLANE_ENABLE & __vreg(to_vgt, VGT_VLV_DSPCNTR(pipe)))
+				set_panel_fitting(to_vgt, pipe);
+		} else if (IS_SNB(pdev) || IS_IVB(pdev) ||IS_HSW(pdev)) {
+			if (_PRI_PLANE_ENABLE & __vreg(to_vgt, VGT_DSPCNTR(pipe)))
+				set_panel_fitting(to_vgt, pipe);
 		}
 	}
 
@@ -151,7 +191,7 @@ static inline int get_event_and_edid_info(vgt_hotplug_cmd_t cmd,
 	case 1:
 		*pedid_idx = I915_MAX_PORTS;
 		*pevent = EVENT_MAX;
-		printk("vGT: No support for hot plug type: DP_A!\n");
+		vgt_dbg(VGT_DBG_DPY, "vGT: No support for hot plug type: DP_A!\n");
 		ret = -EINVAL;
 		break;
 	case 2:
@@ -169,7 +209,7 @@ static inline int get_event_and_edid_info(vgt_hotplug_cmd_t cmd,
 	default:
 		*pedid_idx = I915_MAX_PORTS;
 		*pevent = EVENT_MAX;
-		printk("vGT: Not supported hot plug type: 0x%x!\n",
+		vgt_dbg(VGT_DBG_DPY, "vGT: Not supported hot plug type: 0x%x!\n",
 			cmd.port_sel);
 		ret = -EINVAL;
 		break;
@@ -328,7 +368,7 @@ void vgt_signal_uevent(struct pgt_device *pdev)
 
 		rc = info_entry->vgt_uevent_handler(bit, info_entry, pdev);
 		if (rc == false)
-			printk("%s: %d: vGT: failed to send uevent [%s]!\n",
+			vgt_err("%s: %d: vGT: failed to send uevent [%s]!\n",
 					__func__, __LINE__, info_entry->uevent_name);
 	}
 }
@@ -351,27 +391,44 @@ void vgt_hotplug_udev_notify_func(struct work_struct *work)
 
 void vgt_update_monitor_status(struct vgt_device *vgt)
 {
-	__vreg(vgt, _REG_SDEISR) &= ~(_REGBIT_DP_B_HOTPLUG |
-					_REGBIT_DP_C_HOTPLUG |
-					_REGBIT_DP_D_HOTPLUG);
 
-	if (test_bit(VGT_DP_B, vgt->presented_ports) ||
-		test_bit(VGT_HDMI_B, vgt->presented_ports)) {
-		vgt_dbg(VGT_DBG_DPY, "enable B port monitor\n");
-		__vreg(vgt, _REG_SDEISR) |= _REGBIT_DP_B_HOTPLUG;
-	}
-	if (test_bit(VGT_DP_C, vgt->presented_ports) ||
-		test_bit(VGT_HDMI_C, vgt->presented_ports)) {
-		vgt_dbg(VGT_DBG_DPY, "enable C port monitor\n");
-		__vreg(vgt, _REG_SDEISR) |= _REGBIT_DP_C_HOTPLUG;
-	}
-	if (test_bit(VGT_DP_D, vgt->presented_ports) ||
-		test_bit(VGT_HDMI_D, vgt->presented_ports)) {
-		vgt_dbg(VGT_DBG_DPY, "enable D port monitor\n");
-		__vreg(vgt, _REG_SDEISR) |= _REGBIT_DP_D_HOTPLUG;
-	}
-	if (test_bit(VGT_DP_A, vgt->presented_ports)) {
-		__vreg(vgt, _REG_DDI_BUF_CTL_A) |= _DDI_BUFCTL_DETECT_MASK;
+	if(IS_VLV(vgt->pdev)) {
+		__vreg(vgt, _REG_VLV_PORT_HOTPLUG_STAT) &=
+			~(VLV_HPSTAT_DPB_EVENT | VLV_HPSTAT_DPB_EVENT);
+
+		if (test_bit(VGT_DP_B, vgt->presented_ports) ||
+			test_bit(VGT_HDMI_B, vgt->presented_ports)) {
+			vgt_dbg(VGT_DBG_DPY, "enable B port monitor\n");
+			__vreg(vgt, _REG_VLV_PORT_HOTPLUG_STAT) |= VLV_HPSTAT_DPB_EVENT;
+		}
+		if (test_bit(VGT_DP_C, vgt->presented_ports) ||
+			test_bit(VGT_HDMI_C, vgt->presented_ports)) {
+			vgt_dbg(VGT_DBG_DPY, "enable C port monitor\n");
+			__vreg(vgt, _REG_VLV_PORT_HOTPLUG_STAT) |= VLV_HPSTAT_DPC_EVENT;
+		}
+	} else if (IS_SNB(vgt->pdev) || IS_IVB(vgt->pdev) ||IS_HSW(vgt->pdev)) {
+		__vreg(vgt, _REG_SDEISR) &= ~(_REGBIT_DP_B_HOTPLUG |
+						_REGBIT_DP_C_HOTPLUG |
+						_REGBIT_DP_D_HOTPLUG);
+
+		if (test_bit(VGT_DP_B, vgt->presented_ports) ||
+			test_bit(VGT_HDMI_B, vgt->presented_ports)) {
+			vgt_dbg(VGT_DBG_DPY, "enable B port monitor\n");
+			__vreg(vgt, _REG_SDEISR) |= _REGBIT_DP_B_HOTPLUG;
+		}
+		if (test_bit(VGT_DP_C, vgt->presented_ports) ||
+			test_bit(VGT_HDMI_C, vgt->presented_ports)) {
+			vgt_dbg(VGT_DBG_DPY, "enable C port monitor\n");
+			__vreg(vgt, _REG_SDEISR) |= _REGBIT_DP_C_HOTPLUG;
+		}
+		if (test_bit(VGT_DP_D, vgt->presented_ports) ||
+			test_bit(VGT_HDMI_D, vgt->presented_ports)) {
+			vgt_dbg(VGT_DBG_DPY, "enable D port monitor\n");
+			__vreg(vgt, _REG_SDEISR) |= _REGBIT_DP_D_HOTPLUG;
+		}
+		if (test_bit(VGT_DP_A, vgt->presented_ports)) {
+			__vreg(vgt, _REG_DDI_BUF_CTL_A) |= _DDI_BUFCTL_DETECT_MASK;
+		}
 	}
 }
 
@@ -399,7 +456,9 @@ enum vgt_pipe get_edp_input(uint32_t wr_data)
 	}
 	return pipe;
 }
-
+/* TO-DO : This function has not been updated for Baytrail
+ * This function is only used under the DP/eDP codepath
+ */
 enum vgt_pipe get_pipe(unsigned int reg, uint32_t wr_data)
 {
 	enum vgt_pipe pipe = I915_MAX_PIPES;
@@ -419,12 +478,18 @@ enum vgt_pipe get_pipe(unsigned int reg, uint32_t wr_data)
 	return pipe;
 }
 
+/* TO-DO : This function has not been updated for Baytrail
+ * This function is only used under the DP/eDP codepath
+ */
 static void vgt_update_irq_reg(struct vgt_device *vgt)
 {
 	recalculate_and_update_ier(vgt->pdev, _REG_DEIER);
 	recalculate_and_update_imr(vgt->pdev, _REG_DEIMR);
 }
 
+/* TO-DO : This function has not been updated for Baytrail
+ * This function is only used under the DP/eDP codepath
+ */
 bool rebuild_pipe_mapping(struct vgt_device *vgt, unsigned int reg, uint32_t new_data, uint32_t old_data)
 {
 	vgt_reg_t hw_value;
@@ -437,6 +502,10 @@ bool rebuild_pipe_mapping(struct vgt_device *vgt, unsigned int reg, uint32_t new
 		return true;
 	}
 
+	if(IS_VLV(vgt->pdev)) {
+		return true;
+	}
+
 	virtual_pipe = get_pipe(reg, new_data);
 
 	/*disable pipe case*/
@@ -517,6 +586,9 @@ bool rebuild_pipe_mapping(struct vgt_device *vgt, unsigned int reg, uint32_t new
 	return true;
 }
 
+/* TO-DO : This function has not been updated for Baytrail
+ * This function is only used under the DP/eDP codepath
+ */
 bool update_pipe_mapping(struct vgt_device *vgt, unsigned int physical_reg, uint32_t physical_wr_data)
 {
 	int i = 0;
@@ -527,6 +599,10 @@ bool update_pipe_mapping(struct vgt_device *vgt, unsigned int physical_reg, uint
 
 	physical_pipe = get_pipe(physical_reg, physical_wr_data);
 
+	if(IS_VLV(vgt->pdev)) {
+		return true;
+	}
+
 	/*disable pipe case*/
 	if ((_REGBIT_TRANS_DDI_FUNC_ENABLE & physical_wr_data) == 0) {
 		for (i = 0; i < I915_MAX_PIPES; i ++) {
@@ -621,77 +697,145 @@ bool set_panel_fitting(struct vgt_device *vgt, enum vgt_pipe pipe)
 		vgt_dbg(VGT_DBG_DPY, "try to set panel fitting before pipe is mapped!\n");
 		return false;
 	}
-	if (((_PRI_PLANE_ENABLE & __vreg(vgt, VGT_DSPCNTR(pipe))) == 0) ||
-		(_PRI_PLANE_ENABLE & VGT_MMIO_READ(vgt->pdev, VGT_DSPCNTR(real_pipe))) == 0) {
-		return false;
+
+	if(IS_VLV(vgt->pdev)){
+		if (((_PRI_PLANE_ENABLE & __vreg(vgt, VGT_VLV_DSPCNTR(pipe))) == 0) ||
+			(_PRI_PLANE_ENABLE & VGT_MMIO_READ(vgt->pdev, VGT_VLV_DSPCNTR(real_pipe))) == 0) {
+			return false;
+		}
+	} else if (IS_SNB(vgt->pdev) || IS_IVB(vgt->pdev) ||IS_HSW(vgt->pdev)) {
+		if (((_PRI_PLANE_ENABLE & __vreg(vgt, VGT_DSPCNTR(pipe))) == 0) ||
+			(_PRI_PLANE_ENABLE & VGT_MMIO_READ(vgt->pdev, VGT_DSPCNTR(real_pipe))) == 0) {
+			return false;
+		}
 	}
-	src_width = (__vreg(vgt, VGT_PIPESRC(pipe)) & 0xffff0000) >> 16;
-	src_height = __vreg(vgt, VGT_PIPESRC(pipe)) & 0xffff;
-	ASSERT_VM(src_width != 0, vgt);
-	ASSERT_VM(src_height != 0, vgt);
-	src_width += 1;
-	src_height += 1;
 
-	h_total_reg = VGT_HTOTAL(real_pipe);
-	v_total_reg = VGT_VTOTAL(real_pipe);
+	if(IS_VLV(vgt->pdev)){
 
-	edp_trans_code = VGT_MMIO_READ(vgt->pdev, _REG_TRANS_DDI_FUNC_CTL_EDP);
-	if ((_REGBIT_TRANS_DDI_FUNC_ENABLE & edp_trans_code)) {
-		if (real_pipe == get_edp_input(edp_trans_code)) {
-			h_total_reg = _REG_HTOTAL_EDP;
-			v_total_reg = _REG_VTOTAL_EDP;
+		if(real_pipe != PIPE_A) {
+			/* VLV only has 1 panel fitter - lets keep it for PipeA only*/
+			vgt_warn("VLV has 1 panel fitting - reserving for PipeA!\n");
+			return false;
 		}
-	}
 
-	target_width = VGT_MMIO_READ(vgt->pdev, h_total_reg) & 0xffff;
-	target_height = VGT_MMIO_READ(vgt->pdev, v_total_reg) & 0xffff;
+		src_width = (__vreg(vgt, _REG_VLV_PIPEASRC) & 0xffff0000) >> 16;
+		src_height = __vreg(vgt, _REG_VLV_PIPEASRC) & 0xffff;
+		src_width += 1;
+		src_height += 1;
 
-	ASSERT_VM(target_width != 0, vgt);
-	ASSERT_VM(target_height != 0, vgt);
-	target_width += 1;
-	target_height += 1;
+		h_total_reg = _REG_VLV_HTOTAL_A;
+		v_total_reg = _REG_VLV_VTOTAL_A;
 
-	/*fixed panel fitting mode to 3x3 mode, Restriction : A 3x3 capable filter must not be enabled
-		when the pipe horizontal source size is greater than 2048 pixels*/
-	pf_ctl =  _REGBIT_PF_FILTER_MED_3x3 | _REGBIT_PF_PIPE_SEL(real_pipe);
+		target_width = VGT_MMIO_READ(vgt->pdev, h_total_reg) & 0xffff;
+		target_height = VGT_MMIO_READ(vgt->pdev, v_total_reg) & 0xffff;
+
+		target_width += 1;
+		target_height += 1;
+
+		/*fixed panel fitting mode to 3x3 mode, Restriction : A 3x3 capable filter must not be enabled
+			when the pipe horizontal source size is greater than 2048 pixels*/
+		pf_ctl =  0/*PipeA is BIT30:29=00*/;
+
+		/*enable panel fitting only when the source mode does not eqaul to the target mode*/
+		if (src_width != target_width || src_height != target_height ) {
+			vgt_dbg(VGT_DBG_DPY, "enable panel fitting for pipe %d, src_width:%d, src_height: %d, tgt_width:%d, tgt_height:%d!\n",
+				pipe,src_width,src_height ,target_width,target_height);
+			pf_ctl = pf_ctl | _REGBIT_PF_ENABLE;
+		} else {
+			vgt_dbg(VGT_DBG_DPY, "disable panel fitting for pipe %d!\n", pipe);
+		}
+
+		/* ALANPREVIN - Have not taken care of watermak in VLV for now */
+		/*if (src_width > target_width || src_height > target_height) {
+			wm_reg = _REG_WM0_PIPEA_ILK;
+			plane_wm = (__vreg(vgt_dom0, wm_reg) & _REGBIT_WM0_PIPE_PLANE_MASK) >> _REGBIT_WM0_PIPE_PLANE_SHIFT;
+			sprite_wm = (__vreg(vgt_dom0, wm_reg) & _REGBIT_WM0_PIPE_SPRITE_MASK) >> _REGBIT_WM0_PIPE_SPRITE_SHIFT;
+			cursor_wm = __vreg(vgt_dom0, wm_reg) & _REGBIT_WM0_PIPE_CURSOR_MASK;
+			plane_wm = plane_wm * src_width * src_height / (target_width * target_height);
+			sprite_wm = sprite_wm * src_width * src_height / (target_width * target_height);
+			cursor_wm = cursor_wm * src_width * src_height / (target_width * target_height);
+			plane_wm = plane_wm > DISPLAY_MAXWM ? DISPLAY_MAXWM : plane_wm;
+			sprite_wm = sprite_wm > DISPLAY_MAXWM ? DISPLAY_MAXWM : sprite_wm;
+			cursor_wm = cursor_wm > CURSOR_MAXWM ? CURSOR_MAXWM : cursor_wm;
+			wm_value = cursor_wm & _REGBIT_WM0_PIPE_CURSOR_MASK;
+			wm_value = wm_value | (sprite_wm  << _REGBIT_WM0_PIPE_SPRITE_SHIFT);
+			wm_value = wm_value | ((plane_wm << _REGBIT_WM0_PIPE_PLANE_SHIFT) & _REGBIT_WM0_PIPE_PLANE_MASK);
+			VGT_MMIO_WRITE(vgt->pdev, wm_reg, wm_value);
+		}*/
+
+		VGT_MMIO_WRITE(vgt->pdev, _REG_VLV_PIPEASRC,  ((src_width -1) << 16) | (src_height - 1));
+		VGT_MMIO_WRITE(vgt->pdev, _REG_VLV_PFIT_CTL, pf_ctl);
+
+	} else if (IS_SNB(vgt->pdev) || IS_IVB(vgt->pdev) ||IS_HSW(vgt->pdev)) {
+		src_width = (__vreg(vgt, VGT_PIPESRC(pipe)) & 0xffff0000) >> 16;
+		src_height = __vreg(vgt, VGT_PIPESRC(pipe)) & 0xffff;
+		ASSERT_VM(src_width != 0, vgt);
+		ASSERT_VM(src_height != 0, vgt);
+		src_width += 1;
+		src_height += 1;
+
+		h_total_reg = VGT_HTOTAL(real_pipe);
+		v_total_reg = VGT_VTOTAL(real_pipe);
+
+		edp_trans_code = VGT_MMIO_READ(vgt->pdev, _REG_TRANS_DDI_FUNC_CTL_EDP);
+		if ((_REGBIT_TRANS_DDI_FUNC_ENABLE & edp_trans_code)) {
+			if (real_pipe == get_edp_input(edp_trans_code)) {
+				h_total_reg = _REG_HTOTAL_EDP;
+				v_total_reg = _REG_VTOTAL_EDP;
+			}
+		}
+
+		target_width = VGT_MMIO_READ(vgt->pdev, h_total_reg) & 0xffff;
+		target_height = VGT_MMIO_READ(vgt->pdev, v_total_reg) & 0xffff;
+
+		ASSERT_VM(target_width != 0, vgt);
+		ASSERT_VM(target_height != 0, vgt);
+		target_width += 1;
+		target_height += 1;
+
+		/*fixed panel fitting mode to 3x3 mode, Restriction : A 3x3 capable filter must not be enabled
+			when the pipe horizontal source size is greater than 2048 pixels*/
+		pf_ctl =  _REGBIT_PF_FILTER_MED_3x3 | _REGBIT_PF_PIPE_SEL(real_pipe);
+
+		/*enable panel fitting only when the source mode does not eqaul to the target mode*/
+		if (src_width != target_width || src_height != target_height ) {
+			vgt_dbg(VGT_DBG_DPY, "enable panel fitting for pipe %d, src_width:%d, src_height: %d, tgt_width:%d, tgt_height:%d!\n",
+				pipe,src_width,src_height ,target_width,target_height);
+			pf_ctl = pf_ctl | _REGBIT_PF_ENABLE;
+		} else {
+			vgt_dbg(VGT_DBG_DPY, "disable panel fitting for pipe %d!\n", pipe);
+		}
+
+		/* we need to increase Water Mark in down scaling case */
+		if (src_width > target_width || src_height > target_height) {
+			wm_reg = real_pipe == PIPE_A ? _REG_WM0_PIPEA_ILK :
+				(real_pipe == PIPE_B ? _REG_WM0_PIPEB_ILK : _REG_WM0_PIPEC_IVB);
+			plane_wm = (__vreg(vgt_dom0, wm_reg) & _REGBIT_WM0_PIPE_PLANE_MASK)
+				>> _REGBIT_WM0_PIPE_PLANE_SHIFT;
+			sprite_wm = (__vreg(vgt_dom0, wm_reg) & _REGBIT_WM0_PIPE_SPRITE_MASK)
+				>> _REGBIT_WM0_PIPE_SPRITE_SHIFT;
+			cursor_wm = __vreg(vgt_dom0, wm_reg) & _REGBIT_WM0_PIPE_CURSOR_MASK;
+			plane_wm = plane_wm * src_width * src_height / (target_width * target_height);
+			sprite_wm = sprite_wm * src_width * src_height / (target_width * target_height);
+			cursor_wm = cursor_wm * src_width * src_height / (target_width * target_height);
+			plane_wm = plane_wm > DISPLAY_MAXWM ? DISPLAY_MAXWM : plane_wm;
+			sprite_wm = sprite_wm > DISPLAY_MAXWM ? DISPLAY_MAXWM : sprite_wm;
+			cursor_wm = cursor_wm > CURSOR_MAXWM ? CURSOR_MAXWM : cursor_wm;
+			wm_value = cursor_wm & _REGBIT_WM0_PIPE_CURSOR_MASK;
+			wm_value = wm_value | (sprite_wm  << _REGBIT_WM0_PIPE_SPRITE_SHIFT);
+			wm_value = wm_value | ((plane_wm << _REGBIT_WM0_PIPE_PLANE_SHIFT) &
+				_REGBIT_WM0_PIPE_PLANE_MASK);
+			VGT_MMIO_WRITE(vgt->pdev, wm_reg, wm_value);
+		}
+
+		VGT_MMIO_WRITE(vgt->pdev, VGT_PIPESRC(real_pipe),  ((src_width -1) << 16) | (src_height - 1));
+		VGT_MMIO_WRITE(vgt->pdev, VGT_PF_WIN_POS(real_pipe), 0);
+		VGT_MMIO_WRITE(vgt->pdev, VGT_PF_CTL(real_pipe), pf_ctl);
+		/* PF ctrl is a double buffered registers and gets updated when window
+		 size registered is updated*/
+		VGT_MMIO_WRITE(vgt->pdev, VGT_PF_WIN_SZ(real_pipe),  (target_width << 16) | target_height);
+	}
 
-	/*enable panel fitting only when the source mode does not eqaul to the target mode*/
-	if (src_width != target_width || src_height != target_height ) {
-		vgt_dbg(VGT_DBG_DPY, "enable panel fitting for VM %d, pipe %d, src_width:%d, src_height: %d, tgt_width:%d, tgt_height:%d!\n",
-			vgt->vm_id, real_pipe, src_width, src_height, target_width, target_height);
-		pf_ctl = pf_ctl | _REGBIT_PF_ENABLE;
-	} else {
-		vgt_dbg(VGT_DBG_DPY, "disable panel fitting for VM %d, for pipe %d!\n", vgt->vm_id, real_pipe);
-	}
-
-	/* we need to increase Water Mark in down scaling case */
-	if (src_width > target_width || src_height > target_height) {
-		wm_reg = real_pipe == PIPE_A ? _REG_WM0_PIPEA_ILK :
-			(real_pipe == PIPE_B ? _REG_WM0_PIPEB_ILK : _REG_WM0_PIPEC_IVB);
-		plane_wm = (__vreg(vgt_dom0, wm_reg) & _REGBIT_WM0_PIPE_PLANE_MASK)
-			>> _REGBIT_WM0_PIPE_PLANE_SHIFT;
-		sprite_wm = (__vreg(vgt_dom0, wm_reg) & _REGBIT_WM0_PIPE_SPRITE_MASK)
-			>> _REGBIT_WM0_PIPE_SPRITE_SHIFT;
-		cursor_wm = __vreg(vgt_dom0, wm_reg) & _REGBIT_WM0_PIPE_CURSOR_MASK;
-		plane_wm = plane_wm * src_width * src_height / (target_width * target_height);
-		sprite_wm = sprite_wm * src_width * src_height / (target_width * target_height);
-		cursor_wm = cursor_wm * src_width * src_height / (target_width * target_height);
-		plane_wm = plane_wm > DISPLAY_MAXWM ? DISPLAY_MAXWM : plane_wm;
-		sprite_wm = sprite_wm > DISPLAY_MAXWM ? DISPLAY_MAXWM : sprite_wm;
-		cursor_wm = cursor_wm > CURSOR_MAXWM ? CURSOR_MAXWM : cursor_wm;
-		wm_value = cursor_wm & _REGBIT_WM0_PIPE_CURSOR_MASK;
-		wm_value = wm_value | (sprite_wm  << _REGBIT_WM0_PIPE_SPRITE_SHIFT);
-		wm_value = wm_value | ((plane_wm << _REGBIT_WM0_PIPE_PLANE_SHIFT) &
-			_REGBIT_WM0_PIPE_PLANE_MASK);
-		VGT_MMIO_WRITE(vgt->pdev, wm_reg, wm_value);
-	}
-
-	VGT_MMIO_WRITE(vgt->pdev, VGT_PIPESRC(real_pipe),  ((src_width -1) << 16) | (src_height - 1));
-	VGT_MMIO_WRITE(vgt->pdev, VGT_PF_WIN_POS(real_pipe), 0);
-	VGT_MMIO_WRITE(vgt->pdev, VGT_PF_CTL(real_pipe), pf_ctl);
-	/* PF ctrl is a double buffered registers and gets updated when window
-	 size registered is updated*/
-	VGT_MMIO_WRITE(vgt->pdev, VGT_PF_WIN_SZ(real_pipe),  (target_width << 16) | target_height);
 	return true;
 }
 
@@ -709,13 +853,17 @@ bool vgt_manage_emul_dpy_events(struct pgt_device *pdev)
 
 	for (i = 0; i < VGT_MAX_VMS; i++) {
 		struct vgt_device *vgt = pdev->device[i];
-		vgt_reg_t pipeconf;
+		vgt_reg_t pipeconf=0;
 
 		if (vgt == NULL)
 			continue;
 
 		for (pipe = PIPE_A; pipe < I915_MAX_PIPES; pipe ++) {
-			pipeconf = __vreg(vgt, VGT_PIPECONF(pipe));
+			if(IS_VLV(pdev)) {
+				pipeconf = __vreg(vgt, VGT_VLV_PIPECONF(pipe));
+			} else if (IS_SNB(pdev) || IS_IVB(pdev) ||IS_HSW(pdev)) {
+				pipeconf = __vreg(vgt, VGT_PIPECONF(pipe));
+			}
 			if (pipeconf & _REGBIT_PIPE_ENABLE) {
 				if (is_current_display_owner(vgt))
 					hw_enabled_pipes |= (1 << pipe);
@@ -733,25 +881,28 @@ bool vgt_manage_emul_dpy_events(struct pgt_device *pdev)
 			}
 		}
 
-		pipeconf = __vreg(vgt, _REG_PIPE_EDP_CONF);
-		if (pipeconf & _REGBIT_PIPE_ENABLE) {
-			pipe = get_edp_input(
-				__vreg(vgt, _REG_TRANS_DDI_FUNC_CTL_EDP));
-			if (pipe == I915_MAX_PIPES) {
-				vgt_err("vGT(%d): "
-					"Invalid input selection for eDP\n",
-					vgt->vgt_id);
-				return false;
-			}
-			if (is_current_display_owner(vgt))
-				hw_enabled_pipes |= (1 << pipe);
-			else {
-				enum vgt_pipe p_pipe = vgt->pipe_mapping[pipe];
-				if (p_pipe != I915_MAX_PIPES) {
-					hvm_required_pipes |= (1 << pipe);
-				} else {
-					hvm_no_pipe_mapping = true;
-					break;
+		if(!IS_VLV(pdev)) {
+			/* FIXME ALANPREVIN - for now temporarily we'll skip DP/eDP on Baytrail */
+			pipeconf = __vreg(vgt, _REG_PIPE_EDP_CONF);
+			if (pipeconf & _REGBIT_PIPE_ENABLE) {
+				pipe = get_edp_input(
+					__vreg(vgt, _REG_TRANS_DDI_FUNC_CTL_EDP));
+				if (pipe == I915_MAX_PIPES) {
+					vgt_err("vGT(%d): "
+						"Invalid input selection for eDP\n",
+						vgt->vgt_id);
+					return false;
+				}
+				if (is_current_display_owner(vgt))
+					hw_enabled_pipes |= (1 << pipe);
+				else {
+					enum vgt_pipe p_pipe = vgt->pipe_mapping[pipe];
+					if (p_pipe != I915_MAX_PIPES) {
+						hvm_required_pipes |= (1 << pipe);
+					} else {
+						hvm_no_pipe_mapping = true;
+						break;
+					}
 				}
 			}
 		}
@@ -771,15 +922,29 @@ bool vgt_manage_emul_dpy_events(struct pgt_device *pdev)
 void vgt_update_frmcount(struct vgt_device *vgt,
 	enum vgt_pipe pipe)
 {
-	uint32_t v_counter_addr, count, delta;
+	uint32_t v_counter_addr=0, count, delta, p_counter_addr=0;
 	enum vgt_pipe phys_pipe;
-	v_counter_addr = VGT_PIPE_FRMCOUNT(pipe);
+
+
+	if(IS_VLV(vgt->pdev)) {
+		v_counter_addr = VGT_VLV_PIPE_FRMCOUNT(pipe);
+	} else if (IS_SNB(vgt->pdev) || IS_IVB(vgt->pdev) ||IS_HSW(vgt->pdev)) {
+		v_counter_addr = VGT_PIPE_FRMCOUNT(pipe);
+	}
+
 	phys_pipe = vgt->pipe_mapping[pipe];
 	delta = vgt->frmcount_delta[pipe];
 	if (phys_pipe == I915_MAX_PIPES)
 		__vreg(vgt, v_counter_addr) = delta;
 	else {
-		uint32_t p_counter_addr = VGT_PIPE_FRMCOUNT(phys_pipe);
+
+		if(IS_VLV(vgt->pdev)) {
+			p_counter_addr = VGT_VLV_PIPE_FRMCOUNT(phys_pipe);
+		} else if (IS_SNB(vgt->pdev) || IS_IVB(vgt->pdev) ||IS_HSW(vgt->pdev)) {
+			p_counter_addr = VGT_PIPE_FRMCOUNT(phys_pipe);
+		}
+
+
 		count = VGT_MMIO_READ(vgt->pdev, p_counter_addr);
 		if (count <= 0xffffffff - delta) {
 			__vreg(vgt, v_counter_addr) = count + delta;
@@ -798,9 +963,16 @@ void vgt_calculate_frmcount_delta(struct vgt_device *vgt,
 	enum vgt_pipe pipe)
 {
 	uint32_t delta;
-	uint32_t virt_counter = __vreg(vgt, VGT_PIPE_FRMCOUNT(pipe));
+	uint32_t virt_counter=0;
 	enum vgt_pipe phys_pipe = vgt->pipe_mapping[pipe];
-	uint32_t hw_counter;
+	uint32_t hw_counter=0;
+
+
+	if(IS_VLV(vgt->pdev)) {
+		virt_counter = __vreg(vgt, VGT_VLV_PIPE_FRMCOUNT(pipe));
+	} else if (IS_SNB(vgt->pdev) || IS_IVB(vgt->pdev) ||IS_HSW(vgt->pdev)) {
+		virt_counter = __vreg(vgt, VGT_PIPE_FRMCOUNT(pipe));
+	}
 
 	/* if physical pipe is not enabled yet, Delta will be used
 	 * as the frmcount. When physical pipe is enabled, new delta
@@ -809,8 +981,12 @@ void vgt_calculate_frmcount_delta(struct vgt_device *vgt,
 	if (phys_pipe == I915_MAX_PIPES) {
 		vgt->frmcount_delta[pipe] = virt_counter;
 	} else {
-		hw_counter = VGT_MMIO_READ(vgt->pdev,
-					VGT_PIPE_FRMCOUNT(pipe));
+		if(IS_VLV(vgt->pdev)) {
+			hw_counter = VGT_MMIO_READ(vgt->pdev, VGT_VLV_PIPE_FRMCOUNT(pipe));
+		} else if (IS_SNB(vgt->pdev) || IS_IVB(vgt->pdev) ||IS_HSW(vgt->pdev)) {
+			hw_counter = VGT_MMIO_READ(vgt->pdev, VGT_PIPE_FRMCOUNT(pipe));
+		}
+
 		if (virt_counter >= hw_counter)
 			delta = virt_counter - hw_counter;
 		else {
@@ -821,6 +997,9 @@ void vgt_calculate_frmcount_delta(struct vgt_device *vgt,
 	}
 }
 
+/* TO-DO : This function has not been updated for Baytrail
+ * This function is only used under the DP/eDP codepath
+ */
 void vgt_set_power_well(struct vgt_device *vgt, bool to_enable)
 {
 	bool is_enabled, enable_requested;
diff --git a/drivers/xen/vgt/edid.c b/drivers/xen/vgt/edid.c
index a1adfe0..6064f5c 100644
--- a/drivers/xen/vgt/edid.c
+++ b/drivers/xen/vgt/edid.c
@@ -37,6 +37,7 @@ typedef enum {
 	VGT_EDID_ERROR = 3,
 } vgt_edid_log_t;
 
+#ifndef NO_DEBUGS
 static const char *vgt_port_name[] = {
 	"CRT",
 	"DP_A",
@@ -47,24 +48,25 @@ static const char *vgt_port_name[] = {
 	"HDMI_C",
 	"HDMI_D"
 };
+#endif
 
 #define EDID_LOG(log, emu, fmt, args...)			\
 	do {							\
-		printk("[VGT_EDID");				\
+		vgt_dbg(VGT_DBG_EDID, "[VGT_EDID");				\
 		if (emu == 0x12345678)				\
-			printk("]");				\
+			vgt_dbg(VGT_DBG_EDID, "]");				\
 		else if (emu)					\
-			printk("-EM]");				\
+			vgt_dbg(VGT_DBG_EDID, "-EM]");				\
 		else						\
-			printk("-HW]");				\
+			vgt_dbg(VGT_DBG_EDID, "-HW]");				\
 		if (log == VGT_EDID_INFO) {			\
-			printk("INFO: ");			\
+			vgt_dbg(VGT_DBG_EDID, "INFO: ");			\
 		} else if (log == VGT_EDID_WARN) {		\
-			printk("WARN: ");			\
+			vgt_dbg(VGT_DBG_EDID, "WARN: ");			\
 		} else if (log == VGT_EDID_ERROR) {		\
-			printk("ERROR: ");			\
+			vgt_dbg(VGT_DBG_EDID, "ERROR: ");			\
 		}						\
-		printk(fmt, ##args);				\
+		vgt_dbg(VGT_DBG_EDID, fmt, ##args);				\
 		if (log == VGT_EDID_ERROR) {			\
 			BUG();					\
 		}						\
@@ -113,6 +115,14 @@ do {									\
 	}								\
 } while(0);
 
+/* Need local variables for gmbus register offsets to handle both HSW and BYT */
+#define DEV_GMBUS0 gmbus_reg0
+#define DEV_GMBUS1 gmbus_reg0+0x4
+#define DEV_GMBUS2 gmbus_reg0+0x8
+#define DEV_GMBUS3 gmbus_reg0+0xc
+#define DEV_GMBUS4 gmbus_reg0+0x10
+#define DEV_GMBUS5 gmbus_reg0+0x20
+
 
 /**************************************************************************
  *
@@ -127,51 +137,58 @@ int vgt_get_phys_edid_from_gmbus(struct pgt_device *pdev,
 	int length;
 	int val;
 	int timeout;
+	int gmbus_reg0=0;
 
 	ASSERT(nr_bytes < _GMBUS_TRANS_MAX_BYTES);
 
-	VGT_MMIO_WRITE(pdev, _REG_PCH_GMBUS0, gmbus_port);
+	if(IS_VLV(pdev)){
+		gmbus_reg0 = _REG_VLV_GMBUS0;
+	} else {
+		gmbus_reg0 = _REG_PCH_GMBUS0;
+	}
+
+	VGT_MMIO_WRITE(pdev, DEV_GMBUS0, gmbus_port);
 	// write addr and offset
-	VGT_MMIO_WRITE(pdev, _REG_PCH_GMBUS3, 0);
-	VGT_MMIO_WRITE(pdev, _REG_PCH_GMBUS1,
+	VGT_MMIO_WRITE(pdev, DEV_GMBUS3, 0);
+	VGT_MMIO_WRITE(pdev, DEV_GMBUS1,
 			_GMBUS_SW_RDY |
 			_GMBUS_CYCLE_WAIT |
 			(1 << _GMBUS_BYTE_COUNT_SHIFT) |
 			(EDID_ADDR << _GMBUS_SLAVE_ADDR_SHIFT) |
 			_GMBUS_SLAVE_WRITE);
-	(void)VGT_MMIO_READ(pdev, _REG_PCH_GMBUS2);
+	(void)VGT_MMIO_READ(pdev, DEV_GMBUS2);
 
-	EDID_REPEAT_UNTIL(((val = VGT_MMIO_READ(pdev, _REG_PCH_GMBUS2))
+	EDID_REPEAT_UNTIL(((val = VGT_MMIO_READ(pdev, DEV_GMBUS2))
 				& (_GMBUS_NAK | _GMBUS_HW_WAIT)), 5, 10, timeout);
 
 	if (timeout || (val & _GMBUS_NAK)) {
-		VGT_MMIO_WRITE(pdev, _REG_PCH_GMBUS1, _GMBUS_SW_CLR_INT);
-		VGT_MMIO_WRITE(pdev, _REG_PCH_GMBUS1, 0);
+		VGT_MMIO_WRITE(pdev, DEV_GMBUS1, _GMBUS_SW_CLR_INT);
+		VGT_MMIO_WRITE(pdev, DEV_GMBUS1, 0);
 		return -EIO;
 	}
 
 	/* start read */
-	VGT_MMIO_WRITE(pdev, _REG_PCH_GMBUS1,
+	VGT_MMIO_WRITE(pdev, DEV_GMBUS1,
 			_GMBUS_SW_RDY |
 			_GMBUS_CYCLE_STOP | _GMBUS_CYCLE_WAIT |
 			(nr_bytes << _GMBUS_BYTE_COUNT_SHIFT) |
 			(slave_addr << _GMBUS_SLAVE_ADDR_SHIFT) |
 			_GMBUS_SLAVE_READ);
-	(void)VGT_MMIO_READ(pdev, _REG_PCH_GMBUS2);
+	(void)VGT_MMIO_READ(pdev, DEV_GMBUS2);
 
 	length = 0;
 	do {
 		int j = 0;
-		EDID_REPEAT_UNTIL(((val = VGT_MMIO_READ(pdev, _REG_PCH_GMBUS2))
+		EDID_REPEAT_UNTIL(((val = VGT_MMIO_READ(pdev, DEV_GMBUS2))
 					& (_GMBUS_NAK | _GMBUS_HW_RDY)), 5, 10, timeout);
 		if (timeout || (val & _GMBUS_NAK)) {
-			VGT_MMIO_WRITE(pdev, _REG_PCH_GMBUS1, _GMBUS_SW_CLR_INT);
-			VGT_MMIO_WRITE(pdev, _REG_PCH_GMBUS1, 0);
+			VGT_MMIO_WRITE(pdev, DEV_GMBUS1, _GMBUS_SW_CLR_INT);
+			VGT_MMIO_WRITE(pdev, DEV_GMBUS1, 0);
 			return -EIO;
 			break;
 		}
 
-		val = VGT_MMIO_READ(pdev, _REG_PCH_GMBUS3);
+		val = VGT_MMIO_READ(pdev, DEV_GMBUS3);
 		for (j = 0; j < 4; ++ j) {
 			buf[length] = (val) & 0xff;
 			length ++;
@@ -180,19 +197,20 @@ int vgt_get_phys_edid_from_gmbus(struct pgt_device *pdev,
 	} while (length < nr_bytes);
 
 	/* finish reading. Check the hw state and disable gmbus. */
-	EDID_REPEAT_UNTIL((((val = VGT_MMIO_READ(pdev, _REG_PCH_GMBUS2))
+	EDID_REPEAT_UNTIL((((val = VGT_MMIO_READ(pdev, DEV_GMBUS2))
 					& _GMBUS_ACTIVE) == 0), 5, 10, timeout);
 	if (timeout) {
-		printk("vGT: timeout while waiting for gmbus to be inactive. Will force close.\n");
+		vgt_dbg(VGT_DBG_EDID, "vGT: timeout while waiting for gmbus to be inactive. Will force close.\n");
 		return -EIO;
 	}
-	VGT_MMIO_WRITE(pdev, _REG_PCH_GMBUS0, 0);
+	VGT_MMIO_WRITE(pdev, DEV_GMBUS0, 0);
 
 	return 0;
 
 }
 
 /* code logic copied from i915: intel_ddi.c */
+/* TO-DO ALANPREVIN - havent ported DP/eDP to Baytrail yet! */
 static inline int vgt_get_aux_clock_divider(struct pgt_device *pdev,
 						unsigned int aux_ctrl_addr)
 {
@@ -216,6 +234,7 @@ static inline int vgt_get_aux_clock_divider(struct pgt_device *pdev,
 	return ((clk_freq + 1) / 2);
 }
 
+/* TO-DO ALANPREVIN - havent ported DP/eDP to Baytrail yet! */
 static unsigned int vgt_aux_ch_transaction(struct pgt_device *pdev,
 				unsigned int aux_ctrl_addr,
 				unsigned char *msg, int msg_size)
@@ -228,6 +247,13 @@ static unsigned int vgt_aux_ch_transaction(struct pgt_device *pdev,
 	unsigned int aux_data_addr = aux_ctrl_addr + 4;
 	int aux_clock_divider = vgt_get_aux_clock_divider(pdev, aux_ctrl_addr);
 
+
+	if(IS_VLV(pdev)){
+		/* whenever skipping VLV port, ensure we bail functions if register
+		 * write occur - else we wont know where those writes end up */
+		return 0;
+	}
+
 	if (_is_sandybridge(pdev->pdev->device)) {
 		precharge = 3;
 	} else {
@@ -378,7 +404,11 @@ void vgt_probe_edid(struct pgt_device *pdev, int index, bool init)
 	if (drm_dev)
 		mutex_lock(&drm_dev->mode_config.mutex);
 
-	VGT_MMIO_WRITE(pdev, _REG_PCH_GMBUS0, 0);
+	if (IS_VLV(pdev)){
+		VGT_MMIO_WRITE(pdev, _REG_VLV_GMBUS0, 0);
+	} else if (IS_SNB(pdev) || IS_IVB(pdev) ||IS_HSW(pdev)) {
+		VGT_MMIO_WRITE(pdev, _REG_PCH_GMBUS0, 0);
+	}
 
 	for (i = 0; i < VGT_PORT_MAX; ++ i) {
 		int gmbus_port = 0;
@@ -549,11 +579,19 @@ void vgt_probe_edid(struct pgt_device *pdev, int index, bool init)
 /*
  * Get physical DPCD data from DP. DP is specified by index parameter.
  */
+/* TO-DO ALANPREVIN - havent ported DP/eDP to Baytrail yet! */
 void vgt_probe_dpcd(struct pgt_device *pdev, int index, bool init)
 {
 	int i;
 	struct drm_device *drm_dev = pci_get_drvdata(pdev->pdev);
 
+	/* whenever skipping VLV port, ensure we bail functions if register
+	 * write occur - else we wont know where those writes end up */
+	if (IS_VLV(pdev)){
+		vgt_warn("vgt_probe_dpcd disabled on VLV\n");
+		return;
+	}
+
 	if (drm_dev)
 		mutex_lock(&drm_dev->mode_config.mutex);
 
@@ -950,13 +988,20 @@ static bool vgt_gmbus0_mmio_write(struct vgt_device *vgt, unsigned int offset, v
 	vgt_edid_data_t *edid_data = NULL;
 	vgt_reg_t wvalue = *(vgt_reg_t *)p_data;
 	struct gt_port *port = NULL;
+	int gmbus_reg0=0;
+
+	if(IS_VLV(vgt->pdev)) {
+		gmbus_reg0 = _REG_VLV_GMBUS0;
+	} else if (IS_SNB(vgt->pdev) || IS_IVB(vgt->pdev) ||IS_HSW(vgt->pdev)) {
+		gmbus_reg0 = _REG_PCH_GMBUS0;
+	}
 
 	switch (wvalue & _GMBUS_PIN_SEL_MASK) {
 	case 0: /* disabled. Be treated as reset */
 		edid_data = NULL;
 		break;
 	case 1: /* LCTRCLK */
-		printk("vGT(%d): WARNING: Accessing LCTRCLK which is not supported!\n",
+		vgt_dbg(VGT_DBG_EDID, "vGT(%d): WARNING: Accessing LCTRCLK which is not supported!\n",
 			vgt->vgt_id);
 		break;
 	case 2: /* Analog Mon */
@@ -972,10 +1017,10 @@ static bool vgt_gmbus0_mmio_write(struct vgt_device *vgt, unsigned int offset, v
 		port = &vgt->ports[port_type_to_port(VGT_HDMI_D)];
 		break;
 	case 7:
-		printk("vGT(%d): WARNING: GMBUS accessing reserved port!!!!\n", vgt->vgt_id);
+		vgt_warn("vGT(%d): WARNING: GMBUS accessing reserved port!!!!\n", vgt->vgt_id);
 		break;
 	default:
-		printk("vGT(%d): EDID unknown ERROR!\n", vgt->vgt_id);
+		vgt_err("vGT(%d): EDID unknown ERROR!\n", vgt->vgt_id);
 	}
 
 	if (port) 
@@ -987,13 +1032,13 @@ static bool vgt_gmbus0_mmio_write(struct vgt_device *vgt, unsigned int offset, v
 
 	/* Initialize status reg
 	 * FIXME: never clear _GMBUS_HW_WAIT */
-	__vreg(vgt, _REG_PCH_GMBUS2) &= ~ _GMBUS_ACTIVE;
-	__vreg(vgt, _REG_PCH_GMBUS2) |= _GMBUS_HW_RDY | _GMBUS_HW_WAIT;
+	__vreg(vgt, DEV_GMBUS2) &= ~ _GMBUS_ACTIVE;
+	__vreg(vgt, DEV_GMBUS2) |= _GMBUS_HW_RDY | _GMBUS_HW_WAIT;
 	if (edid_data && edid_data->data_valid && !(port->dpcd && port->dpcd->data_valid)) {
-		__vreg(vgt, _REG_PCH_GMBUS2) &= ~_GMBUS_NAK;
+		__vreg(vgt, DEV_GMBUS2) &= ~_GMBUS_NAK;
 		vgt->vgt_i2c_bus.gmbus.pedid = edid_data;
 	} else
-		__vreg(vgt, _REG_PCH_GMBUS2) |= _GMBUS_NAK;
+		__vreg(vgt, DEV_GMBUS2) |= _GMBUS_NAK;
 
 	memcpy(p_data, (char *)vgt->state.vReg + offset, bytes);
 	return true;
@@ -1002,16 +1047,23 @@ static bool vgt_gmbus0_mmio_write(struct vgt_device *vgt, unsigned int offset, v
 /* TODO: */
 void vgt_reset_gmbus_controller(struct vgt_device *vgt)
 {
+	int gmbus_reg0=0;
+	if(IS_VLV(vgt->pdev)) {
+		gmbus_reg0 = _REG_VLV_GMBUS0;
+	} else if (IS_SNB(vgt->pdev) || IS_IVB(vgt->pdev) ||IS_HSW(vgt->pdev)) {
+		gmbus_reg0 = _REG_PCH_GMBUS0;
+	}
+
 	/* TODO: clear gmbus0 ? */
-	//__vreg(vgt, _REG_PCH_GMBUS0) = 0;
-	//__vreg(vgt, _REG_PCH_GMBUS1) = 0;
-	__vreg(vgt, _REG_PCH_GMBUS2) = _GMBUS_HW_RDY;
+	//__vreg(vgt, DEV_GMBUS0) = 0;
+	//__vreg(vgt, DEV_GMBUS1) = 0;
+	__vreg(vgt, DEV_GMBUS2) = _GMBUS_HW_RDY;
 	if (!vgt->vgt_i2c_bus.gmbus.pedid) {
-		__vreg(vgt, _REG_PCH_GMBUS2) |= _GMBUS_NAK;
+		__vreg(vgt, DEV_GMBUS2) |= _GMBUS_NAK;
 	}
-	//__vreg(vgt, _REG_PCH_GMBUS3) = 0;
-	//__vreg(vgt, _REG_PCH_GMBUS4) = 0;
-	//__vreg(vgt, _REG_PCH_GMBUS5) = 0;
+	//__vreg(vgt, DEV_GMBUS3) = 0;
+	//__vreg(vgt, DEV_GMBUS4) = 0;
+	//__vreg(vgt, DEV_GMBUS5) = 0;
 	vgt->vgt_i2c_bus.gmbus.phase = GMBUS_IDLE_PHASE;
 }
 
@@ -1023,6 +1075,14 @@ void *p_data, unsigned int bytes)
 	vgt_i2c_bus_t *i2c_bus = &vgt->vgt_i2c_bus;
 
 	vgt_reg_t wvalue = *(vgt_reg_t *)p_data;
+	int gmbus_reg0=0;
+
+	if(IS_VLV(vgt->pdev)) {
+		gmbus_reg0 = _REG_VLV_GMBUS0;
+	} else if (IS_SNB(vgt->pdev) || IS_IVB(vgt->pdev) ||IS_HSW(vgt->pdev)) {
+		gmbus_reg0 = _REG_PCH_GMBUS0;
+	}
+
 	if (__vreg(vgt, offset) & _GMBUS_SW_CLR_INT) {
 		if (!(wvalue & _GMBUS_SW_CLR_INT)) {
 			__vreg(vgt, offset) &= ~_GMBUS_SW_CLR_INT;
@@ -1036,8 +1096,8 @@ void *p_data, unsigned int bytes)
 		 2) HW_RDY bit asserted
 		 */
 		if (wvalue & _GMBUS_SW_CLR_INT) {
-			__vreg(vgt, _REG_PCH_GMBUS2) &= ~_GMBUS_INT_STAT;
-			__vreg(vgt, _REG_PCH_GMBUS2) |= _GMBUS_HW_RDY;
+			__vreg(vgt, DEV_GMBUS2) &= ~_GMBUS_INT_STAT;
+			__vreg(vgt, DEV_GMBUS2) |= _GMBUS_HW_RDY;
 		}
 
 		/* For virtualization, we suppose that HW is always ready,
@@ -1057,7 +1117,7 @@ void *p_data, unsigned int bytes)
 			i2c_bus->edid_slave.edid_data = i2c_bus->gmbus.pedid;
 
 		} else if (slave_addr != 0) {
-			vgt_dbg(VGT_DBG_DPY, "vGT(%d): unsupported gmbus slave addr(%x)\n",
+			vgt_dbg(VGT_DBG_EDID, "vGT(%d): unsupported gmbus slave addr(%x)\n",
 					vgt->vgt_id, slave_addr);
 			i2c_bus->current_slave = (vgt_i2c_slave_t *)&i2c_bus->edid_slave;
 			i2c_bus->edid_slave.edid_data = i2c_bus->gmbus.pedid;
@@ -1091,10 +1151,10 @@ void *p_data, unsigned int bytes)
 					i2c_bus->gmbus.phase = GMBUS_IDLE_PHASE;
 					/*
 					FIXME: never clear _GMBUS_WAIT
-					__vreg(vgt, _REG_PCH_GMBUS2) &=
+					__vreg(vgt, DEV_GMBUS2) &=
 						~(_GMBUS_ACTIVE | _GMBUS_HW_WAIT);
 					*/
-					__vreg(vgt, _REG_PCH_GMBUS2) &= ~_GMBUS_ACTIVE;
+					__vreg(vgt, DEV_GMBUS2) &= ~_GMBUS_ACTIVE;
 				}
 				break;
 			case NIDX_NS_W:
@@ -1106,9 +1166,9 @@ void *p_data, unsigned int bytes)
 				 * START (-->INDEX) -->DATA
 				 */
 				i2c_bus->gmbus.phase = GMBUS_DATA_PHASE;
-				__vreg(vgt, _REG_PCH_GMBUS2) |= _GMBUS_ACTIVE;
+				__vreg(vgt, DEV_GMBUS2) |= _GMBUS_ACTIVE;
 				/* FIXME: never clear _GMBUS_WAIT */
-				//__vreg(vgt, _REG_PCH_GMBUS2) &= ~_GMBUS_HW_WAIT;
+				//__vreg(vgt, DEV_GMBUS2) &= ~_GMBUS_HW_WAIT;
 				break;
 			default:
 				vgt_err("Unknown/reserved GMBUS cycle detected!");
@@ -1121,7 +1181,7 @@ void *p_data, unsigned int bytes)
 		 */
 		/* FIXME: never clear _GMBUS_WAIT
 		if (gmbus1_bus_cycle(wvalue) != GMBUS_NOCYCLE)
-			__vreg(vgt, _REG_PCH_GMBUS2) &= ~_GMBUS_HW_WAIT;
+			__vreg(vgt, DEV_GMBUS2) &= ~_GMBUS_HW_WAIT;
 		*/
 
 		__vreg(vgt, offset) = wvalue;
@@ -1145,9 +1205,16 @@ bool vgt_gmbus3_mmio_read(struct vgt_device *vgt, unsigned int offset,
 	int i, byte_count = byte_left;
 	vgt_reg_t reg_data = 0;
 	unsigned char byte_data;
+	int gmbus_reg0=0;
+
+	if(IS_VLV(vgt->pdev)) {
+		gmbus_reg0 = _REG_VLV_GMBUS0;
+	} else if (IS_SNB(vgt->pdev) || IS_IVB(vgt->pdev) ||IS_HSW(vgt->pdev)) {
+		gmbus_reg0 = _REG_PCH_GMBUS0;
+	}
 
 	/* Data can only be recevied if previous settings correct */
-	if (__vreg(vgt, _REG_PCH_GMBUS1) & _GMBUS_SLAVE_READ) {
+	if (__vreg(vgt, DEV_GMBUS1) & _GMBUS_SLAVE_READ) {
 		if (byte_left <= 0) {
 			memcpy((char *)p_data, (char *)vgt->state.vReg + offset, bytes);
 			return true;
@@ -1177,7 +1244,7 @@ bool vgt_gmbus3_mmio_read(struct vgt_device *vgt, unsigned int offset,
 					break;
 			}
 			//if (i2c_bus->gmbus.phase == GMBUS_WAIT_PHASE)
-			//__vreg(vgt, _REG_PCH_GMBUS2) |= _GMBUS_HW_WAIT;
+			//__vreg(vgt, DEV_GMBUS2) |= _GMBUS_HW_WAIT;
 
 			vgt_init_i2c_bus(i2c_bus);
 		}
@@ -1185,7 +1252,7 @@ bool vgt_gmbus3_mmio_read(struct vgt_device *vgt, unsigned int offset,
 		/* Read GMBUS3 during send operation, return the latest written value */
 	} else {
 		memcpy((char *)p_data, (char *)vgt->state.vReg + offset, bytes);
-		printk("vGT(%d): warning: gmbus3 read with nothing retuned\n",
+		vgt_dbg(VGT_DBG_EDID, "vGT(%d): warning: gmbus3 read with nothing retuned\n",
 				vgt->vgt_id);
 	}
 
@@ -1220,8 +1287,10 @@ bool vgt_i2c_handle_gmbus_read(struct vgt_device *vgt, unsigned int offset,
 	ASSERT(bytes <= 8 && !(offset & (bytes - 1)));
 	switch (offset) {
 		case _REG_PCH_GMBUS2:
+		case _REG_VLV_GMBUS2:
 			return vgt_gmbus2_mmio_read(vgt, offset, p_data, bytes);
 		case _REG_PCH_GMBUS3:
+		case _REG_VLV_GMBUS3:
 			return vgt_gmbus3_mmio_read(vgt, offset, p_data, bytes);
 		default:
 			memcpy(p_data, (char *)vgt->state.vReg + offset, bytes);
@@ -1235,13 +1304,17 @@ bool vgt_i2c_handle_gmbus_write(struct vgt_device *vgt, unsigned int offset,
 	ASSERT(bytes <= 8 && !(offset & (bytes - 1)));
 	switch (offset) {
 		case _REG_PCH_GMBUS0:
+		case _REG_VLV_GMBUS0:
 			return vgt_gmbus0_mmio_write(vgt, offset, p_data, bytes);
 		case _REG_PCH_GMBUS1:
+		case _REG_VLV_GMBUS1:
 			return vgt_gmbus1_mmio_write(vgt, offset, p_data, bytes);
 		case _REG_PCH_GMBUS2:
+		case _REG_VLV_GMBUS2:
 			return vgt_gmbus2_mmio_write(vgt, offset, p_data, bytes);
 		/* TODO: */
 		case _REG_PCH_GMBUS3:
+		case _REG_VLV_GMBUS3:
 			BUG();
 			return false;
 		default:
diff --git a/drivers/xen/vgt/fb_decoder.c b/drivers/xen/vgt/fb_decoder.c
index 364dfa2..40be0d1 100644
--- a/drivers/xen/vgt/fb_decoder.c
+++ b/drivers/xen/vgt/fb_decoder.c
@@ -43,9 +43,11 @@ static struct pixel_format hsw_pixel_formats[FORMAT_NUM] = {
 	[0b0010]  = {DRM_FORMAT_C8, 8, "8-bit Indexed"},
 	[0b0101]  = {DRM_FORMAT_RGB565, 16, "16-bit BGRX (5:6:5 MSB-R:G:B)"},
 	[0b0110]  = {DRM_FORMAT_XRGB8888, 32, "32-bit BGRX (8:8:8:8 MSB-X:R:G:B)"},
+	[0b0111]  = {DRM_FORMAT_ARGB8888, 32, "32-bit BGRA (8:8:8:8 MSB-A:R:G:B)"},
 	[0b1000]  = {DRM_FORMAT_XBGR2101010, 32, "32-bit RGBX (2:10:10:10 MSB-X:B:G:R)"},
 	[0b1010] = {DRM_FORMAT_XRGB2101010, 32, "32-bit BGRX (2:10:10:10 MSB-X:R:G:B)"},
 	[0b1110] = {DRM_FORMAT_XBGR8888, 32, "32-bit RGBX (8:8:8:8 MSB-X:B:G:R)"},
+	[0b1111] = {DRM_FORMAT_ABGR8888, 32, "32-bit RGBA (8:8:8:8 MSB-X:B:G:R)"},
 };
 
 int vgt_decode_primary_plane_format(struct vgt_device *vgt,
@@ -54,6 +56,7 @@ int vgt_decode_primary_plane_format(struct vgt_device *vgt,
 	u32	val, fmt;
 
 	val = __vreg(vgt, VGT_DSPCNTR(pipe));
+	if(IS_VLV(vgt->pdev)) val = __vreg(vgt, VGT_VLV_DSPCNTR(pipe));
 	plane->enabled = !!(val & _PRI_PLANE_ENABLE);
 	if (!plane->enabled)
 		return 0;
@@ -70,16 +73,22 @@ int vgt_decode_primary_plane_format(struct vgt_device *vgt,
 	plane->drm_format = hsw_pixel_formats[fmt].drm_format;
 
 	plane->base = __vreg(vgt, VGT_DSPSURF(pipe)) & GTT_PAGE_MASK;
+	if(IS_VLV(vgt->pdev)) plane->base = __vreg(vgt, VGT_VLV_DSPSURF(pipe)) & GTT_PAGE_MASK;
 	plane->stride = __vreg(vgt, VGT_DSPSTRIDE(pipe)) &
 				_PRI_PLANE_STRIDE_MASK;
+	if(IS_VLV(vgt->pdev)) plane->stride = __vreg(vgt, VGT_VLV_DSPSTRIDE(pipe)) & _PRI_PLANE_STRIDE_MASK;
 	plane->width = (__vreg(vgt, VGT_PIPESRC(pipe)) & _PIPE_H_SRCSZ_MASK) >>
 				_PIPE_H_SRCSZ_SHIFT;
+	if(IS_VLV(vgt->pdev)) plane->width = (__vreg(vgt, VGT_VLV_PIPESRC(pipe)) & _PIPE_H_SRCSZ_MASK) >> _PIPE_H_SRCSZ_SHIFT;
 	plane->width += 1;
 	plane->height = (__vreg(vgt, VGT_PIPESRC(pipe)) &
 			 _PIPE_V_SRCSZ_MASK) >> _PIPE_V_SRCSZ_SHIFT;
+	if(IS_VLV(vgt->pdev)) plane->height = (__vreg(vgt, VGT_VLV_PIPESRC(pipe)) & _PIPE_V_SRCSZ_MASK) >> _PIPE_V_SRCSZ_SHIFT;
+
 	plane->height += 1;	/* raw height is one minus the real value */
 
 	val = __vreg(vgt, VGT_DSPTILEOFF(pipe));
+	if(IS_VLV(vgt->pdev)) val = __vreg(vgt, VGT_VLV_DSPTILEOFF(pipe));
 	plane->x_offset = (val & _PRI_PLANE_X_OFF_MASK) >>
 			   _PRI_PLANE_X_OFF_SHIFT;
 	plane->y_offset = (val & _PRI_PLANE_Y_OFF_MASK) >>
@@ -110,6 +119,7 @@ int vgt_decode_cursor_plane_format(struct vgt_device *vgt,
 	u32 alpha_plane, alpha_force;
 
 	val = __vreg(vgt, VGT_CURCNTR(pipe));
+	if(IS_VLV(vgt->pdev)) val = __vreg(vgt, VGT_VLV_CURCNTR(pipe));
 	mode = val & _CURSOR_MODE;
 	plane->enabled = (mode != _CURSOR_MODE_DISABLE);
 	if (!plane->enabled)
@@ -134,8 +144,10 @@ int vgt_decode_cursor_plane_format(struct vgt_device *vgt,
 			alpha_plane, alpha_force);
 
 	plane->base = __vreg(vgt, VGT_CURBASE(pipe)) & GTT_PAGE_MASK;
+	if(IS_VLV(vgt->pdev)) plane->base = __vreg(vgt, VGT_VLV_CURBASE(pipe)) & GTT_PAGE_MASK;
 
 	val = __vreg(vgt, VGT_CURPOS(pipe));
+	if(IS_VLV(vgt->pdev)) val = __vreg(vgt, VGT_VLV_CURPOS(pipe));
 	plane->x_pos = (val & _CURSOR_POS_X_MASK) >> _CURSOR_POS_X_SHIFT;
 	plane->x_sign = (val & _CURSOR_SIGN_X_MASK) >> _CURSOR_SIGN_X_SHIFT;
 	plane->y_pos = (val & _CURSOR_POS_Y_MASK) >> _CURSOR_POS_Y_SHIFT;
@@ -159,6 +171,12 @@ static struct pixel_format hsw_pixel_formats_sprite[FORMAT_NUM_SRRITE] = {
 	[0b010]  = {DRM_FORMAT_XRGB8888, 32, "RGB 32-bit 8:8:8:8"},
 	[0b100] = {DRM_FORMAT_AYUV, 32, "YUV 32-bit 4:4:4 packed (8:8:8:8 MSB-X:Y:U:V)"},
 };
+static struct pixel_format vlv_pixel_formats_sprite[FORMAT_NUM_SRRITE] = {
+	[0b000]  = {DRM_FORMAT_YUV422, 16, "YUV 16-bit 4:2:2 packed"},
+	[0b101]  = {DRM_FORMAT_RGB565, 16, "RGB 16-bit 5:6:5"},
+	[0b110]  = {DRM_FORMAT_XRGB8888, 32, "XRGB 32-bit 8:8:8:8"},
+	[0b111]  = {DRM_FORMAT_ARGB8888, 32, "ARGB 32-bit 8:8:8:8"},
+};
 
 /* Non-supported format has bpp default to 0 */
 int vgt_decode_sprite_plane_format(struct vgt_device *vgt,
@@ -168,8 +186,10 @@ int vgt_decode_sprite_plane_format(struct vgt_device *vgt,
 	u32 width;
 	u32 color_order, yuv_order;
 	int drm_format;
+	struct pixel_format * fmt_info;
 
 	val = __vreg(vgt, VGT_SPRCTL(pipe));
+	if(IS_VLV(vgt->pdev)) val = __vreg(vgt, VGT_VLV_SPRCTL(pipe));
 	plane->enabled = !!(val & _SPRITE_ENABLE);
 	if (!plane->enabled)
 		return 0;
@@ -180,13 +200,26 @@ int vgt_decode_sprite_plane_format(struct vgt_device *vgt,
 				_SPRITE_YUV_ORDER_SHIFT;
 
 	fmt = (val & _SPRITE_FMT_MASK) >> _SPRITE_FMT_SHIFT;
-	if (!hsw_pixel_formats_sprite[fmt].bpp) {
-		vgt_err("Non-supported pixel format (0x%x)\n", fmt);
-		return -EINVAL;
+	if(IS_VLV(vgt->pdev)) fmt = (val & _SPRITE_FMT_MASK) >> _VLV_SPRITE_FMT_SHIFT;
+	/* VLV has more format bits, but the MSB includes only unpopular formats we exclude */
+
+	if(IS_VLV(vgt->pdev)){
+		if (!vlv_pixel_formats_sprite[fmt].bpp) {
+			vgt_err("Non-supported pixel format (0x%x)\n", fmt);
+			return -EINVAL;
+		}
+		fmt_info = &vlv_pixel_formats_sprite[fmt];
+
+	} else {
+		if (!hsw_pixel_formats_sprite[fmt].bpp) {
+			vgt_err("Non-supported pixel format (0x%x)\n", fmt);
+			return -EINVAL;
+		}
+		fmt_info = &hsw_pixel_formats_sprite[fmt];
 	}
 	plane->hw_format = fmt;
-	plane->bpp = hsw_pixel_formats_sprite[fmt].bpp;
-	drm_format = hsw_pixel_formats_sprite[fmt].drm_format;
+	plane->bpp = fmt_info->bpp;
+	drm_format = fmt_info->drm_format;
 
 	/* Order of RGB values in an RGBxxx buffer may be ordered RGB or
 	 * BGR depending on the state of the color_order field
@@ -222,11 +255,14 @@ int vgt_decode_sprite_plane_format(struct vgt_device *vgt,
 	plane->drm_format = drm_format;
 
 	plane->base = __vreg(vgt, VGT_SPRSURF(pipe)) & GTT_PAGE_MASK;
+	if(IS_VLV(vgt->pdev)) plane->base = __vreg(vgt, VGT_VLV_SPRSURF(pipe)) & GTT_PAGE_MASK;
 	plane->width = __vreg(vgt, VGT_SPRSTRIDE(pipe)) &
 				_SPRITE_STRIDE_MASK;
+	if(IS_VLV(vgt->pdev)) plane->width = __vreg(vgt, VGT_VLV_SPRSTRIDE(pipe)) & _VLV_SPRITE_STRIDE_MASK;
 	plane->width /= plane->bpp / 8;	/* raw width in bytes */
 
 	val = __vreg(vgt, VGT_SPRSIZE(pipe));
+	if(IS_VLV(vgt->pdev)) val = __vreg(vgt, VGT_VLV_SPRSIZE(pipe));
 	plane->height = (val & _SPRITE_SIZE_HEIGHT_MASK) >>
 		_SPRITE_SIZE_HEIGHT_SHIFT;
 	width = (val & _SPRITE_SIZE_WIDTH_MASK) >> _SPRITE_SIZE_WIDTH_SHIFT;
@@ -237,10 +273,12 @@ int vgt_decode_sprite_plane_format(struct vgt_device *vgt,
 			plane->width, width);
 
 	val = __vreg(vgt, VGT_SPRPOS(pipe));
+	if(IS_VLV(vgt->pdev)) val = __vreg(vgt, VGT_VLV_SPRPOS(pipe));
 	plane->x_pos = (val & _SPRITE_POS_X_MASK) >> _SPRITE_POS_X_SHIFT;
 	plane->y_pos = (val & _SPRITE_POS_Y_MASK) >> _SPRITE_POS_Y_SHIFT;
 
 	val = __vreg(vgt, VGT_SPROFFSET(pipe));
+	if(IS_VLV(vgt->pdev)) val = __vreg(vgt, VGT_VLV_SPROFFSET(pipe));
 	plane->x_offset = (val & _SPRITE_OFFSET_START_X_MASK) >>
 			   _SPRITE_OFFSET_START_X_SHIFT;
 	plane->y_offset = (val & _SPRITE_OFFSET_START_Y_MASK) >>
@@ -316,6 +354,9 @@ static void vgt_dump_sprite_plane_format(struct dump_buffer *buf,
 	dump_string(buf, "  drm_format: 0x%08x: %s\n",
 		plane->drm_format,
 		hsw_pixel_formats_sprite[plane->hw_format].desc);
+	dump_string(buf, "  VLV drm_format: 0x%08x: %s\n",
+		plane->drm_format,
+		vlv_pixel_formats_sprite[plane->hw_format].desc);
 	dump_string(buf, "  base: 0x%x\n", plane->base);
 	dump_string(buf, "  x-off: %d\n", plane->x_offset);
 	dump_string(buf, "  y-off: %d\n", plane->y_offset);
@@ -399,8 +440,8 @@ int vgt_decode_fb_format(int vmid, struct vgt_fb_format *fb)
 	if (!fb)
 		return -EINVAL;
 
-	if (!IS_HSW(pdev)) {
-		vgt_err("Only HSW is supported now\n");
+	if (! (IS_HSW(pdev) || IS_IVB(pdev) || IS_VLV(pdev))) {
+		vgt_err("Only HSW / VLV / IVB is supported now\n");
 		return -EINVAL;
 	}
 
@@ -416,17 +457,47 @@ int vgt_decode_fb_format(int vmid, struct vgt_fb_format *fb)
 
 	for (i = 0; i < MAX_INTEL_PIPES; i++) {
 		struct vgt_pipe_format *pipe = &fb->pipes[i];
-		vgt_reg_t ddi_func_ctl = __vreg(vgt, _VGT_TRANS_DDI_FUNC_CTL(i));
 
-		if (!(ddi_func_ctl & _TRANS_DDI_PORT_SHIFT)) {
+		if(IS_VLV(pdev)) {
+			int j;
+			/* The intention if to find the active port for each pipe */
+			if(((int)PORT_B != (int)DDI_PORT_B) &&
+				((int)PORT_C != (int)DDI_PORT_C) &&
+				((int)PORT_E != (int)DDI_PORT_E)) {
+				vgt_err("No mapping between DDI_PORT_X in include and PORT_X in vgt!\n");
+			}
+			if(((int)PIPE_A != 0) && ((int)PIPE_B != 1)) {
+				vgt_err("No mapping between PIPE_A and zero-index!\n");
+			}
 			pipe->ddi_port = DDI_PORT_NONE;
+			for(j=(int)PORT_B; j<(int)I915_MAX_PORTS; ++j){
+				/* Cant start with PORT_A, XenGT headers dont support that for "get_pipe_from_port" */
+				switch(vgt_get_pipe_from_port(vgt, (enum vgt_port)j)){
+					case PIPE_A:
+						if( ((int)i == (int)PIPE_A) && pipe->ddi_port == DDI_PORT_NONE)
+							pipe->ddi_port = (ddi_port_t)j;
+						break;
+					case PIPE_B:
+						if( ((int)i == (int)PIPE_B) && pipe->ddi_port == DDI_PORT_NONE)
+							pipe->ddi_port = (ddi_port_t)j;
+						break;
+					default:
+						break;
+				}
+			}
+
 		} else {
-			vgt_reg_t port = (ddi_func_ctl & _REGBIT_TRANS_DDI_PORT_MASK) >>
-						_TRANS_DDI_PORT_SHIFT;
-			if ((port >= DDI_PORT_NONE) || (port <= DDI_PORT_E))
-				pipe->ddi_port = port;
-			else
+			vgt_reg_t ddi_func_ctl = __vreg(vgt, _VGT_TRANS_DDI_FUNC_CTL(i));
+			if (!(ddi_func_ctl & _TRANS_DDI_PORT_SHIFT)) {
 				pipe->ddi_port = DDI_PORT_NONE;
+			} else {
+				vgt_reg_t port = (ddi_func_ctl & _REGBIT_TRANS_DDI_PORT_MASK) >>
+							_TRANS_DDI_PORT_SHIFT;
+				if ((port >= DDI_PORT_NONE) || (port <= DDI_PORT_E))
+					pipe->ddi_port = port;
+				else
+					pipe->ddi_port = DDI_PORT_NONE;
+			}
 		}
 
 		ret |= vgt_decode_primary_plane_format(vgt, i, &pipe->primary);
diff --git a/drivers/xen/vgt/gtt.c b/drivers/xen/vgt/gtt.c
index 2bc6f20..a068576 100644
--- a/drivers/xen/vgt/gtt.c
+++ b/drivers/xen/vgt/gtt.c
@@ -36,7 +36,7 @@ unsigned long gtt_pte_get_pfn(struct pgt_device *pdev, u32 pte)
 {
 	u64 addr = 0;
 
-	if (IS_SNB(pdev) || IS_IVB(pdev))
+	if (IS_VLV(pdev) || IS_SNB(pdev) || IS_IVB(pdev))
 		addr = (((u64)pte & 0xff0) << 28) | (u64)(pte & 0xfffff000);
 	else if (IS_HSW(pdev))
 		addr = (((u64)pte & 0x7f0) << 28) | (u64)(pte & 0xfffff000);
@@ -49,7 +49,7 @@ static u32 gtt_pte_update(struct pgt_device *pdev, unsigned long pfn, u32 old_pt
 	u64 addr = pfn << GTT_PAGE_SHIFT;
 	u32 pte, addr_mask = 0, ctl_mask = 0;
 
-	if (IS_SNB(pdev) || IS_IVB(pdev)) {
+	if (IS_VLV(pdev) || IS_SNB(pdev) || IS_IVB(pdev)) {
 		addr_mask = 0xff0;
 		ctl_mask = _REGBIT_PTE_CTL_MASK_GEN7;
 	} else if (IS_HSW(pdev)) {
@@ -324,12 +324,12 @@ vgt_ppgtt_pde_handle(struct vgt_device *vgt, unsigned int i, u32 pde)
 	dma_addr_t pte_phy;
 
 	if (!(pde & _REGBIT_PDE_VALID)) {
-		printk("vGT(%d): PDE %d not valid!\n", vgt->vgt_id, i);
+		vgt_dbg(VGT_DBG_MEM, "vGT(%d): PDE %d not valid!\n", vgt->vgt_id, i);
 		return;
 	}
 
 	if ((pde & _REGBIT_PDE_PAGE_32K)) {
-		printk("vGT(%d): 32K page in PDE!\n", vgt->vgt_id);
+		vgt_dbg(VGT_DBG_MEM, "vGT(%d): 32K page in PDE!\n", vgt->vgt_id);
 		vgt->shadow_pde_table[i].big_page = true;
 	} else
 		vgt->shadow_pde_table[i].big_page = false;
@@ -414,11 +414,11 @@ static bool gtt_mmio_read32(struct vgt_device *vgt, unsigned int off,
 	} else if (off < vgt->vgtt_sz) {
 		*(uint32_t*)p_data = vgt->vgtt[g_gtt_index];
 	} else {
-		printk("vGT(%d): captured out of range GTT read on "
+		vgt_dbg(VGT_DBG_MEM, "vGT(%d): captured out of range GTT read on "
 		       "off %x\n", vgt->vgt_id, off);
 		return false;
 	}
-	
+
 	return true;
 }
 
@@ -730,7 +730,7 @@ void vgt_try_setup_ppgtt(struct vgt_device *vgt)
 	base = vgt->rb[0].vring_ppgtt_info.base;
 	for (i = 1; i < num; i++) {
 		if (vgt->rb[i].vring_ppgtt_info.base != base) {
-			printk(KERN_WARNING "zhen: different PPGTT base set is not supported now!\n");
+			vgt_warn("when: different PPGTT base set is not supported now!\n");
 			vgt->pdev->enable_ppgtt = 0;
 			return;
 		}
@@ -757,7 +757,7 @@ int ring_ppgtt_mode(struct vgt_device *vgt, int ring_id, u32 off, u32 mode)
 
 	/* sanity check */
 	if ((mode & _REGBIT_PPGTT_ENABLE) && (mode & (_REGBIT_PPGTT_ENABLE << 16))) {
-		printk("PPGTT enabling on ring %d\n", ring_id);
+		vgt_dbg(VGT_DBG_MEM, "PPGTT enabling on ring %d\n", ring_id);
 		/* XXX the order of mode enable for PPGTT and PPGTT dir base
 		 * setting is not strictly defined, e.g linux driver first
 		 * enables PPGTT bit in mode reg, then write PP dir base...
diff --git a/drivers/xen/vgt/handlers.c b/drivers/xen/vgt/handlers.c
index 738840a..57a0f3dd3 100644
--- a/drivers/xen/vgt/handlers.c
+++ b/drivers/xen/vgt/handlers.c
@@ -66,7 +66,7 @@ static bool fence_mmio_read(struct vgt_device *vgt, unsigned int off,
 	id = (off - _REG_FENCE_0_LOW) >> 3;
 
 	if (id >= vgt->fence_sz) {
-		printk("vGT(%d) , read fence register %x,"
+		vgt_dbg(VGT_DBG_MEM, "vGT(%d) , read fence register %x,"
 			" %x out of assignment %x.\n", vgt->vgt_id,
 			off, id, vgt->fence_sz);
 	}
@@ -82,7 +82,7 @@ static bool fence_mmio_write(struct vgt_device *vgt, unsigned int off,
 	id = (off - _REG_FENCE_0_LOW) >> 3;
 
 	if (id >= vgt->fence_sz) {
-		printk("vGT (%d) , write fence register %x,"
+		vgt_dbg(VGT_DBG_MEM, "vGT (%d) , write fence register %x,"
 			" %x out of assignment %x.\n", vgt->vgt_id,
 			off, id, vgt->fence_sz);
 	}
@@ -135,7 +135,7 @@ static void v_force_wake_get(struct vgt_device *vgt)
 	if (bitmap_empty(vgt->pdev->v_force_wake_bitmap, VGT_MAX_VMS)){
 		rc = hcall_vgt_ctrl(VGT_CTRL_FORCEWAKE_GET);
 		if (rc < 0){
-			printk("incompatible hypervisor, consider to update your hypervisor\n");
+			vgt_err("incompatible hypervisor, consider to update your hypervisor\n");
 			BUG();
 		}
 
@@ -162,7 +162,7 @@ static void v_force_wake_put(struct vgt_device *vgt)
 		if (bitmap_empty(vgt->pdev->v_force_wake_bitmap, VGT_MAX_VMS)){
 			rc = hcall_vgt_ctrl(VGT_CTRL_FORCEWAKE_PUT);
 			if (rc < 0){
-				printk("incompatible hypervisor, consider to update your hypervisor\n");
+				vgt_err("incompatible hypervisor, consider to update your hypervisor\n");
 				BUG();
 			}
 
@@ -184,11 +184,23 @@ static bool force_wake_write(struct vgt_device *vgt, unsigned int offset,
 
 	if (IS_HSW(vgt->pdev)) {
 		__vreg(vgt, _REG_FORCEWAKE_ACK_HSW) = data;
+	} else if (IS_VLV(vgt->pdev)) {
+		if(offset == _REG_VLV_FORCEWAKE)
+			__vreg(vgt, _REG_VLV_FORCEWAKE_ACK) = data;
+		else
+			__vreg(vgt, _REG_VLV_FORCEWAKE_MEDIA_ACK) = data;
 	} else {
 		__vreg(vgt, _REG_FORCEWAKE_ACK) = data;
 	}
 
-	__vreg(vgt, _REG_FORCEWAKE) = data;
+	if (IS_VLV(vgt->pdev)) {
+		if(offset == _REG_VLV_FORCEWAKE)
+			__vreg(vgt, _REG_VLV_FORCEWAKE) = data;
+		else
+			__vreg(vgt, _REG_VLV_FORCEWAKE_MEDIA) = data;
+	} else {
+		__vreg(vgt, _REG_FORCEWAKE) = data;
+	}
 	if (data == 1){
 		set_vRC_to_C0(vgt);
 		v_force_wake_get(vgt);
@@ -213,6 +225,9 @@ static bool mul_force_wake_write(struct vgt_device *vgt, unsigned int offset,
 {
 	uint32_t data, mask, wake, old_wake, new_wake;
 
+	if(IS_VLV(vgt->pdev))
+		return true;
+
 	data = *(uint32_t*) p_data;
 
 	vgt_dbg(VGT_DBG_GENERIC, "VM%d write register FORCE_WAKE_MT with %x\n", vgt->vm_id, data);
@@ -257,7 +272,7 @@ static bool rc_state_ctrl_1_mmio_write(struct vgt_device *vgt, unsigned int offs
 	uint32_t data;
 
 	data = *(uint32_t*)p_data;
-	printk("VM%d write register RC_STATE_CTRL_1 with 0x%x\n", vgt->vm_id, data);
+	vgt_dbg(VGT_DBG_RENDER, "VM%d write register RC_STATE_CTRL_1 with 0x%x\n", vgt->vm_id, data);
 
 	if ( (data & _REGBIT_RC_HW_CTRL_ENABLE) && (data & (_REGBIT_RC_RC6_ENABLE
 					| _REGBIT_RC_DEEPEST_RC6_ENABLE	| _REGBIT_RC_DEEP_RC6_ENABLE) ) )
@@ -335,7 +350,7 @@ static bool gen6_gdrst_mmio_write(struct vgt_device *vgt, unsigned int offset,
 		ring_bitmap |= (1 << RING_BUFFER_BCS);
 	}
 
-	if (IS_HSW(vgt->pdev) && (data & (1 << 4))) {
+	if (IS_HSW(vgt->pdev) && (data & _REGBIT_GEN6_GRDOM_VECS)) {
 		vgt_info("VM %d request GPU VECS Reset\n", vgt->vm_id);
 		ring_bitmap |= (1 << RING_BUFFER_VECS);
 	}
@@ -404,10 +419,22 @@ static bool pch_pp_control_mmio_write(struct vgt_device *vgt, unsigned int offse
 
 	data = *(uint32_t*)p_data;
 
-	__vreg(vgt, _REG_PCH_PP_CONTROL) = data;
+	if(IS_VLV(vgt->pdev)){
+		if(offset == _REG_VLV_PIPEA_PP_CONTROL) {
+			__vreg(vgt, _REG_VLV_PIPEA_PP_CONTROL) = data;
+			pp_control.data = data;
+			pp_status.data = __vreg(vgt, _REG_VLV_PIPEA_PP_STATUS);
+		} else {
+			__vreg(vgt, _REG_VLV_PIPEB_PP_CONTROL) = data;
+			pp_control.data = data;
+			pp_status.data = __vreg(vgt, _REG_VLV_PIPEB_PP_STATUS);
+		}
+	} else {
+		__vreg(vgt, _REG_PCH_PP_CONTROL) = data;
+		pp_control.data = data;
+		pp_status.data = __vreg(vgt, _REG_PCH_PP_STATUS);
+	}
 
-	pp_control.data = data;
-	pp_status.data = __vreg(vgt, _REG_PCH_PP_STATUS);
 	if (pp_control.power_state_target == 1){
 		/* power on panel */
 		pp_status.panel_powere_on_statue = 1;
@@ -419,7 +446,15 @@ static bool pch_pp_control_mmio_write(struct vgt_device *vgt, unsigned int offse
 		pp_status.power_sequence_progress = 0;
 		pp_status.power_cycle_delay_active = 0;
 	}
-	__vreg(vgt, _REG_PCH_PP_STATUS) = pp_status.data;
+	if(IS_VLV(vgt->pdev)){
+		if(offset == _REG_VLV_PIPEA_PP_CONTROL) {
+			__vreg(vgt, _REG_VLV_PIPEA_PP_STATUS) = pp_status.data;
+		} else {
+			__vreg(vgt, _REG_VLV_PIPEB_PP_STATUS) = pp_status.data;
+		}
+	} else {
+		__vreg(vgt, _REG_PCH_PP_STATUS) = pp_status.data;
+	}
 
 	return true;
 }
@@ -496,6 +531,8 @@ static bool pipe_frmcount_mmio_read(struct vgt_device *vgt, unsigned int offset,
 				p_data, bytes);
 
 	pipe = VGT_FRMCOUNTPIPE(offset);
+	if(IS_VLV(vgt->pdev)) pipe = VGT_VLV_FRMCOUNTPIPE(offset);
+
 	ASSERT(pipe >= PIPE_A && pipe < I915_MAX_PIPES);
 
 	if (vgt_has_pipe_enabled(vgt, pipe))
@@ -651,6 +688,7 @@ static bool ring_pp_mode_write(struct vgt_device *vgt, unsigned int off,
 
 /* FIXME: add EDID virtualization in the future
  */
+/* TODO - this handler function has NOT been updated for Baytrail support */
 static bool dp_aux_ch_ctl_mmio_read(struct vgt_device *vgt, unsigned int offset,
 	void *p_data, unsigned int bytes)
 {
@@ -667,7 +705,7 @@ static bool dp_aux_ch_ctl_mmio_read(struct vgt_device *vgt, unsigned int offset,
 
 	return rc;
 }
-
+/* TODO - this handler function has NOT been updated for Baytrail support */
 static bool dpy_trans_ddi_ctl_write(struct vgt_device *vgt, unsigned int offset,
 	void *p_data, unsigned int bytes)
 {
@@ -734,6 +772,7 @@ vgt_reg_t vgt_surf_base_range_check (struct vgt_device *vgt,
 		vgt_decode_primary_plane_format(vgt, pipe, &primary_plane);
 		if (primary_plane.enabled){
 			reg = VGT_DSPSURF(pipe);
+			if(IS_VLV(vgt->pdev)) reg = VGT_VLV_DSPSURF(pipe);
 			range = primary_plane.stride * primary_plane.height;
 		}
 		break;
@@ -742,6 +781,7 @@ vgt_reg_t vgt_surf_base_range_check (struct vgt_device *vgt,
 		vgt_decode_sprite_plane_format(vgt, pipe, &sprite_plane);
 		if (sprite_plane.enabled){
 			reg = VGT_SPRSURF(pipe);
+			if(IS_VLV(vgt->pdev)) reg = VGT_VLV_SPRSURF(pipe);
 			range = sprite_plane.width* sprite_plane.height*
 					(sprite_plane.bpp / 8);
 		}
@@ -751,6 +791,7 @@ vgt_reg_t vgt_surf_base_range_check (struct vgt_device *vgt,
 		vgt_decode_cursor_plane_format(vgt, pipe, &cursor_plane);
 		if (cursor_plane.enabled) {
 			reg = VGT_CURBASE(pipe);
+			if(IS_VLV(vgt->pdev)) reg = VGT_VLV_CURBASE(pipe);
 			range = cursor_plane.width * cursor_plane.height *
 					(cursor_plane.bpp / 8);
 		}
@@ -803,6 +844,7 @@ static bool pipe_conf_mmio_write(struct vgt_device *vgt, unsigned int offset,
 		}
 	} else {
 		pipe = VGT_PIPECONFPIPE(offset);
+		if(IS_VLV(vgt->pdev)) pipe = VGT_VLV_PIPECONFPIPE(offset);
 		orig_pipe_enabled = vgt_has_pipe_enabled(vgt, pipe);
 		rc = default_mmio_write(vgt, offset, &wr_data, bytes);
 		curr_pipe_enabled = vgt_has_pipe_enabled(vgt, pipe);
@@ -1086,6 +1128,7 @@ static bool pch_adpa_mmio_read(struct vgt_device *vgt, unsigned int offset,
 	if (reg_hw_access(vgt, reg)) {
 
 		adpa_value = VGT_MMIO_READ(vgt->pdev, _REG_PCH_ADPA);
+		if(IS_VLV(vgt->pdev)) adpa_value = VGT_MMIO_READ(vgt->pdev, _REG_VLV_PCH_ADPA);
 
 		/* force trigger bit was fully virtualized. Should always be zero */
 		ASSERT (!(adpa_value & _REGBIT_ADPA_CRT_HOTPLUG_FORCE_TRIGGER));
@@ -1115,7 +1158,12 @@ static bool pch_adpa_mmio_write(struct vgt_device *vgt, unsigned int offset,
 	 * will be fully virtualized. Other bits will be written to hardware.
 	 */
 	if (reg_hw_access(vgt, offset)) {
-		VGT_MMIO_WRITE(pdev, _REG_PCH_ADPA, new &
+		if(IS_VLV(vgt->pdev))
+			VGT_MMIO_WRITE(pdev, _REG_VLV_PCH_ADPA, new &
+				~(_REGBIT_ADPA_CRT_HOTPLUG_MONITOR_MASK |
+				 _REGBIT_ADPA_CRT_HOTPLUG_FORCE_TRIGGER));
+		else
+			VGT_MMIO_WRITE(pdev, _REG_PCH_ADPA, new &
 				~(_REGBIT_ADPA_CRT_HOTPLUG_MONITOR_MASK |
 				 _REGBIT_ADPA_CRT_HOTPLUG_FORCE_TRIGGER));
 	}
@@ -1185,68 +1233,140 @@ bool vgt_map_plane_reg(struct vgt_device *vgt, unsigned int reg, unsigned int *p
 	enum vgt_pipe virtual_pipe;
 	enum vgt_pipe real_pipe ;
 
-	switch (reg)
-	{
-	case _REG_CURABASE:
-	case _REG_CURACNTR:
-	case _REG_CURAPOS:
-	case _REG_DSPACNTR:
-	case _REG_DSPASURF:
-	case _REG_DSPASURFLIVE:
-	case _REG_DSPALINOFF:
-	case _REG_DSPASTRIDE:
-	case _REG_DSPAPOS:
-	case _REG_DSPASIZE:
-	case _REG_DSPATILEOFF:
-	case _REG_SPRASURF:
-	case _REG_SPRA_CTL:
-	case _REG_PIPEASRC:
-		real_pipe = vgt->pipe_mapping[0];
-		virtual_pipe = PIPE_A;
-		break;
+	if(IS_VLV(vgt->pdev)){
+		switch (reg)
+		{
+		case _REG_VLV_CURABASE:
+		case _REG_VLV_CURACNTR:
+		case _REG_VLV_CURAPOS:
+		case _REG_VLV_SPRA_CTL:
+		case _REG_VLV_SPRASURF:
+		case _REG_VLV_SPRASURFLIVE:
+		case _REG_VLV_SPRA_STRIDE:
+		case _REG_VLV_SPRA_SIZE:
+		case _REG_VLV_SPRA_POS:
+		case _REG_VLV_SPRA_OFFSET:
+		case _REG_VLV_SPRB_CTL:
+		case _REG_VLV_SPRBSURF:
+		case _REG_VLV_SPRBSURFLIVE:
+		case _REG_VLV_SPRB_STRIDE:
+		case _REG_VLV_SPRB_SIZE:
+		case _REG_VLV_SPRB_POS:
+		case _REG_VLV_SPRB_OFFSET:
+		case _REG_VLV_DSPACNTR:
+		case _REG_VLV_DSPAASYNCFLIPADDR  :
+		case _REG_VLV_DSPASURF           :
+		case _REG_VLV_DSPASURFLIVE       :
+		case _REG_VLV_DSPALINOFF         :
+		case _REG_VLV_DSPASTRIDE         :
+		case _REG_VLV_DSPATILEOFF        :
+		case _REG_VLV_DSPASIZE:
+		case _REG_VLV_DSPAPOS:
+		case _REG_VLV_PIPEASRC:
+			real_pipe = vgt->pipe_mapping[0];
+			virtual_pipe = PIPE_A;
+			break;
 
-	case _REG_CURBBASE_SNB:
-	case _REG_CURBCNTR_SNB:
-	case _REG_CURBPOS_SNB:
-	case _REG_CURBBASE:
-	case _REG_CURBCNTR:
-	case _REG_CURBPOS:
-	case _REG_DSPBCNTR:
-	case _REG_DSPBSURF:
-	case _REG_DSPBSURFLIVE:
-	case _REG_DSPBLINOFF:
-	case _REG_DSPBSTRIDE:
-	case _REG_DSPBPOS:
-	case _REG_DSPBSIZE:
-	case _REG_DSPBTILEOFF:
-	case _REG_SPRBSURF:
-	case _REG_SPRB_CTL:
-	case _REG_PIPEBSRC:
-		real_pipe = vgt->pipe_mapping[1];
-		virtual_pipe = PIPE_B;
-		break;
+		case _REG_VLV_CURBBASE:
+		case _REG_VLV_CURBCNTR:
+		case _REG_VLV_CURBPOS:
+		case _REG_VLV_SPRC_CTL:
+		case _REG_VLV_SPRCSURF:
+		case _REG_VLV_SPRCSURFLIVE:
+		case _REG_VLV_SPRC_STRIDE:
+		case _REG_VLV_SPRC_SIZE:
+		case _REG_VLV_SPRC_POS:
+		case _REG_VLV_SPRC_OFFSET:
+		case _REG_VLV_SPRD_CTL:
+		case _REG_VLV_SPRDSURF:
+		case _REG_VLV_SPRDSURFLIVE:
+		case _REG_VLV_SPRD_STRIDE:
+		case _REG_VLV_SPRD_SIZE:
+		case _REG_VLV_SPRD_POS:
+		case _REG_VLV_SPRD_OFFSET:
+		case _REG_VLV_DSPBCNTR:
+		case _REG_VLV_DSPBASYNCFLIPADDR  :
+		case _REG_VLV_DSPBSURF           :
+		case _REG_VLV_DSPBSURFLIVE       :
+		case _REG_VLV_DSPBLINOFF         :
+		case _REG_VLV_DSPBSTRIDE         :
+		case _REG_VLV_DSPBTILEOFF        :
+		case _REG_VLV_DSPBSIZE:
+		case _REG_VLV_DSPBPOS:
+		case _REG_VLV_PIPEBSRC:
+			real_pipe = vgt->pipe_mapping[1];
+			virtual_pipe = PIPE_B;
+			break;
 
-	case _REG_CURCBASE:
-	case _REG_CURCCNTR:
-	case _REG_CURCPOS:
-	case _REG_DSPCCNTR:
-	case _REG_DSPCSURF:
-	case _REG_DSPCSURFLIVE:
-	case _REG_DSPCLINOFF:
-	case _REG_DSPCSTRIDE:
-	case _REG_DSPCPOS:
-	case _REG_DSPCSIZE:
-	case _REG_DSPCTILEOFF:
-	case _REG_SPRCSURF:
-	case _REG_SPRC_CTL:
-	case _REG_PIPECSRC:
-		real_pipe = vgt->pipe_mapping[2];
-		virtual_pipe = PIPE_C;
-		break;
+		default:
+			vgt_warn("try to map mmio that is not plane related! reg = %x\n", reg);
+			ASSERT(0);
+		}
 
-	default:
-		vgt_warn("try to map mmio that is not plane related! reg = %x\n", reg);
-		ASSERT(0);
+	} else {
+		switch (reg)
+		{
+		case _REG_CURABASE:
+		case _REG_CURACNTR:
+		case _REG_CURAPOS:
+		case _REG_DSPACNTR:
+		case _REG_DSPASURF:
+		case _REG_DSPASURFLIVE:
+		case _REG_DSPALINOFF:
+		case _REG_DSPASTRIDE:
+		case _REG_DSPAPOS:
+		case _REG_DSPASIZE:
+		case _REG_DSPATILEOFF:
+		case _REG_SPRASURF:
+		case _REG_SPRA_CTL:
+		case _REG_PIPEASRC:
+			real_pipe = vgt->pipe_mapping[0];
+			virtual_pipe = PIPE_A;
+			break;
+
+		case _REG_CURBBASE_SNB:
+		case _REG_CURBCNTR_SNB:
+		case _REG_CURBPOS_SNB:
+		case _REG_CURBBASE:
+		case _REG_CURBCNTR:
+		case _REG_CURBPOS:
+		case _REG_DSPBCNTR:
+		case _REG_DSPBSURF:
+		case _REG_DSPBSURFLIVE:
+		case _REG_DSPBLINOFF:
+		case _REG_DSPBSTRIDE:
+		case _REG_DSPBPOS:
+		case _REG_DSPBSIZE:
+		case _REG_DSPBTILEOFF:
+		case _REG_SPRBSURF:
+		case _REG_SPRB_CTL:
+		case _REG_PIPEBSRC:
+			real_pipe = vgt->pipe_mapping[1];
+			virtual_pipe = PIPE_B;
+			break;
+
+		case _REG_CURCBASE:
+		case _REG_CURCCNTR:
+		case _REG_CURCPOS:
+		case _REG_DSPCCNTR:
+		case _REG_DSPCSURF:
+		case _REG_DSPCSURFLIVE:
+		case _REG_DSPCLINOFF:
+		case _REG_DSPCSTRIDE:
+		case _REG_DSPCPOS:
+		case _REG_DSPCSIZE:
+		case _REG_DSPCTILEOFF:
+		case _REG_SPRCSURF:
+		case _REG_SPRC_CTL:
+		case _REG_PIPECSRC:
+			real_pipe = vgt->pipe_mapping[2];
+			virtual_pipe = PIPE_C;
+			break;
+
+		default:
+			vgt_warn("try to map mmio that is not plane related! reg = %x\n", reg);
+			ASSERT(0);
+		}
 	}
 
 	if(real_pipe == I915_MAX_PIPES)
@@ -1297,6 +1417,8 @@ static bool dpy_plane_ctl_write(struct vgt_device *vgt, unsigned int offset,
 
 	new_plane_ctl = *(vgt_reg_t *)p_data;
 	pipe = VGT_DSPCNTRPIPE(offset);
+	if(IS_VLV(vgt->pdev)) pipe = VGT_VLV_DSPCNTRPIPE(offset);
+
 	if ( (_PRI_PLANE_ENABLE & new_plane_ctl) &&  (_PRI_PLANE_ENABLE & __vreg(vgt, offset)) == 0) {
 		enable_plane = true;
 	}
@@ -1333,6 +1455,8 @@ static bool pri_surf_mmio_write(struct vgt_device *vgt, unsigned int offset,
 	unsigned int real_offset;
 	vgt_reg_t ret_val;
 
+	if(IS_VLV(vgt->pdev)) pipe = VGT_VLV_DSPSURFPIPE(offset);
+
 	__vreg(vgt, offset) = *(vgt_reg_t*)p_data;
 	ret_val = vgt_surf_base_range_check(vgt, pipe, PRIMARY_PLANE);
 	__sreg(vgt, offset) = ret_val ? ret_val : __vreg(vgt, offset);
@@ -1345,9 +1469,13 @@ static bool pri_surf_mmio_write(struct vgt_device *vgt, unsigned int offset,
 	msg.vm_id = vgt->vm_id;
 	msg.plane_id = PRIMARY_PLANE;
 	msg.pipe_id = VGT_DSPSURFPIPE(offset);
+	if(IS_VLV(vgt->pdev)) msg.pipe_id = VGT_VLV_DSPSURFPIPE(offset);
 	vgt_fb_notifier_call_chain(FB_DISPLAY_FLIP, &msg);
 
-	vgt_inject_flip_done(vgt, VGT_DSPSURFPIPE(offset));
+	if(IS_VLV(vgt->pdev))
+		vgt_inject_flip_done(vgt, VGT_VLV_DSPSURFPIPE(offset));
+	else
+		vgt_inject_flip_done(vgt, VGT_DSPSURFPIPE(offset));
 
 	return true;
 }
@@ -1357,6 +1485,14 @@ static bool sprite_plane_ctl_write(struct vgt_device *vgt, unsigned int offset,
 {
 	enum vgt_pipe pipe = VGT_SPRCNTRPIPE(offset);
 
+	if(IS_VLV(vgt->pdev)){
+		if(offset == _REG_VLV_SPRB_CTL || offset == _REG_VLV_SPRD_CTL) {
+			vgt_warn("sprite B/D ctrl map rerouted to A/B! Unsupported reg = %x\n", offset);
+			offset -= 0x100;
+		}
+		pipe = VGT_VLV_SPRCNTRPIPE(offset);
+	}
+
 	dpy_plane_mmio_write(vgt, offset, p_data, bytes);
 	vgt_surf_base_range_check(vgt, pipe, SPRITE_PLANE);
 
@@ -1371,6 +1507,13 @@ static bool spr_surf_mmio_write(struct vgt_device *vgt, unsigned int offset,
 	unsigned int real_offset;
 	vgt_reg_t ret_val;
 
+	if(IS_VLV(vgt->pdev)){
+		if(offset == _REG_VLV_SPRBSURF || offset == _REG_VLV_SPRDSURF) {
+			vgt_warn("sprite B/D surf map rerouted to A/B! Unsupported reg = %x\n", offset);
+			offset -= 0x100;
+		}
+		pipe = VGT_VLV_SPRSURFPIPE(offset);
+	}
 	__vreg(vgt, offset) = *(vgt_reg_t*)p_data;
 	ret_val = vgt_surf_base_range_check(vgt, pipe, SPRITE_PLANE);
 	__sreg(vgt, offset) = ret_val ? ret_val : __vreg(vgt, offset);
@@ -1383,6 +1526,7 @@ static bool spr_surf_mmio_write(struct vgt_device *vgt, unsigned int offset,
 	msg.vm_id = vgt->vm_id;
 	msg.plane_id = SPRITE_PLANE;
 	msg.pipe_id = VGT_SPRSURFPIPE(offset);
+	if(IS_VLV(vgt->pdev)) msg.pipe_id = VGT_VLV_SPRSURFPIPE(offset);
 	vgt_fb_notifier_call_chain(FB_DISPLAY_FLIP, &msg);
 
 	return true;
@@ -1392,6 +1536,7 @@ static bool cur_plane_ctl_write(struct vgt_device *vgt, unsigned int offset,
 	void *p_data, unsigned int bytes)
 {
 	enum vgt_pipe pipe = VGT_CURCNTRPIPE(offset);
+	if(IS_VLV(vgt->pdev)) pipe = VGT_VLV_CURCNTRPIPE(offset);
 
 	dpy_plane_mmio_write(vgt,offset, p_data, bytes);
 	vgt_surf_base_range_check(vgt, pipe, CURSOR_PLANE);
@@ -1406,6 +1551,8 @@ static bool cur_surf_mmio_write(struct vgt_device *vgt, unsigned int offset,
 	unsigned int real_offset;
 	vgt_reg_t ret_val;
 
+	if(IS_VLV(vgt->pdev)) pipe = VGT_VLV_CURSURFPIPE(offset);
+
 	__vreg(vgt, offset) = *(vgt_reg_t*)p_data;
 	ret_val = vgt_surf_base_range_check(vgt, pipe, CURSOR_PLANE);
 	__sreg(vgt, offset) = ret_val ? ret_val : __vreg(vgt, offset);
@@ -1445,21 +1592,36 @@ static bool surflive_mmio_read(struct vgt_device *vgt, unsigned int offset,
 	unsigned int surf_reg = 0;
 	enum vgt_pipe pipe;
 
-	if (plane == PRIMARY_PLANE) {
-		pipe = VGT_DSPSURFLIVEPIPE(offset);
-		surf_reg = VGT_DSPSURF(pipe);
-	} else if (plane == CURSOR_PLANE) {
-		if (offset == _REG_CURBSURFLIVE_SNB) {
-			surf_reg = _REG_CURBBASE_SNB;
+	if(IS_VLV(vgt->pdev)) {
+		if (plane == PRIMARY_PLANE) {
+			pipe = VGT_VLV_DSPSURFLIVEPIPE(offset);
+			surf_reg = VGT_VLV_DSPSURF(pipe);
+		} else if (plane == CURSOR_PLANE) {
+			pipe = VGT_VLV_CURSURFPIPE(offset);
+			surf_reg = VGT_VLV_CURSURF(pipe);
+		} else if (plane == SPRITE_PLANE) {
+			pipe = VGT_VLV_SPRSURFPIPE(offset);
+			surf_reg = VGT_VLV_SPRSURF(pipe);
 		} else {
-			pipe = VGT_CURSURFPIPE(offset);
-			surf_reg = VGT_CURSURF(pipe);
+			BUG();
 		}
-	} else if (plane == SPRITE_PLANE) {
-		pipe = VGT_SPRSURFPIPE(offset);
-		surf_reg = VGT_SPRSURF(pipe);
 	} else {
-		BUG();
+		if (plane == PRIMARY_PLANE) {
+			pipe = VGT_DSPSURFLIVEPIPE(offset);
+			surf_reg = VGT_DSPSURF(pipe);
+		} else if (plane == CURSOR_PLANE) {
+			if (offset == _REG_CURBSURFLIVE_SNB) {
+				surf_reg = _REG_CURBBASE_SNB;
+			} else {
+				pipe = VGT_CURSURFPIPE(offset);
+				surf_reg = VGT_CURSURF(pipe);
+			}
+		} else if (plane == SPRITE_PLANE) {
+			pipe = VGT_SPRSURFPIPE(offset);
+			surf_reg = VGT_SPRSURF(pipe);
+		} else {
+			BUG();
+		}
 	}
 
 	surflive_val = __vreg(vgt, surf_reg);
@@ -2468,10 +2630,10 @@ reg_attr_t vgt_base_reg_info[] = {
 {0x20e4, 4, F_RDR_MODE, 0, D_GEN7PLUS, NULL, NULL},
 {_REG_VFSKPD, 4, F_RDR_MODE, 0, D_ALL, NULL, NULL},
 {_REG_ECOCHK, 4, F_RDR, 0, D_ALL, NULL, NULL},
-{_REG_GEN7_COMMON_SLICE_CHICKEN1, 4, F_RDR, 0, D_HSW, NULL, NULL},
-{_REG_GEN7_L3CNTLREG1, 4, F_RDR, 0, D_HSW, NULL, NULL},
-{_REG_GEN7_L3_CHICKEN_MODE_REGISTER, 4, F_RDR, 0, D_HSW, NULL, NULL},
-{_REG_GEN7_SQ_CHICKEN_MBCUNIT_CONFIG, 4, F_RDR, 0, D_HSW, NULL, NULL},
+{_REG_GEN7_COMMON_SLICE_CHICKEN1, 4, F_RDR, 0, D_GEN7PLUS, NULL, NULL},
+{_REG_GEN7_L3CNTLREG1, 4, F_RDR, 0, D_GEN7PLUS, NULL, NULL},
+{_REG_GEN7_L3_CHICKEN_MODE_REGISTER, 4, F_RDR, 0, D_GEN7PLUS, NULL, NULL},
+{_REG_GEN7_SQ_CHICKEN_MBCUNIT_CONFIG, 4, F_RDR, 0, D_GEN7PLUS, NULL, NULL},
 {0x20a0, 4, F_RDR, 0, D_HSW, NULL, NULL},
 {0x20e8, 4, F_RDR, 0, D_HSW, NULL, NULL},
 {_REG_RCS_TIMESTAMP, 8, F_PT, 0, D_ALL, NULL, NULL},
@@ -2489,376 +2651,330 @@ reg_attr_t vgt_base_reg_info[] = {
 {0x7018, 4, F_RDR, 0, D_ALL, NULL, NULL},
 {0xe184, 4, F_RDR, 0, D_ALL, NULL, NULL},
 
-{0x60220, 0x20, F_DPY, 0, D_ALL, NULL, NULL},
-{0x602a0, 4, F_DPY, 0, D_ALL, NULL, NULL},
+{0x60220, 0x20, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{0x602a0, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
 
-{0x65050, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{0x650b4, 4, F_DPY, 0, D_ALL, NULL, NULL},
+{0x65050, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{0x650b4, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+
+/* ------- CORE display regs---------- */
 
-	/* -------display regs---------- */
 {_REG_VGA_CR_INDEX_MDA, 1, F_DPY, 0, D_ALL, NULL, NULL},
 {_REG_VGA_ST01_MDA, 1, F_DPY, 0, D_ALL, NULL, NULL},
 {_REG_VGA_AR_INDEX, 1, F_DPY, 0, D_ALL, NULL, NULL},
 {_REG_VGA_DACMASK, 1, F_DPY, 0, D_ALL, NULL, NULL},
 {_REG_VGA_MSR_READ, 1, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_VGA0, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_VGA1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_VGA_PD, 4, F_DPY, 0, D_ALL, NULL, NULL},
-
-{0x42080, 4, F_DOM0, 0, D_HSW, NULL, NULL},
-{_REG_DEIMR, 4, F_VIRT, 0, D_ALL, NULL, vgt_reg_imr_handler},
-{_REG_DEIER, 4, F_VIRT, 0, D_ALL, NULL, vgt_reg_ier_handler},
-{_REG_DEIIR, 4, F_VIRT, 0, D_ALL, NULL, vgt_reg_iir_handler},
-{_REG_DEISR, 4, F_VIRT, 0, D_ALL, NULL, NULL},
-{_REG_SDEIMR, 4, F_VIRT, 0, D_ALL, NULL, vgt_reg_imr_handler},
-{_REG_SDEIER, 4, F_VIRT, 0, D_ALL, NULL, vgt_reg_ier_handler},
-{_REG_SDEIIR, 4, F_VIRT, 0, D_ALL, NULL, vgt_reg_iir_handler},
-{_REG_SDEISR, 4, F_VIRT, 0, D_ALL, vgt_reg_isr_read, vgt_reg_isr_write},
-
-{0xc4040, 4, F_VIRT, 0, D_ALL, NULL, NULL},
-
-{_REG_DE_RRMR, 4, F_VIRT, 0, D_ALL, NULL, rrmr_mmio_write},
-
-{_REG_PIPEADSL, 4, F_DPY, 0, D_ALL, pipe_dsl_mmio_read, NULL},
-{_REG_PIPEACONF, 4, F_DPY, 0, D_ALL, NULL, pipe_conf_mmio_write},
-{_REG_PIPEASTAT, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_DSPARB, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEA_FRMCOUNT, 4, F_DPY, 0, D_ALL, pipe_frmcount_mmio_read, NULL},
-
-{_REG_PIPEBDSL, 4, F_DPY, 0, D_ALL, pipe_dsl_mmio_read, NULL},
-{_REG_PIPEBCONF, 4, F_DPY, 0, D_ALL, NULL, pipe_conf_mmio_write},
-{_REG_PIPEBSTAT, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEB_FRMCOUNT, 4, F_DPY, 0, D_ALL, pipe_frmcount_mmio_read, NULL},
-
-{_REG_PIPECDSL, 4, F_DPY, 0, D_HSW, pipe_dsl_mmio_read, NULL},
-{_REG_PIPECCONF, 4, F_DPY, 0, D_HSW, NULL, pipe_conf_mmio_write},
-{_REG_PIPECSTAT, 4, F_DPY, 0, D_HSW, NULL, NULL},
+{_REG_VGA0, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_VGA1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_VGA_PD, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+
+{0x42080,     4, F_DOM0, 0, D_HSW, NULL, NULL},
+{_REG_DEIMR,  4, F_VIRT, 0, D_ALLCORE, NULL, vgt_reg_imr_handler},
+{_REG_DEIER,  4, F_VIRT, 0, D_ALLCORE, NULL, vgt_reg_ier_handler},
+{_REG_DEIIR,  4, F_VIRT, 0, D_ALLCORE, NULL, vgt_reg_iir_handler},
+{_REG_DEISR,  4, F_VIRT, 0, D_ALLCORE, NULL, NULL},
+{_REG_SDEIMR, 4, F_VIRT, 0, D_ALLCORE, NULL, vgt_reg_imr_handler},
+{_REG_SDEIER, 4, F_VIRT, 0, D_ALLCORE, NULL, vgt_reg_ier_handler},
+{_REG_SDEIIR, 4, F_VIRT, 0, D_ALLCORE, NULL, vgt_reg_iir_handler},
+{_REG_SDEISR, 4, F_VIRT, 0, D_ALLCORE, vgt_reg_isr_read, vgt_reg_isr_write},
+
+{0xc4040, 4, F_VIRT, 0, D_ALLCORE, NULL, NULL},
+
+{_REG_DE_RRMR, 4, F_VIRT, 0, D_ALLCORE, NULL, rrmr_mmio_write},
+
+{_REG_PIPEADSL,       4, F_DPY, 0, D_ALLCORE, pipe_dsl_mmio_read, NULL},
+{_REG_PIPEACONF,      4, F_DPY, 0, D_ALLCORE, NULL, pipe_conf_mmio_write},
+{_REG_PIPEASTAT,      4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_DSPARB,         4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_PIPEA_FRMCOUNT, 4, F_DPY, 0, D_ALLCORE, pipe_frmcount_mmio_read, NULL},
+
+{_REG_PIPEBDSL,       4, F_DPY, 0, D_ALLCORE, pipe_dsl_mmio_read, NULL},
+{_REG_PIPEBCONF,      4, F_DPY, 0, D_ALLCORE, NULL, pipe_conf_mmio_write},
+{_REG_PIPEBSTAT,      4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_PIPEB_FRMCOUNT, 4, F_DPY, 0, D_ALLCORE, pipe_frmcount_mmio_read, NULL},
+
+{_REG_PIPECDSL,       4, F_DPY, 0, D_HSW, pipe_dsl_mmio_read, NULL},
+{_REG_PIPECCONF,      4, F_DPY, 0, D_HSW, NULL, pipe_conf_mmio_write},
+{_REG_PIPECSTAT,      4, F_DPY, 0, D_HSW, NULL, NULL},
 {_REG_PIPEC_FRMCOUNT, 4, F_DPY, 0, D_HSW, pipe_frmcount_mmio_read, NULL},
 
-{_REG_PIPE_EDP_CONF, 4, F_DPY, 0, D_HSW, NULL, pipe_conf_mmio_write},
-
-{_REG_CURABASE, 4, F_DPY_ADRFIX, 0xFFFFF000, D_ALL, dpy_plane_mmio_read,
-						cur_surf_mmio_write},
-{_REG_CURACNTR, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, cur_plane_ctl_write},
-{_REG_CURAPOS, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
-{_REG_CURASURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_ALL, cur_surflive_mmio_read,
-					surflive_mmio_write},
-
-{_REG_CURAPALET_0, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_CURAPALET_1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_CURAPALET_2, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_CURAPALET_3, 4, F_DPY, 0, D_ALL, NULL, NULL},
-
-{_REG_CURBBASE_SNB, 4, F_DPY_ADRFIX, 0xFFFFF000, D_SNB, dpy_plane_mmio_read,
-						dpy_plane_mmio_write},
-{_REG_CURBCNTR_SNB, 4, F_DPY, 0, D_SNB, dpy_plane_mmio_read,
-						dpy_plane_mmio_write},
-{_REG_CURBPOS_SNB, 4, F_DPY, 0, D_SNB, dpy_plane_mmio_read,
-						dpy_plane_mmio_write},
-{_REG_CURBSURFLIVE_SNB, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_SNB, cur_surflive_mmio_read,
-					surflive_mmio_write},
-
-{_REG_CURBBASE, 4, F_DPY_ADRFIX, 0xFFFFF000, D_GEN7PLUS, dpy_plane_mmio_read,
-						cur_surf_mmio_write},
-{_REG_CURBCNTR, 4, F_DPY, 0, D_GEN7PLUS, dpy_plane_mmio_read,
-						cur_plane_ctl_write},
-{_REG_CURBPOS, 4, F_DPY, 0, D_GEN7PLUS, dpy_plane_mmio_read,
-						dpy_plane_mmio_write},
-{_REG_CURBSURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_GEN7PLUS, cur_surflive_mmio_read,
-					surflive_mmio_write},
-{_REG_CURCBASE, 4, F_DPY_ADRFIX, 0xFFFFF000, D_GEN7PLUS, dpy_plane_mmio_read,
-						cur_surf_mmio_write},
-
-{_REG_CURCCNTR, 4, F_DPY, 0, D_GEN7PLUS, dpy_plane_mmio_read,
-						cur_plane_ctl_write},
-{_REG_CURCPOS, 4, F_DPY, 0, D_GEN7PLUS, dpy_plane_mmio_read,
-						dpy_plane_mmio_write},
-{_REG_CURCSURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_GEN7PLUS, cur_surflive_mmio_read,
-					surflive_mmio_write},
-
-{0x7008C, 4, F_DPY, 0, D_ALL, NULL, vgt_error_handler},
+{_REG_PIPE_EDP_CONF,  4, F_DPY, 0, D_HSW, NULL, pipe_conf_mmio_write},
+
+{_REG_CURBBASE_SNB, 4, F_DPY_ADRFIX,           0xFFFFF000, D_SNB, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_CURBSURFLIVE_SNB, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_SNB, cur_surflive_mmio_read, surflive_mmio_write},
+{_REG_CURBCNTR_SNB, 4, F_DPY, 0, D_SNB, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_CURBPOS_SNB,  4, F_DPY, 0, D_SNB, dpy_plane_mmio_read, dpy_plane_mmio_write},
+
+{_REG_CURABASE,     4, F_DPY_ADRFIX,       0xFFFFF000, D_ALLCORE, dpy_plane_mmio_read, cur_surf_mmio_write},
+{_REG_CURASURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_ALLCORE, cur_surflive_mmio_read, surflive_mmio_write},
+{_REG_CURACNTR,     4, F_DPY,  0, D_ALLCORE, dpy_plane_mmio_read, cur_plane_ctl_write},
+{_REG_CURAPOS,      4, F_DPY,  0, D_ALLCORE, dpy_plane_mmio_read, dpy_plane_mmio_write},
+
+{_REG_CURAPALET_0,  4, F_DPY,  0, D_ALLCORE, NULL, NULL},
+{_REG_CURAPALET_1,  4, F_DPY,  0, D_ALLCORE, NULL, NULL},
+{_REG_CURAPALET_2,  4, F_DPY,  0, D_ALLCORE, NULL, NULL},
+{_REG_CURAPALET_3,  4, F_DPY,  0, D_ALLCORE, NULL, NULL},
+
+{_REG_CURBBASE,     4, F_DPY_ADRFIX,       0xFFFFF000, D_GEN7PLUSCORE, dpy_plane_mmio_read, cur_surf_mmio_write},
+{_REG_CURBSURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_GEN7PLUSCORE, cur_surflive_mmio_read, surflive_mmio_write},
+{_REG_CURBCNTR,     4, F_DPY, 0, D_GEN7PLUSCORE, dpy_plane_mmio_read, cur_plane_ctl_write},
+{_REG_CURBPOS,      4, F_DPY, 0, D_GEN7PLUSCORE, dpy_plane_mmio_read, dpy_plane_mmio_write},
+
+{_REG_CURCBASE,     4, F_DPY_ADRFIX,       0xFFFFF000, D_GEN7PLUSCORE, dpy_plane_mmio_read, cur_surf_mmio_write},
+{_REG_CURCSURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_GEN7PLUSCORE, cur_surflive_mmio_read, surflive_mmio_write},
+{_REG_CURCCNTR,     4, F_DPY, 0, D_GEN7PLUSCORE, dpy_plane_mmio_read, cur_plane_ctl_write},
+{_REG_CURCPOS,      4, F_DPY, 0, D_GEN7PLUSCORE, dpy_plane_mmio_read, dpy_plane_mmio_write},
+
+{0x7008C, 4, F_DPY, 0, D_ALLCORE, NULL, vgt_error_handler},
 
 {0x700D0, 4, F_DPY, 0, D_SNB, NULL, NULL},
 {0x700D4, 4, F_DPY, 0, D_SNB, NULL, NULL},
 {0x700D8, 4, F_DPY, 0, D_SNB, NULL, NULL},
 {0x700DC, 4, F_DPY, 0, D_SNB, NULL, NULL},
 
-{0x701b0, 4, F_VIRT, 0, D_ALL, NULL, NULL},
-
-{_REG_DSPACNTR, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read,
-							dpy_plane_ctl_write},
-{_REG_DSPASURF, 4, F_DPY_ADRFIX, 0xFFFFF000, D_ALL, dpy_plane_mmio_read,
-							pri_surf_mmio_write},
-{_REG_DSPASURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_ALL, pri_surflive_mmio_read,
-							surflive_mmio_write},
-{_REG_DSPALINOFF, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read,
-							dpy_plane_mmio_write},
-{_REG_DSPASTRIDE, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read,
-							dpy_plane_mmio_write},
-{_REG_DSPAPOS, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read,
-							dpy_plane_mmio_write},
-{_REG_DSPASIZE, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read,
-							dpy_plane_mmio_write},
-{_REG_DSPATILEOFF, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read,
-							dpy_plane_mmio_write},
-
-{_REG_DSPBCNTR, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read,
-							dpy_plane_ctl_write},
-{_REG_DSPBSURF, 4, F_DPY_ADRFIX, 0xFFFFF000, D_ALL, dpy_plane_mmio_read,
-							pri_surf_mmio_write},
-{_REG_DSPBSURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_ALL, pri_surflive_mmio_read,
-							surflive_mmio_write},
-{_REG_DSPBLINOFF, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read,
-							dpy_plane_mmio_write},
-{_REG_DSPBSTRIDE, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read,
-							dpy_plane_mmio_write},
-{_REG_DSPBPOS, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read,
-							dpy_plane_mmio_write},
-{_REG_DSPBSIZE, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read,
-							dpy_plane_mmio_write},
-{_REG_DSPBTILEOFF, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read,
-							dpy_plane_mmio_write},
-
-{_REG_DSPCCNTR, 4, F_DPY, 0, D_HSW, dpy_plane_mmio_read,
-							dpy_plane_ctl_write},
-{_REG_DSPCSURF, 4, F_DPY_ADRFIX, 0xFFFFF000, D_HSW, dpy_plane_mmio_read,
-							pri_surf_mmio_write},
-{_REG_DSPCSURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_HSW, pri_surflive_mmio_read,
-							surflive_mmio_write},
-{_REG_DSPCLINOFF, 4, F_DPY, 0, D_HSW, dpy_plane_mmio_read,
-							dpy_plane_mmio_write},
-{_REG_DSPCSTRIDE, 4, F_DPY, 0, D_HSW, dpy_plane_mmio_read,
-							dpy_plane_mmio_write},
-{_REG_DSPCPOS, 4, F_DPY, 0, D_HSW, dpy_plane_mmio_read,
-							dpy_plane_mmio_write},
-{_REG_DSPCSIZE, 4, F_DPY, 0, D_HSW, dpy_plane_mmio_read,
-							dpy_plane_mmio_write},
-{_REG_DSPCTILEOFF, 4, F_DPY, 0, D_HSW, dpy_plane_mmio_read,
-							dpy_plane_mmio_write},
-
-{_REG_DVSACNTR, 4, F_DPY, 0, D_SNB, NULL, NULL},
-{_REG_DVSASURF, 4, F_DPY_ADRFIX, 0xFFFFF000, D_SNB, NULL, NULL},
+{0x701b0, 4, F_VIRT, 0, D_ALLCORE, NULL, NULL},
+
+{_REG_DSPACNTR,     4, F_DPY, 0, D_ALLCORE, dpy_plane_mmio_read, dpy_plane_ctl_write},
+{_REG_DSPASURF,     4, F_DPY_ADRFIX,       0xFFFFF000, D_ALLCORE, dpy_plane_mmio_read, pri_surf_mmio_write},
+{_REG_DSPASURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_ALLCORE, pri_surflive_mmio_read, surflive_mmio_write},
+{_REG_DSPALINOFF,   4, F_DPY, 0, D_ALLCORE, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_DSPASTRIDE,   4, F_DPY, 0, D_ALLCORE, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_DSPAPOS,      4, F_DPY, 0, D_ALLCORE, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_DSPASIZE,     4, F_DPY, 0, D_ALLCORE, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_DSPATILEOFF,  4, F_DPY, 0, D_ALLCORE, dpy_plane_mmio_read, dpy_plane_mmio_write},
+
+{_REG_DSPBCNTR,     4, F_DPY, 0, D_ALLCORE, dpy_plane_mmio_read, dpy_plane_ctl_write},
+{_REG_DSPBSURF,     4, F_DPY_ADRFIX,       0xFFFFF000, D_ALLCORE, dpy_plane_mmio_read, pri_surf_mmio_write},
+{_REG_DSPBSURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_ALLCORE, pri_surflive_mmio_read, surflive_mmio_write},
+{_REG_DSPBLINOFF,   4, F_DPY, 0, D_ALLCORE, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_DSPBSTRIDE,   4, F_DPY, 0, D_ALLCORE, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_DSPBPOS,      4, F_DPY, 0, D_ALLCORE, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_DSPBSIZE,     4, F_DPY, 0, D_ALLCORE, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_DSPBTILEOFF,  4, F_DPY, 0, D_ALLCORE, dpy_plane_mmio_read, dpy_plane_mmio_write},
+
+{_REG_DSPCCNTR,     4, F_DPY, 0, D_HSW, dpy_plane_mmio_read, dpy_plane_ctl_write},
+{_REG_DSPCSURF,     4, F_DPY_ADRFIX,       0xFFFFF000, D_HSW, dpy_plane_mmio_read, pri_surf_mmio_write},
+{_REG_DSPCSURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_HSW, pri_surflive_mmio_read, surflive_mmio_write},
+{_REG_DSPCLINOFF,   4, F_DPY, 0, D_HSW, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_DSPCSTRIDE,   4, F_DPY, 0, D_HSW, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_DSPCPOS,      4, F_DPY, 0, D_HSW, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_DSPCSIZE,     4, F_DPY, 0, D_HSW, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_DSPCTILEOFF,  4, F_DPY, 0, D_HSW, dpy_plane_mmio_read, dpy_plane_mmio_write},
+
+{_REG_DVSACNTR,     4, F_DPY, 0, D_SNB, NULL, NULL},
+{_REG_DVSASURF,     4, F_DPY_ADRFIX,       0xFFFFF000, D_SNB, NULL, NULL},
 {_REG_DVSASURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_SNB, NULL, NULL},
-{_REG_DVSALINOFF, 4, F_DPY, 0, D_SNB, NULL, NULL},
-{_REG_DVSAPOS, 4, F_DPY, 0, D_SNB, NULL, NULL},
-{_REG_DVSASIZE, 4, F_DPY, 0, D_SNB, NULL, NULL},
-{_REG_DVSATILEOFF, 4, F_DPY, 0, D_SNB, NULL, NULL},
-{_REG_DVSAKEYVAL, 4, F_DPY, 0, D_SNB, NULL, NULL},
-{_REG_DVSAKEYMSK, 4, F_DPY, 0, D_SNB, NULL, NULL},
-{_REG_DVSAKEYMAXVAL, 4, F_DPY, 0, D_SNB, NULL, NULL},
-{_REG_DVSASCALE, 4, F_DPY, 0, D_SNB, NULL, NULL},
-{_REG_DVSBCNTR, 4, F_DPY, 0, D_SNB, NULL, NULL},
-{_REG_DVSBSURF, 4, F_DPY_ADRFIX, 0xFFFFF000, D_ALL, NULL, NULL},
+{_REG_DVSALINOFF,   4, F_DPY, 0, D_SNB, NULL, NULL},
+{_REG_DVSAPOS,      4, F_DPY, 0, D_SNB, NULL, NULL},
+{_REG_DVSASIZE,     4, F_DPY, 0, D_SNB, NULL, NULL},
+{_REG_DVSATILEOFF,  4, F_DPY, 0, D_SNB, NULL, NULL},
+{_REG_DVSAKEYVAL,   4, F_DPY, 0, D_SNB, NULL, NULL},
+{_REG_DVSAKEYMSK,   4, F_DPY, 0, D_SNB, NULL, NULL},
+{_REG_DVSAKEYMAXVAL,4, F_DPY, 0, D_SNB, NULL, NULL},
+{_REG_DVSASCALE,    4, F_DPY, 0, D_SNB, NULL, NULL},
+{_REG_DVSBCNTR,     4, F_DPY, 0, D_SNB, NULL, NULL},
+{_REG_DVSBSURF,     4, F_DPY_ADRFIX,       0xFFFFF000, D_ALLCORE, NULL, NULL},
 {_REG_DVSBSURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_SNB, NULL, NULL},
-{_REG_DVSBLINOFF, 4, F_DPY, 0, D_SNB, NULL, NULL},
-{_REG_DVSBPOS, 4, F_DPY, 0, D_SNB, NULL, NULL},
-{_REG_DVSBSIZE, 4, F_DPY, 0, D_SNB, NULL, NULL},
-{_REG_DVSBTILEOFF, 4, F_DPY, 0, D_SNB, NULL, NULL},
-{_REG_DVSBKEYVAL, 4, F_DPY, 0, D_SNB, NULL, NULL},
-{_REG_DVSBKEYMSK, 4, F_DPY, 0, D_SNB, NULL, NULL},
-{_REG_DVSBKEYMAXVAL, 4, F_DPY, 0, D_SNB, NULL, NULL},
-{_REG_DVSBSCALE, 4, F_DPY, 0, D_SNB, NULL, NULL},
-
-{_REG_SPRASURF, 4, F_DPY_ADRFIX, 0xFFFFF000, D_HSW,
-			dpy_plane_mmio_read, spr_surf_mmio_write},
-{_REG_SPRASURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_HSW,
-			spr_surflive_mmio_read, surflive_mmio_write},
-
-{_REG_SPRBSURF, 4, F_DPY_ADRFIX, 0xFFFFF000, D_HSW,
-			dpy_plane_mmio_read, spr_surf_mmio_write},
-{_REG_SPRBSURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_HSW,
-			spr_surflive_mmio_read, surflive_mmio_write},
-
-{_REG_SPRCSURF, 4, F_DPY_ADRFIX, 0xFFFFF000, D_HSW,
-			dpy_plane_mmio_read, spr_surf_mmio_write},
-{_REG_SPRCSURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_HSW,
-			spr_surflive_mmio_read, surflive_mmio_write},
-
-{_REG_SPRA_CTL, 4, F_DPY, 0, D_HSW, NULL, sprite_plane_ctl_write},
-{_REG_SPRA_SCALE, 4, F_DPY, 0, D_HSW, NULL, NULL},
-
-{_REG_SPRB_CTL, 4, F_DPY, 0, D_HSW, NULL, sprite_plane_ctl_write},
-{_REG_SPRB_SCALE, 4, F_DPY, 0, D_HSW, NULL, NULL},
-
-{_REG_SPRC_CTL, 4, F_DPY, 0, D_HSW, NULL, sprite_plane_ctl_write},
-
-{_REG_SPRC_SCALE, 4, F_DPY, 0, D_HSW, NULL, NULL},
-
-
-{_REG_LGC_PALETTE_A, 4*256, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_LGC_PALETTE_B, 4*256, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_LGC_PALETTE_C, 4*256, F_DPY, 0, D_GEN7PLUS, NULL, NULL},
-
-{_REG_HTOTAL_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_HBLANK_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_HSYNC_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VTOTAL_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VBLANK_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VSYNC_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_PIPEASRC, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
-{_REG_BCLRPAT_A, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_VSYNCSHIFT_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-
-{_REG_HTOTAL_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_HBLANK_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_HSYNC_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VTOTAL_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VBLANK_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VSYNC_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_PIPEBSRC, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
-{_REG_BCLRPAT_B, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_VSYNCSHIFT_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-
-{_REG_HTOTAL_C, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_HBLANK_C, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_HSYNC_C, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VTOTAL_C, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VBLANK_C, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_VSYNC_C, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_PIPECSRC, 4, F_DPY, 0, D_ALL, dpy_plane_mmio_read, dpy_plane_mmio_write},
-{_REG_BCLRPAT_C, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_VSYNCSHIFT_C, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-
-{0x6F000, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{0x6F004, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{0x6F008, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{0x6F00C, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{0x6F010, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{0x6F014, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{0x6F028, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{0x6F030, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{0x6F034, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{0x6F040, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{0x6F044, 4, F_DPY, 0, D_ALL, NULL, NULL},
-
-{_REG_PIPEA_DATA_M1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEA_DATA_N1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEA_LINK_M1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEA_LINK_N1, 4, F_DPY, 0, D_ALL, NULL, NULL},
+{_REG_DVSBLINOFF,   4, F_DPY, 0, D_SNB, NULL, NULL},
+{_REG_DVSBPOS,      4, F_DPY, 0, D_SNB, NULL, NULL},
+{_REG_DVSBSIZE,     4, F_DPY, 0, D_SNB, NULL, NULL},
+{_REG_DVSBTILEOFF,  4, F_DPY, 0, D_SNB, NULL, NULL},
+{_REG_DVSBKEYVAL,   4, F_DPY, 0, D_SNB, NULL, NULL},
+{_REG_DVSBKEYMSK,   4, F_DPY, 0, D_SNB, NULL, NULL},
+{_REG_DVSBKEYMAXVAL,4, F_DPY, 0, D_SNB, NULL, NULL},
+{_REG_DVSBSCALE,    4, F_DPY, 0, D_SNB, NULL, NULL},
+
+{_REG_SPRA_CTL,     4, F_DPY, 0, D_HSW, NULL, sprite_plane_ctl_write},
+{_REG_SPRA_SCALE,   4, F_DPY, 0, D_HSW, NULL, NULL},
+{_REG_SPRASURF,     4, F_DPY_ADRFIX,       0xFFFFF000, D_HSW, dpy_plane_mmio_read, spr_surf_mmio_write},
+{_REG_SPRASURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_HSW, spr_surflive_mmio_read, surflive_mmio_write},
+
+{_REG_SPRB_CTL,     4, F_DPY, 0, D_HSW, NULL, sprite_plane_ctl_write},
+{_REG_SPRB_SCALE,   4, F_DPY, 0, D_HSW, NULL, NULL},
+{_REG_SPRBSURF,     4, F_DPY_ADRFIX,       0xFFFFF000, D_HSW, dpy_plane_mmio_read, spr_surf_mmio_write},
+{_REG_SPRBSURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_HSW, spr_surflive_mmio_read, surflive_mmio_write},
+
+{_REG_SPRC_CTL,     4, F_DPY, 0, D_HSW, NULL, sprite_plane_ctl_write},
+{_REG_SPRC_SCALE,   4, F_DPY, 0, D_HSW, NULL, NULL},
+{_REG_SPRCSURF,     4, F_DPY_ADRFIX,       0xFFFFF000, D_HSW, dpy_plane_mmio_read, spr_surf_mmio_write},
+{_REG_SPRCSURFLIVE, 4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_HSW, spr_surflive_mmio_read, surflive_mmio_write},
+
+{_REG_LGC_PALETTE_A, 4*256, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_LGC_PALETTE_B, 4*256, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_LGC_PALETTE_C, 4*256, F_DPY, 0, D_GEN7PLUSCORE, NULL, NULL},
+
+{_REG_HTOTAL_A,     4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_HBLANK_A,     4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_HSYNC_A,      4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_VTOTAL_A,     4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_VBLANK_A,     4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_VSYNC_A,      4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_PIPEASRC,     4, F_DPY, 0, D_ALLCORE, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_BCLRPAT_A,    4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_VSYNCSHIFT_A, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+
+{_REG_HTOTAL_B,     4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_HBLANK_B,     4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_HSYNC_B,      4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_VTOTAL_B,     4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_VBLANK_B,     4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_VSYNC_B,      4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_PIPEBSRC,     4, F_DPY, 0, D_ALLCORE, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_BCLRPAT_B,    4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_VSYNCSHIFT_B, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+
+{_REG_HTOTAL_C,     4, F_DPY, 0, D_GEN7PLUSCORE, NULL, dpy_modeset_mmio_write},
+{_REG_HBLANK_C,     4, F_DPY, 0, D_GEN7PLUSCORE, NULL, dpy_modeset_mmio_write},
+{_REG_HSYNC_C,      4, F_DPY, 0, D_GEN7PLUSCORE, NULL, dpy_modeset_mmio_write},
+{_REG_VTOTAL_C,     4, F_DPY, 0, D_GEN7PLUSCORE, NULL, dpy_modeset_mmio_write},
+{_REG_VBLANK_C,     4, F_DPY, 0, D_GEN7PLUSCORE, NULL, dpy_modeset_mmio_write},
+{_REG_VSYNC_C,      4, F_DPY, 0, D_GEN7PLUSCORE, NULL, dpy_modeset_mmio_write},
+{_REG_PIPECSRC,     4, F_DPY, 0, D_GEN7PLUSCORE, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_BCLRPAT_C,    4, F_DPY, 0, D_GEN7PLUSCORE, NULL, NULL},
+{_REG_VSYNCSHIFT_C, 4, F_DPY, 0, D_GEN7PLUSCORE, NULL, dpy_modeset_mmio_write},
+
+{0x6F000, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{0x6F004, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{0x6F008, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{0x6F00C, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{0x6F010, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{0x6F014, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{0x6F028, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{0x6F030, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{0x6F034, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{0x6F040, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{0x6F044, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+
+{_REG_PIPEA_DATA_M1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_PIPEA_DATA_N1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_PIPEA_LINK_M1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_PIPEA_LINK_N1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
 
 {_REG_PIPEA_DATA_M2, 4, F_DPY, 0, D_IVB, NULL, NULL},
 {_REG_PIPEA_DATA_N2, 4, F_DPY, 0, D_IVB, NULL, NULL},
 {_REG_PIPEA_LINK_M2, 4, F_DPY, 0, D_IVB, NULL, NULL},
 {_REG_PIPEA_LINK_N2, 4, F_DPY, 0, D_IVB, NULL, NULL},
 
-{_REG_PIPEB_DATA_M1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEB_DATA_N1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEB_LINK_M1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEB_LINK_N1, 4, F_DPY, 0, D_ALL, NULL, NULL},
+{_REG_PIPEB_DATA_M1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_PIPEB_DATA_N1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_PIPEB_LINK_M1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_PIPEB_LINK_N1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
 
 {_REG_PIPEB_DATA_M2, 4, F_DPY, 0, D_IVB, NULL, NULL},
 {_REG_PIPEB_DATA_N2, 4, F_DPY, 0, D_IVB, NULL, NULL},
 {_REG_PIPEB_LINK_M2, 4, F_DPY, 0, D_IVB, NULL, NULL},
 {_REG_PIPEB_LINK_N2, 4, F_DPY, 0, D_IVB, NULL, NULL},
 
-{_REG_PIPEC_DATA_M1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEC_DATA_N1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEC_LINK_M1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PIPEC_LINK_N1, 4, F_DPY, 0, D_ALL, NULL, NULL},
+{_REG_PIPEC_DATA_M1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_PIPEC_DATA_N1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_PIPEC_LINK_M1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_PIPEC_LINK_N1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
 
 {_REG_PIPEC_DATA_M2, 4, F_DPY, 0, D_IVB, NULL, NULL},
 {_REG_PIPEC_DATA_N2, 4, F_DPY, 0, D_IVB, NULL, NULL},
 {_REG_PIPEC_LINK_M2, 4, F_DPY, 0, D_IVB, NULL, NULL},
 {_REG_PIPEC_LINK_N2, 4, F_DPY, 0, D_IVB, NULL, NULL},
 
-{_REG_PF_CTL_0, 4, F_DPY, 0, D_ALL, pf_read, pf_write},
-{_REG_PF_WIN_SZ_0, 4, F_DPY, 0, D_ALL, pf_read, pf_write},
-{_REG_PF_WIN_POS_0, 4, F_DPY, 0, D_ALL, pf_read, pf_write},
-{_REG_PF_CTL_1, 4, F_DPY, 0, D_ALL, pf_read, pf_write},
-{_REG_PF_WIN_SZ_1, 4, F_DPY, 0, D_ALL, pf_read, pf_write},
-{_REG_PF_WIN_POS_1, 4, F_DPY, 0, D_ALL, pf_read, pf_write},
-{_REG_PF_CTL_2, 4, F_DPY, 0, D_GEN7PLUS, pf_read, pf_write},
-{_REG_PF_WIN_SZ_2, 4, F_DPY, 0, D_GEN7PLUS, pf_read, pf_write},
-{_REG_PF_WIN_POS_2, 4, F_DPY, 0, D_GEN7PLUS, pf_read, pf_write},
-
-{_REG_WM0_PIPEA_ILK, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_WM0_PIPEB_ILK, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_WM0_PIPEC_IVB, 4, F_DPY, 0, D_GEN7PLUS, NULL, NULL},
-{_REG_WM1_LP_ILK, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_WM2_LP_ILK, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_WM3_LP_ILK, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_WM1S_LP_ILK, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_WM2S_LP_IVB, 4, F_DPY, 0, D_GEN7PLUS, NULL, NULL},
-{_REG_WM3S_LP_IVB, 4, F_DPY, 0, D_GEN7PLUS, NULL, NULL},
-
-{_REG_HISTOGRAM_THRSH, 4, F_DPY, 0, D_ALL, NULL, NULL},
-
-{_REG_BLC_PWM_CPU_CTL2, 4, F_DOM0, 0, D_ALL, NULL, NULL},
-{_REG_BLC_PWM_CPU_CTL, 4, F_DOM0, 0, D_ALL, NULL, NULL},
-{_REG_BLC_PWM_PCH_CTL1, 4, F_DOM0, 0, D_ALL, NULL, NULL},
-{_REG_BLC_PWM_PCH_CTL2, 4, F_DOM0, 0, D_ALL, NULL, NULL},
-
-{_REG_PCH_GMBUS0, 4*4, F_DPY, 0, D_ALL, gmbus_mmio_read, gmbus_mmio_write},
-{_REG_PCH_GPIOA, 6*4, F_VIRT, 0, D_ALL, NULL, NULL},
-
-{_REG_DP_BUFTRANS, 0x28, F_DPY, 0, D_ALL, NULL, NULL},
-
-{_REG_PCH_DPB_AUX_CH_CTL, 6*4, F_DPY, 0, D_ALL,
-	dp_aux_ch_ctl_mmio_read, dp_aux_ch_ctl_mmio_write},
-{_REG_PCH_DPC_AUX_CH_CTL, 6*4, F_DPY, 0, D_ALL,
-	dp_aux_ch_ctl_mmio_read, dp_aux_ch_ctl_mmio_write},
-{_REG_PCH_DPD_AUX_CH_CTL, 6*4, F_DPY, 0, D_ALL,
-	dp_aux_ch_ctl_mmio_read, dp_aux_ch_ctl_mmio_write},
-
-{_REG_PCH_ADPA, 4, F_DPY, 0, D_ALL, pch_adpa_mmio_read, pch_adpa_mmio_write},
-{_REG_DP_B_CTL, 4, F_DPY, 0, D_SNB|D_IVB, NULL, dp_ctl_mmio_write},
-{_REG_DP_C_CTL, 4, F_DPY, 0, D_SNB|D_IVB, NULL, dp_ctl_mmio_write},
-{_REG_DP_D_CTL, 4, F_DPY, 0, D_SNB|D_IVB, NULL, dp_ctl_mmio_write},
-{_REG_HDMI_B_CTL, 4, F_DPY, 0, D_SNB|D_IVB, NULL, hdmi_ctl_mmio_write},
-{_REG_HDMI_C_CTL, 4, F_DPY, 0, D_SNB|D_IVB, NULL, hdmi_ctl_mmio_write},
-{_REG_HDMI_D_CTL, 4, F_DPY, 0, D_SNB|D_IVB, NULL, hdmi_ctl_mmio_write},
-{_REG_TRANSACONF, 4, F_DPY, 0, D_ALL, NULL, transaconf_mmio_write},
-{_REG_TRANSBCONF, 4, F_DPY, 0, D_ALL, NULL, transaconf_mmio_write},
-{_REG_FDI_RXA_IIR, 4, F_DPY, 0, D_ALL, NULL, fdi_rx_iir_mmio_write},
-{_REG_FDI_RXB_IIR, 4, F_DPY, 0, D_ALL, NULL, fdi_rx_iir_mmio_write},
-{_REG_FDI_RXC_IIR, 4, F_DPY, 0, D_GEN7PLUS, NULL, fdi_rx_iir_mmio_write},
-{_REG_FDI_RXA_CTL, 4, F_DPY, 0, D_ALL, NULL, update_fdi_rx_iir_status},
-{_REG_FDI_RXB_CTL, 4, F_DPY, 0, D_ALL, NULL, update_fdi_rx_iir_status},
-{_REG_FDI_RXC_CTL, 4, F_DPY, 0, D_GEN7PLUS, NULL, update_fdi_rx_iir_status},
-{_REG_FDI_TXA_CTL, 4, F_DPY, 0, D_ALL, NULL, update_fdi_rx_iir_status},
-{_REG_FDI_TXB_CTL, 4, F_DPY, 0, D_ALL, NULL, update_fdi_rx_iir_status},
-{_REG_FDI_TXC_CTL, 4, F_DPY, 0, D_GEN7PLUS, NULL, update_fdi_rx_iir_status},
-{_REG_FDI_RXA_IMR, 4, F_DPY, 0, D_ALL, NULL, update_fdi_rx_iir_status},
-{_REG_FDI_RXB_IMR, 4, F_DPY, 0, D_ALL, NULL, update_fdi_rx_iir_status},
-{_REG_FDI_RXC_IMR, 4, F_DPY, 0, D_GEN7PLUS, NULL, update_fdi_rx_iir_status},
-
-{_REG_TRANS_HTOTAL_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_TRANS_HBLANK_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_TRANS_HSYNC_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_TRANS_VTOTAL_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_TRANS_VBLANK_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_TRANS_VSYNC_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_TRANS_VSYNCSHIFT_A, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-
-{_REG_TRANS_HTOTAL_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_TRANS_HBLANK_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_TRANS_HSYNC_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_TRANS_VTOTAL_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_TRANS_VBLANK_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_TRANS_VSYNC_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-{_REG_TRANS_VSYNCSHIFT_B, 4, F_DPY, 0, D_ALL, NULL, dpy_modeset_mmio_write},
-
-{_REG_TRANSA_DATA_M1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_TRANSA_DATA_N1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_TRANSA_DATA_M2, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_TRANSA_DATA_N2, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_TRANSA_DP_LINK_M1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_TRANSA_DP_LINK_N1, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_TRANSA_DP_LINK_M2, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_TRANSA_DP_LINK_N2, 4, F_DPY, 0, D_ALL, NULL, NULL},
-
-{_REG_TRANSA_VIDEO_DIP_CTL, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_TRANSA_VIDEO_DIP_DATA, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_TRANSA_VIDEO_DIP_GCP, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_TRANSA_DP_CTL, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_TRANSB_VIDEO_DIP_CTL, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_TRANSB_VIDEO_DIP_DATA, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_TRANSB_VIDEO_DIP_GCP, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_TRANSB_DP_CTL, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_TRANSC_VIDEO_DIP_CTL, 4, F_DPY, 0, D_GEN7PLUS, NULL, NULL},
-{_REG_TRANSC_VIDEO_DIP_DATA, 4, F_DPY, 0, D_GEN7PLUS, NULL, NULL},
-{_REG_TRANSC_VIDEO_DIP_GCP, 4, F_DPY, 0, D_GEN7PLUS, NULL, NULL},
-{_REG_TRANSC_DP_CTL, 4, F_DPY, 0, D_GEN7PLUS, NULL, NULL},
+{_REG_PF_CTL_0,      4, F_DPY, 0, D_ALLCORE, pf_read, pf_write},
+{_REG_PF_WIN_SZ_0,   4, F_DPY, 0, D_ALLCORE, pf_read, pf_write},
+{_REG_PF_WIN_POS_0,  4, F_DPY, 0, D_ALLCORE, pf_read, pf_write},
+{_REG_PF_CTL_1,      4, F_DPY, 0, D_ALLCORE, pf_read, pf_write},
+{_REG_PF_WIN_SZ_1,   4, F_DPY, 0, D_ALLCORE, pf_read, pf_write},
+{_REG_PF_WIN_POS_1,  4, F_DPY, 0, D_ALLCORE, pf_read, pf_write},
+{_REG_PF_CTL_2,      4, F_DPY, 0, D_GEN7PLUSCORE, pf_read, pf_write},
+{_REG_PF_WIN_SZ_2,   4, F_DPY, 0, D_GEN7PLUSCORE, pf_read, pf_write},
+{_REG_PF_WIN_POS_2,  4, F_DPY, 0, D_GEN7PLUSCORE, pf_read, pf_write},
+
+{_REG_WM0_PIPEA_ILK, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_WM0_PIPEB_ILK, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_WM0_PIPEC_IVB, 4, F_DPY, 0, D_GEN7PLUSCORE, NULL, NULL},
+{_REG_WM1_LP_ILK,    4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_WM2_LP_ILK,    4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_WM3_LP_ILK,    4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_WM1S_LP_ILK,   4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_WM2S_LP_IVB,   4, F_DPY, 0, D_GEN7PLUSCORE, NULL, NULL},
+{_REG_WM3S_LP_IVB,   4, F_DPY, 0, D_GEN7PLUSCORE, NULL, NULL},
+
+{_REG_HISTOGRAM_THRSH,  4, F_DPY,  0, D_ALLCORE, NULL, NULL},
+
+{_REG_BLC_PWM_CPU_CTL2, 4, F_DOM0, 0, D_ALLCORE, NULL, NULL},
+{_REG_BLC_PWM_CPU_CTL,  4, F_DOM0, 0, D_ALLCORE, NULL, NULL},
+{_REG_BLC_PWM_PCH_CTL1, 4, F_DOM0, 0, D_ALLCORE, NULL, NULL},
+{_REG_BLC_PWM_PCH_CTL2, 4, F_DOM0, 0, D_ALLCORE, NULL, NULL},
+
+{_REG_PCH_GMBUS0,     4*4, F_DPY,  0, D_ALLCORE, gmbus_mmio_read, gmbus_mmio_write},
+{_REG_PCH_GPIOA,      6*4, F_VIRT, 0, D_ALLCORE, NULL, NULL},
+/* FIXME: now looks gmbus handler can't cover 4/5 ports */
+{_REG_PCH_GMBUS4,       4, F_DPY,  0, D_ALLCORE, NULL, NULL},
+{_REG_PCH_GMBUS5,       4, F_DPY,  0, D_ALLCORE, NULL, NULL},
+
+{_REG_DP_BUFTRANS,   0x28, F_DPY, 0, D_ALLCORE, NULL, NULL},
+
+{_REG_PCH_DPB_AUX_CH_CTL, 6*4, F_DPY, 0, D_ALLCORE, dp_aux_ch_ctl_mmio_read, dp_aux_ch_ctl_mmio_write},
+{_REG_PCH_DPC_AUX_CH_CTL, 6*4, F_DPY, 0, D_ALLCORE, dp_aux_ch_ctl_mmio_read, dp_aux_ch_ctl_mmio_write},
+{_REG_PCH_DPD_AUX_CH_CTL, 6*4, F_DPY, 0, D_ALLCORE, dp_aux_ch_ctl_mmio_read, dp_aux_ch_ctl_mmio_write},
+
+{_REG_PCH_ADPA,    4, F_DPY, 0, D_ALLCORE, pch_adpa_mmio_read, pch_adpa_mmio_write},
+{_REG_DP_B_CTL,    4, F_DPY, 0, D_SNB|D_IVB, NULL, dp_ctl_mmio_write},
+{_REG_DP_C_CTL,    4, F_DPY, 0, D_SNB|D_IVB, NULL, dp_ctl_mmio_write},
+{_REG_DP_D_CTL,    4, F_DPY, 0, D_SNB|D_IVB, NULL, dp_ctl_mmio_write},
+{_REG_HDMI_B_CTL,  4, F_DPY, 0, D_SNB|D_IVB, NULL, hdmi_ctl_mmio_write},
+{_REG_HDMI_C_CTL,  4, F_DPY, 0, D_SNB|D_IVB, NULL, hdmi_ctl_mmio_write},
+{_REG_HDMI_D_CTL,  4, F_DPY, 0, D_SNB|D_IVB, NULL, hdmi_ctl_mmio_write},
+{_REG_TRANSACONF,  4, F_DPY, 0, D_ALLCORE, NULL, transaconf_mmio_write},
+{_REG_TRANSBCONF,  4, F_DPY, 0, D_ALLCORE, NULL, transaconf_mmio_write},
+{_REG_FDI_RXA_IIR, 4, F_DPY, 0, D_ALLCORE, NULL, fdi_rx_iir_mmio_write},
+{_REG_FDI_RXB_IIR, 4, F_DPY, 0, D_ALLCORE, NULL, fdi_rx_iir_mmio_write},
+{_REG_FDI_RXC_IIR, 4, F_DPY, 0, D_GEN7PLUSCORE, NULL, fdi_rx_iir_mmio_write},
+{_REG_FDI_RXA_CTL, 4, F_DPY, 0, D_ALLCORE, NULL, update_fdi_rx_iir_status},
+{_REG_FDI_RXB_CTL, 4, F_DPY, 0, D_ALLCORE, NULL, update_fdi_rx_iir_status},
+{_REG_FDI_RXC_CTL, 4, F_DPY, 0, D_GEN7PLUSCORE, NULL, update_fdi_rx_iir_status},
+{_REG_FDI_TXA_CTL, 4, F_DPY, 0, D_ALLCORE, NULL, update_fdi_rx_iir_status},
+{_REG_FDI_TXB_CTL, 4, F_DPY, 0, D_ALLCORE, NULL, update_fdi_rx_iir_status},
+{_REG_FDI_TXC_CTL, 4, F_DPY, 0, D_GEN7PLUSCORE, NULL, update_fdi_rx_iir_status},
+{_REG_FDI_RXA_IMR, 4, F_DPY, 0, D_ALLCORE, NULL, update_fdi_rx_iir_status},
+{_REG_FDI_RXB_IMR, 4, F_DPY, 0, D_ALLCORE, NULL, update_fdi_rx_iir_status},
+{_REG_FDI_RXC_IMR, 4, F_DPY, 0, D_GEN7PLUSCORE, NULL, update_fdi_rx_iir_status},
+
+{_REG_TRANS_HTOTAL_A, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_TRANS_HBLANK_A, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_TRANS_HSYNC_A,  4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_TRANS_VTOTAL_A, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_TRANS_VBLANK_A, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_TRANS_VSYNC_A,  4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_TRANS_VSYNCSHIFT_A, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+
+{_REG_TRANS_HTOTAL_B, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_TRANS_HBLANK_B, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_TRANS_HSYNC_B,  4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_TRANS_VTOTAL_B, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_TRANS_VBLANK_B, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_TRANS_VSYNC_B,  4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+{_REG_TRANS_VSYNCSHIFT_B, 4, F_DPY, 0, D_ALLCORE, NULL, dpy_modeset_mmio_write},
+
+{_REG_TRANSA_DATA_M1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_DATA_N1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_DATA_M2, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_DATA_N2, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_DP_LINK_M1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_DP_LINK_N1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_DP_LINK_M2, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_DP_LINK_N2, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+
+{_REG_TRANSA_VIDEO_DIP_CTL,  4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_VIDEO_DIP_DATA, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_VIDEO_DIP_GCP,  4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_DP_CTL,         4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSB_VIDEO_DIP_CTL,  4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSB_VIDEO_DIP_DATA, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSB_VIDEO_DIP_GCP,  4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSB_DP_CTL,         4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSC_VIDEO_DIP_CTL,  4, F_DPY, 0, D_GEN7PLUSCORE, NULL, NULL},
+{_REG_TRANSC_VIDEO_DIP_DATA, 4, F_DPY, 0, D_GEN7PLUSCORE, NULL, NULL},
+{_REG_TRANSC_VIDEO_DIP_GCP,  4, F_DPY, 0, D_GEN7PLUSCORE, NULL, NULL},
+{_REG_TRANSC_DP_CTL,         4, F_DPY, 0, D_GEN7PLUSCORE, NULL, NULL},
+
+/* --- end of CORE display regs--- */
 
 {_REG_FDI_RXA_MISC, 4, F_DPY, 0, D_ALL, NULL, NULL},
 {_REG_FDI_RXB_MISC, 4, F_DPY, 0, D_ALL, NULL, NULL},
@@ -2890,10 +3006,9 @@ reg_attr_t vgt_base_reg_info[] = {
 {0xE661C, 4, F_DPY, 0, D_ALL, dpy_reg_mmio_read, NULL},
 {0xE671C, 4, F_DPY, 0, D_ALL, dpy_reg_mmio_read, NULL},
 {0xE681C, 4, F_DPY, 0, D_ALL, dpy_reg_mmio_read, NULL},
-{0xE6C04, 4, F_DPY, 0, D_ALL,
-	dpy_reg_mmio_read_2, NULL},
-{0xE6E1C, 4, F_DPY, 0, D_ALL,
-	dpy_reg_mmio_read_3, NULL},
+{0xE6C04, 4, F_DPY, 0, D_ALL, dpy_reg_mmio_read_2, NULL},
+{0xE6E1C, 4, F_DPY, 0, D_ALL, dpy_reg_mmio_read_3, NULL},
+
 {_REG_SHOTPLUG_CTL, 4, F_DPY, 0, D_ALL, NULL, shotplug_ctl_mmio_write},
 {_REG_LCPLL_CTL, 4, F_DPY, 0, D_HSW, NULL, NULL},
 {_REG_HSW_FUSE_STRAP, 4, F_DPY, 0, D_HSW, NULL, NULL},
@@ -3050,8 +3165,8 @@ reg_attr_t vgt_base_reg_info[] = {
 {_REG_PMIER, 4, F_VIRT, 0, D_ALL, NULL, vgt_reg_ier_handler},
 {_REG_PMIIR, 4, F_VIRT, 0, D_ALL, NULL, vgt_reg_iir_handler},
 {_REG_PMISR, 4, F_VIRT, 0, D_ALL, NULL, NULL},
-{_REG_FORCEWAKE, 4, F_VIRT, 0, D_ALL, NULL, force_wake_write},
-{_REG_FORCEWAKE_ACK, 4, F_VIRT, 0, D_ALL, NULL, NULL},
+{_REG_FORCEWAKE,     4, F_VIRT, 0, D_ALLCORE, NULL, force_wake_write},
+{_REG_FORCEWAKE_ACK, 4, F_VIRT, 0, D_ALLCORE, NULL, NULL},
 {_REG_GT_CORE_STATUS, 4, F_VIRT, 0, D_ALL, NULL, NULL},
 {_REG_GT_THREAD_STATUS, 4, F_VIRT, 0, D_ALL, NULL, NULL},
 {_REG_GTFIFODBG, 4, F_RDR, 0, D_ALL, NULL, NULL},
@@ -3131,7 +3246,7 @@ reg_attr_t vgt_base_reg_info[] = {
 
 	/* -------un-categorized regs--------- */
 
-{0x3c, 4, F_DOM0, 0, D_ALL, NULL, NULL},
+{0x3c,  4, F_DOM0, 0, D_ALL, NULL, NULL},
 {0x860, 4, F_VIRT, 0, D_ALL, NULL, NULL},
 /* no definition on this. from Linux */
 {_REG_GEN3_MI_ARB_STATE, 4, F_PT, 0, D_SNB, NULL, NULL},
@@ -3165,9 +3280,6 @@ reg_attr_t vgt_base_reg_info[] = {
 {0xe6704, 4, F_VIRT, 0, D_ALL, NULL, NULL},
 {0xe6800, 4, F_VIRT, 0, D_ALL, NULL, NULL},
 {0xe6804, 4, F_VIRT, 0, D_ALL, NULL, NULL},
-/* FIXME: now looks gmbus handler can't cover 4/5 ports */
-{_REG_PCH_GMBUS4, 4, F_DPY, 0, D_ALL, NULL, NULL},
-{_REG_PCH_GMBUS5, 4, F_DPY, 0, D_ALL, NULL, NULL},
 
 {_REG_SUPER_QUEUE_CONFIG, 4, F_VIRT, 0, D_ALL, NULL, NULL},
 {_REG_MISC_CLOCK_GATING, 4, F_VIRT, 0, D_ALL, NULL, NULL},
@@ -3217,14 +3329,243 @@ reg_attr_t vgt_base_reg_info[] = {
 /* MAXCNT means max idle count */
 
 {_REG_RC_PWRCTX_MAXCNT, 4, F_DOM0, 0, D_ALL, NULL, NULL},
-{0x12054, 4, F_DOM0, 0, D_HSW, NULL, NULL},
-{0x22054, 4, F_DOM0, 0, D_HSW, NULL, NULL},
-{0x1A054, 4, F_DOM0, 0, D_HSW, NULL, NULL},
+{0x12054, 4, F_DOM0, 0, D_GEN7PLUS, NULL, NULL},
+{0x22054, 4, F_DOM0, 0, D_GEN7PLUS, NULL, NULL},
+{0x1A054, 4, F_DOM0, 0, D_GEN7PLUS, NULL, NULL},
+
+
+/* Baytrail Registers that differ from HSW */
+{_REG_GEN6_GT_GFX_RC6_LOCKED,4, F_VIRT, 0, D_GEN7, NULL, NULL},
+{_REG_IVB_CHICKEN3,          4, F_VIRT, 0, D_GEN7, NULL, NULL},
+{_REG_GEN7_HALF_SLICE_CHICKEN1,4, F_VIRT, 0,D_GEN7, NULL, NULL},
+{_REG_GEN7_L3SQCREG4,        4, F_VIRT, 0, D_GEN7, NULL, NULL},
+{_REG_GEN7_ROW_CHICKEN2,     4, F_VIRT, 0, D_GEN7, NULL, NULL},
+{_REG_VLV_9408,              4, F_VIRT, 0, D_GEN7, NULL, NULL},
+{_REG_VLV_GEN7_UCGCTL4,      4, F_VIRT, 0, D_GEN7, NULL, NULL},
+{_REG_VLV_9410,              4, F_VIRT, 0, D_GEN7, NULL, NULL},
+{_REG_VLV_9414,              4, F_VIRT, 0, D_GEN7, NULL, NULL},
+{_REG_VLV_9418,              4, F_VIRT, 0, D_GEN7, NULL, NULL},
+
+{_REG_VLV_FORCEWAKE,         4, F_VIRT, 0, D_VLV, NULL, force_wake_write},
+{_REG_VLV_FORCEWAKE_ACK,     4, F_VIRT, 0, D_VLV, NULL, NULL},
+{_REG_VLV_FORCEWAKE_MEDIA,   4, F_VIRT, 0, D_VLV, NULL, force_wake_write},
+{_REG_VLV_FORCEWAKE_MEDIA_ACK,4, F_VIRT, 0, D_VLV, NULL, NULL},
+{_REG_VLV_GTLC_WAKE_CTRL ,   4, F_VIRT, 0, D_VLV, NULL, NULL},
+{_REG_VLV_GTLC_PW_STATUS,    4, F_VIRT, 0, D_VLV, NULL, NULL},
+
+{ _REG_VLV_IMR,              4, F_VIRT, 0, D_VLV, NULL, vgt_reg_imr_handler},
+{ _REG_VLV_IIR_RW,           4, F_VIRT, 0, D_VLV, NULL, vgt_reg_iir_handler},
+{ _REG_VLV_IER,              4, F_VIRT, 0, D_VLV, NULL, vgt_reg_ier_handler},
+{ _REG_VLV_IIR,              4, F_VIRT, 0, D_VLV, NULL, vgt_reg_iir_handler},
+{ _REG_VLV_ISR,              4, F_VIRT, 0, D_VLV, NULL, NULL},
+{ _REG_VLV_GTLC_MIR,         4, F_VIRT, 0, D_VLV, NULL, vgt_reg_ier_handler},
+
+{ _REG_VLV_GMBUS0,         4*4, F_PT/*F_VIRT*//*F_DPY*/, 0, D_VLV, gmbus_mmio_read, gmbus_mmio_write},
+{ _REG_VLV_GMBUS4,           4, F_PT/*F_VIRT*//*F_DPY*/, 0, D_VLV, NULL, NULL},
+{ _REG_VLV_GMBUS5,           4, F_PT/*F_VIRT*//*F_DPY*/, 0, D_VLV, NULL, NULL},
+
+{ _REG_VLV_VGACNTRL,         4, F_DPY,  0, D_VLV, NULL, NULL},
+{ _REG_VLV_PIPEA_PP_STATUS,  4, F_DPY,  0, D_VLV, NULL, NULL},
+{ _REG_VLV_PIPEA_PP_CONTROL, 4, F_DPY,  0, D_VLV, NULL, NULL},
+{ _REG_VLV_PIPEA_PP_ON_DELAYS,4, F_DPY, 0, D_VLV, NULL, NULL},
+{ _REG_VLV_PIPEA_PP_OFF_DELAYS,4, F_DPY,0, D_VLV, NULL, NULL},
+{ _REG_VLV_PIPEA_PP_DIVISOR, 4, F_DPY,  0, D_VLV, NULL, NULL},
+
+{ _REG_VLV_PIPEB_PP_STATUS,  4, F_DPY,  0, D_VLV, NULL, NULL},
+{ _REG_VLV_PIPEB_PP_CONTROL, 4, F_DPY,  0, D_VLV, NULL, NULL},
+{ _REG_VLV_PIPEB_PP_ON_DELAYS,4, F_DPY, 0, D_VLV, NULL, NULL},
+{ _REG_VLV_PIPEB_PP_OFF_DELAYS,4, F_DPY,0, D_VLV, NULL, NULL},
+{ _REG_VLV_PIPEB_PP_DIVISOR, 4, F_DPY,  0, D_VLV, NULL, NULL},
+
+{ _REG_VLV_DPINVGTT,         4, F_VIRT, 0, D_VLV, NULL, NULL},
+{ _REG_VLV_PORT_HOTPLUG_EN,  4, F_VIRT, 0, D_VLV, NULL, NULL},
+{ _REG_VLV_PORT_HOTPLUG_STAT,4, F_VIRT, 0, D_VLV, NULL, NULL},
+
+{ _REG_VLV_PIPEACONF,        4, F_DPY,  0, D_VLV, NULL, pipe_conf_mmio_write},
+{ _REG_VLV_PIPEADSL,         4, F_DPY,  0, D_VLV, pipe_dsl_mmio_read, NULL},
+{ _REG_VLV_PIPEASTAT,        4, F_VIRT,  0, D_VLV, vgt_reg_vlv_pipe_iser_handler_read, vgt_reg_vlv_pipe_iser_handler_write},
+{ _REG_VLV_PIPEA_FRMCOUNT,   4, F_DPY,  0, D_VLV, pipe_frmcount_mmio_read, NULL},
+
+{ _REG_VLV_PIPEBCONF,        4, F_DPY,  0, D_VLV, NULL, pipe_conf_mmio_write},
+{ _REG_VLV_PIPEBDSL,         4, F_DPY,  0, D_VLV, pipe_dsl_mmio_read, NULL},
+{ _REG_VLV_PIPEBSTAT,        4, F_VIRT,  0, D_VLV, vgt_reg_vlv_pipe_iser_handler_read, vgt_reg_vlv_pipe_iser_handler_write},
+{ _REG_VLV_PIPEB_FRMCOUNT,   4, F_DPY,  0, D_VLV, pipe_frmcount_mmio_read, NULL},
+
+{ _REG_VLV_DPFLIPSTAT,       4, F_DPY,  0, D_VLV, NULL, NULL},
+{ _REG_VLV_DSPARB,           4, F_DPY,  0, D_VLV, NULL, NULL},
+{ _REG_VLV_PCBR,             4, F_DOM0, 0, D_VLV, NULL, NULL},/*one-time power context - only DOM0? */
+//{ _REG_VLV_DPC_AUX_CH_CTL,   4, F_VIRT, 0, D_VLV, NULL, NULL},
+//{ _REG_VLV_DPC_AUX_CH_DATA1, 4, F_VIRT, 0, D_VLV, NULL, NULL},
+
+/* Cursor registers */
+{_REG_VLV_CURABASE,          4, F_DPY_ADRFIX,       0xFFFFF000, D_VLV, dpy_plane_mmio_read, cur_surf_mmio_write},
+{_REG_VLV_CURASURFLIVE,      4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_VLV, cur_surflive_mmio_read, surflive_mmio_write},
+{_REG_VLV_CURACNTR,          4, F_DPY,  0, D_VLV, dpy_plane_mmio_read, cur_plane_ctl_write},
+{_REG_VLV_CURAPOS,           4, F_DPY,  0, D_VLV, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_VLV_CURAPALET_0,       4, F_DPY,  0, D_VLV, NULL, NULL},
+{_REG_VLV_CURAPALET_1,       4, F_DPY,  0, D_VLV, NULL, NULL},
+{_REG_VLV_CURAPALET_2,       4, F_DPY,  0, D_VLV, NULL, NULL},
+{_REG_VLV_CURAPALET_3,       4, F_DPY,  0, D_VLV, NULL, NULL},
+
+{_REG_VLV_CURBBASE,          4, F_DPY_ADRFIX,       0xFFFFF000, D_VLV, dpy_plane_mmio_read, cur_surf_mmio_write},
+{_REG_VLV_CURBSURFLIVE,      4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_VLV, cur_surflive_mmio_read, surflive_mmio_write},
+{_REG_VLV_CURBCNTR,          4, F_DPY, 0, D_VLV, dpy_plane_mmio_read, cur_plane_ctl_write},
+{_REG_VLV_CURBPOS,           4, F_DPY, 0, D_VLV, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_VLV_CURBPALET_0,       4, F_DPY,  0, D_VLV, NULL, NULL},
+{_REG_VLV_CURBPALET_1,       4, F_DPY,  0, D_VLV, NULL, NULL},
+{_REG_VLV_CURBPALET_2,       4, F_DPY,  0, D_VLV, NULL, NULL},
+{_REG_VLV_CURBPALET_3,       4, F_DPY,  0, D_VLV, NULL, NULL},
+
+{_REG_VLV_DSPACNTR,          4, F_DPY, 0, D_VLV, dpy_plane_mmio_read, dpy_plane_ctl_write},
+{_REG_VLV_DSPASURF,          4, F_DPY_ADRFIX,       0xFFFFF000, D_VLV, dpy_plane_mmio_read, pri_surf_mmio_write},
+{_REG_VLV_DSPASURFLIVE,      4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_VLV, pri_surflive_mmio_read, surflive_mmio_write},
+{_REG_VLV_DSPALINOFF,        4, F_DPY, 0, D_VLV, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_VLV_DSPASTRIDE,        4, F_DPY, 0, D_VLV, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_VLV_DSPATILEOFF,       4, F_DPY, 0, D_VLV, dpy_plane_mmio_read, dpy_plane_mmio_write},
+
+{_REG_VLV_DSPBCNTR,          4, F_DPY, 0, D_VLV, dpy_plane_mmio_read, dpy_plane_ctl_write},
+{_REG_VLV_DSPBSURF,          4, F_DPY_ADRFIX,       0xFFFFF000, D_VLV, dpy_plane_mmio_read, pri_surf_mmio_write},
+{_REG_VLV_DSPBSURFLIVE,      4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_VLV, pri_surflive_mmio_read, surflive_mmio_write},
+{_REG_VLV_DSPBLINOFF,        4, F_DPY, 0, D_VLV, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_VLV_DSPBSTRIDE,        4, F_DPY, 0, D_VLV, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_VLV_DSPBTILEOFF,       4, F_DPY, 0, D_VLV, dpy_plane_mmio_read, dpy_plane_mmio_write},
+
+{_REG_VLV_SPRA_CTL,          4, F_DPY, 0, D_VLV, NULL, sprite_plane_ctl_write},
+{_REG_VLV_SPRASURF,          4, F_DPY_ADRFIX,       0xFFFFF000, D_VLV, dpy_plane_mmio_read, spr_surf_mmio_write},
+{_REG_VLV_SPRASURFLIVE,      4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_VLV, spr_surflive_mmio_read, surflive_mmio_write},
+
+{_REG_VLV_SPRB_CTL,          4, F_DPY, 0, D_VLV, NULL, sprite_plane_ctl_write},
+{_REG_VLV_SPRBSURF,          4, F_DPY_ADRFIX,       0xFFFFF000, D_VLV, dpy_plane_mmio_read, spr_surf_mmio_write},
+{_REG_VLV_SPRBSURFLIVE,      4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_VLV, spr_surflive_mmio_read, surflive_mmio_write},
+
+{_REG_VLV_SPRC_CTL,          4, F_DPY, 0, D_VLV, NULL, sprite_plane_ctl_write},
+{_REG_VLV_SPRCSURF,          4, F_DPY_ADRFIX,       0xFFFFF000, D_VLV, dpy_plane_mmio_read, spr_surf_mmio_write},
+{_REG_VLV_SPRCSURFLIVE,      4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_VLV, spr_surflive_mmio_read, surflive_mmio_write},
+
+{_REG_VLV_SPRD_CTL,          4, F_DPY, 0, D_VLV, NULL, sprite_plane_ctl_write},
+{_REG_VLV_SPRDSURF,          4, F_DPY_ADRFIX,       0xFFFFF000, D_VLV, dpy_plane_mmio_read, spr_surf_mmio_write},
+{_REG_VLV_SPRDSURFLIVE,      4, F_DPY_HWSTS_ADRFIX, 0xFFFFF000, D_VLV, spr_surflive_mmio_read, surflive_mmio_write},
+
+
+{_REG_VLV_DSPASIZE,       4, F_DPY, 0, D_VLV, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_VLV_DSPBSIZE,       4, F_DPY, 0, D_VLV, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_VLV_DSPAPOS,       4, F_DPY, 0, D_VLV, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_VLV_DSPBPOS,       4, F_DPY, 0, D_VLV, dpy_plane_mmio_read, dpy_plane_mmio_write},
+
+
+{_REG_VLV_LGC_PALETTE_A,     4*256, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_LGC_PALETTE_B,     4*256, F_DPY, 0, D_VLV, NULL, NULL},
+
+{_REG_VLV_HTOTAL_A,          4, F_DPY, 0, D_VLV, NULL, dpy_modeset_mmio_write},
+{_REG_VLV_HBLANK_A,          4, F_DPY, 0, D_VLV, NULL, dpy_modeset_mmio_write},
+{_REG_VLV_HSYNC_A,           4, F_DPY, 0, D_VLV, NULL, dpy_modeset_mmio_write},
+{_REG_VLV_VTOTAL_A,          4, F_DPY, 0, D_VLV, NULL, dpy_modeset_mmio_write},
+{_REG_VLV_VBLANK_A,          4, F_DPY, 0, D_VLV, NULL, dpy_modeset_mmio_write},
+{_REG_VLV_VSYNC_A,           4, F_DPY, 0, D_VLV, NULL, dpy_modeset_mmio_write},
+{_REG_VLV_PIPEASRC,          4, F_DPY, 0, D_VLV, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_VLV_BCLRPAT_A,         4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_VSYNCSHIFT_A,      4, F_DPY, 0, D_VLV, NULL, dpy_modeset_mmio_write},
+
+{_REG_VLV_HTOTAL_B,          4, F_DPY, 0, D_VLV, NULL, dpy_modeset_mmio_write},
+{_REG_VLV_HBLANK_B,          4, F_DPY, 0, D_VLV, NULL, dpy_modeset_mmio_write},
+{_REG_VLV_HSYNC_B,           4, F_DPY, 0, D_VLV, NULL, dpy_modeset_mmio_write},
+{_REG_VLV_VTOTAL_B,          4, F_DPY, 0, D_VLV, NULL, dpy_modeset_mmio_write},
+{_REG_VLV_VBLANK_B,          4, F_DPY, 0, D_VLV, NULL, dpy_modeset_mmio_write},
+{_REG_VLV_VSYNC_B,           4, F_DPY, 0, D_VLV, NULL, dpy_modeset_mmio_write},
+{_REG_VLV_PIPEBSRC,          4, F_DPY, 0, D_VLV, dpy_plane_mmio_read, dpy_plane_mmio_write},
+{_REG_VLV_BCLRPAT_B,         4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_VSYNCSHIFT_B,      4, F_DPY, 0, D_VLV, NULL, dpy_modeset_mmio_write},
+
+{_REG_VLV_PFIT_CTL,          4, F_DPY, 0, D_VLV, pf_read, pf_write},
+{_REG_VLV_PFIT_PGM_RATIOS,   4, F_DPY, 0, D_VLV, pf_read, pf_write},
+
+{_REG_VLV_PCH_DPLL_A,        4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_PCH_DPLL_B,        4, F_DPY, 0, D_VLV, NULL, NULL},
+
+/* THE DPIO side band register accesses for plls!!! */
+/* FIXME ALANPREVIN: Actually we might have to figure out handlers just for
+ * the dpio access - since they can target punit, nc and modphy pll's
+ * where the modphy's will be F_DPY but the Punit and NC should be F_DOM0???
+ */
+{_REG_VLV_IOSF_DOORBELL_REQ, 4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_IOSF_DATA,         4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_IOSF_ADDR,         4, F_DPY, 0, D_VLV, NULL, NULL},
+
+{_REG_VLV_FW1,               4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_FW2,               4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_FW3,               4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_FW4,               4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_FW5,               4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_FW6,               4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_FW7,               4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_DDL1,              4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_DDL2,              4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_DSPHOWM,           4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_DSPHOWM1,          4, F_DPY, 0, D_VLV, NULL, NULL},
+
+{_REG_VLV_VIDEO_DIP_CTL_A, 4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_VIDEO_DIP_CTL_B, 4, F_DPY, 0, D_VLV, NULL, NULL},
+
+// Add others...
+/*
+{_REG_HISTOGRAM_THRSH,  4, F_DPY,  0, D_ALLCORE, NULL, NULL},
+
+{_REG_BLC_PWM_CPU_CTL2, 4, F_DOM0, 0, D_ALLCORE, NULL, NULL},
+{_REG_BLC_PWM_CPU_CTL,  4, F_DOM0, 0, D_ALLCORE, NULL, NULL},
+{_REG_BLC_PWM_PCH_CTL1, 4, F_DOM0, 0, D_ALLCORE, NULL, NULL},
+{_REG_BLC_PWM_PCH_CTL2, 4, F_DOM0, 0, D_ALLCORE, NULL, NULL},
+
+{_REG_TRANSA_DATA_M1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_DATA_N1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_DATA_M2, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_DATA_N2, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_DP_LINK_M1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_DP_LINK_N1, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_DP_LINK_M2, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_DP_LINK_N2, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+
+{_REG_TRANSA_VIDEO_DIP_CTL,  4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_VIDEO_DIP_DATA, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_VIDEO_DIP_GCP,  4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSA_DP_CTL,         4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSB_VIDEO_DIP_CTL,  4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSB_VIDEO_DIP_DATA, 4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSB_VIDEO_DIP_GCP,  4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSB_DP_CTL,         4, F_DPY, 0, D_ALLCORE, NULL, NULL},
+{_REG_TRANSC_VIDEO_DIP_CTL,  4, F_DPY, 0, D_GEN7PLUSCORE, NULL, NULL},
+{_REG_TRANSC_VIDEO_DIP_DATA, 4, F_DPY, 0, D_GEN7PLUSCORE, NULL, NULL},
+{_REG_TRANSC_VIDEO_DIP_GCP,  4, F_DPY, 0, D_GEN7PLUSCORE, NULL, NULL},
+{_REG_TRANSC_DP_CTL,         4, F_DPY, 0, D_GEN7PLUSCORE, NULL, NULL},
+*/
+
+{_REG_VLV_PCH_ADPA,          4, F_DPY, 0, D_VLV, pch_adpa_mmio_read, pch_adpa_mmio_write},
+{_REG_VLV_DP_B_CTL,          4, F_DPY, 0, D_VLV, NULL, dp_ctl_mmio_write},
+{_REG_VLV_DP_C_CTL,          4, F_DPY, 0, D_VLV, NULL, dp_ctl_mmio_write},
+{_REG_VLV_DPB_AUX_CH_CTL,  6*4, F_DPY, 0, D_VLV, dp_aux_ch_ctl_mmio_read, dp_aux_ch_ctl_mmio_write},
+{_REG_VLV_DPC_AUX_CH_CTL,  6*4, F_DPY, 0, D_VLV, dp_aux_ch_ctl_mmio_read, dp_aux_ch_ctl_mmio_write},
+
+{_REG_VLV_HDMI_B_CTL,        4, F_DPY, 0, D_VLV, NULL, hdmi_ctl_mmio_write},
+{_REG_VLV_HDMI_C_CTL,        4, F_DPY, 0, D_VLV, NULL, hdmi_ctl_mmio_write},
+//{_REG_PCH_DPB_AUX_CH_CTL,  6*4, F_DPY, 0, D_ALLCORE, dp_aux_ch_ctl_mmio_read, dp_aux_ch_ctl_mmio_write},
+//{_REG_PCH_DPC_AUX_CH_CTL,  6*4, F_DPY, 0, D_ALLCORE, dp_aux_ch_ctl_mmio_read, dp_aux_ch_ctl_mmio_write},
+
+
+{_REG_VLV_DSPCLK_GATE_D,   4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_MI_ARB,         4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_GUNIT_CLOCK_GATE,   4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_DPLL_A_MD,         4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_DPLL_B_MD,         4, F_DPY, 0, D_VLV, NULL, NULL},
+
+
+{ _REG_VLV_GPIOA,   4, F_DPY, 0, D_VLV, NULL, NULL},
+{ _REG_VLV_GPIOE,   4, F_DPY, 0, D_VLV, NULL, NULL},
+{_REG_VLV_FW_BLC_SELF_VLV,  4, F_DPY, 0, D_VLV, NULL, NULL},
+
 };
 
 bool vgt_post_setup_mmio_hooks(struct pgt_device *pdev)
 {
-	printk("post mmio hooks initialized\n");
+	vgt_dbg(VGT_DBG_MMIOSPACE, "post mmio hooks initialized\n");
 
 	if (pdev->enable_ppgtt) {
 		vgt_dbg(VGT_DBG_MEM,"Hook up PPGTT register handlers\n");
@@ -3338,6 +3679,17 @@ reg_list_t vgt_sticky_regs[] = {
 	{_REG_FENCE_0_LOW, 0x80},
 	{VGT_PVINFO_PAGE, VGT_PVINFO_SIZE},
 	{_REG_CPU_VGACNTRL, 4},
+
+	/* GT related registers specifically for Baytrail */
+    { _REG_VLV_IMR     , 4},
+    { _REG_VLV_IIR_RW  , 4},
+    { _REG_VLV_IER     , 4},
+    { _REG_VLV_IIR     , 4},
+    { _REG_VLV_ISR     , 4},
+	{ _REG_VLV_FORCEWAKE, 4},
+	{ _REG_VLV_FORCEWAKE_ACK, 4},
+	{ _REG_VLV_FORCEWAKE_MEDIA, 4},
+	{ _REG_VLV_FORCEWAKE_MEDIA_ACK, 4},
 };
 
 int vgt_get_sticky_reg_num()
diff --git a/drivers/xen/vgt/hypercall.c b/drivers/xen/vgt/hypercall.c
index c95e5af..bdbfd09 100644
--- a/drivers/xen/vgt/hypercall.c
+++ b/drivers/xen/vgt/hypercall.c
@@ -332,7 +332,7 @@ int vgt_hvm_vmem_init(struct vgt_device *vgt)
 				vgt->vm_id, i);
 	}
 
-	printk("start vmem_map\n");
+	vgt_dbg(VGT_DBG_MEM, "start vmem_map\n");
 	count = 0;
 	/* map the >1MB memory */
 	for (i = 1; i < nr_high_bkt; i++) {
@@ -373,7 +373,7 @@ int vgt_hvm_vmem_init(struct vgt_device *vgt)
 			vgt_dbg(VGT_DBG_GENERIC, "vGT: VM%d: can't map %ldKB\n",
 				vgt->vm_id, i);
 	}
-	printk("end vmem_map (%ld 4k mappings)\n", count);
+	vgt_dbg(VGT_DBG_MEM, "end vmem_map (%ld 4k mappings)\n", count);
 
 	return 0;
 err:
diff --git a/drivers/xen/vgt/instance.c b/drivers/xen/vgt/instance.c
index 00ee3ac..f7ad291 100644
--- a/drivers/xen/vgt/instance.c
+++ b/drivers/xen/vgt/instance.c
@@ -85,7 +85,7 @@ static int create_state_instance(struct vgt_device *vgt)
 	state->sReg = vzalloc(vgt->pdev->mmio_size);
 	if ( state->vReg == NULL || state->sReg == NULL )
 	{
-		printk("VGT: insufficient memory allocation at %s\n", __FUNCTION__);
+		vgt_err("VGT: insufficient memory allocation at %s\n", __FUNCTION__);
 		if ( state->vReg )
 			vfree (state->vReg);
 		if ( state->sReg )
@@ -119,7 +119,7 @@ int create_vgt_instance(struct pgt_device *pdev, struct vgt_device **ptr_vgt, vg
 
 	vgt = vzalloc(sizeof(*vgt));
 	if (vgt == NULL) {
-		printk("Insufficient memory for vgt_device in %s\n", __FUNCTION__);
+		vgt_err("Insufficient memory for vgt_device in %s\n", __FUNCTION__);
 		return rc;
 	}
 
@@ -155,7 +155,7 @@ int create_vgt_instance(struct pgt_device *pdev, struct vgt_device **ptr_vgt, vg
 
 	/* init aperture/gm ranges allocated to this vgt */
 	if ((rc = allocate_vm_aperture_gm_and_fence(vgt, vp)) < 0) {
-		printk("vGT: %s: no enough available aperture/gm/fence!\n", __func__);
+		vgt_err("vGT: %s: no enough available aperture/gm/fence!\n", __func__);
 		goto err;
 	}
 
@@ -170,7 +170,7 @@ int create_vgt_instance(struct pgt_device *pdev, struct vgt_device **ptr_vgt, vg
 	vgt_info("Virtual GTT size: 0x%lx\n", (long)vgt->vgtt_sz);
 	vgt->vgtt = vzalloc(vgt->vgtt_sz);
 	if (!vgt->vgtt) {
-		printk("vGT: failed to allocate virtual GTT table\n");
+		vgt_err("vGT: failed to allocate virtual GTT table\n");
 		rc = -ENOMEM;
 		goto err;
 	}
@@ -353,7 +353,7 @@ void vgt_release_instance(struct vgt_device *vgt)
 	struct vgt_device *v = NULL;
 	int cpu;
 
-	printk("prepare to destroy vgt (%d)\n", vgt->vgt_id);
+	vgt_dbg(VGT_DBG_GENERIC, "prepare to destroy vgt (%d)\n", vgt->vgt_id);
 
 	/* destroy vgt_mmio_device */
 	vgt_destroy_mmio_dev(vgt);
@@ -362,7 +362,7 @@ void vgt_release_instance(struct vgt_device *vgt)
 
 	vgt_lock_dev(pdev, cpu);
 
-	printk("check render ownership...\n");
+	vgt_dbg(VGT_DBG_GENERIC, "check render ownership...\n");
 	list_for_each (pos, &pdev->rendering_runq_head) {
 		v = list_entry (pos, struct vgt_device, list);
 		if (v == vgt)
@@ -370,13 +370,13 @@ void vgt_release_instance(struct vgt_device *vgt)
 	}
 
 	if (v != vgt)
-		printk("vgt instance has been removed from run queue\n");
+		vgt_dbg(VGT_DBG_RENDER, "vgt instance has been removed from run queue\n");
 	else if (hvm_render_owner || current_render_owner(pdev) != vgt) {
-		printk("remove vgt(%d) from runqueue safely\n",
+		vgt_dbg(VGT_DBG_RENDER, "remove vgt(%d) from runqueue safely\n",
 			vgt->vgt_id);
 		vgt_disable_render(vgt);
 	} else {
-		printk("vgt(%d) is current owner, request reschedule\n",
+		vgt_dbg(VGT_DBG_RENDER, "vgt(%d) is current owner, request reschedule\n",
 			vgt->vgt_id);
 		vgt->force_removal = 1;
 		pdev->next_sched_vgt = vgt_dom0;
@@ -384,7 +384,7 @@ void vgt_release_instance(struct vgt_device *vgt)
 		wmb();
 	}
 
-	printk("check display ownership...\n");
+	vgt_dbg(VGT_DBG_DPY, "check display ownership...\n");
 	if (!hvm_super_owner && (current_display_owner(pdev) == vgt)) {
 		vgt_dbg(VGT_DBG_DPY, "switch display ownership back to dom0\n");
 		current_display_owner(pdev) = vgt_dom0;
@@ -401,7 +401,7 @@ void vgt_release_instance(struct vgt_device *vgt)
 		/* wait for removal completion */
 		wait_event(pdev->destroy_wq, !vgt->force_removal);
 
-	printk("release display/render ownership... done\n");
+	vgt_dbg(VGT_DBG_GENERIC, "release display/render ownership... done\n");
 
 	/* FIXME: any conflicts between destroy_wq ? */
 	if (shadow_tail_based_qos)
@@ -453,7 +453,7 @@ void vgt_release_instance(struct vgt_device *vgt)
 	vfree(vgt->state.vReg);
 	vfree(vgt->state.sReg);
 	vfree(vgt);
-	printk("vGT: vgt_release_instance done\n");
+	vgt_dbg(VGT_DBG_GENERIC, "vGT: vgt_release_instance done\n");
 }
 
 static void vgt_reset_ppgtt(struct vgt_device *vgt, unsigned long ring_bitmap)
diff --git a/drivers/xen/vgt/interrupt.c b/drivers/xen/vgt/interrupt.c
index 0feaecd..83dbd81 100644
--- a/drivers/xen/vgt/interrupt.c
+++ b/drivers/xen/vgt/interrupt.c
@@ -119,6 +119,8 @@ char *vgt_irq_name[EVENT_MAX] = {
 	[PIPE_C_VBLANK] = "Pipe C vblank",
 	[DPST_PHASE_IN] = "DPST phase in event",
 	[DPST_HISTOGRAM] = "DPST histogram event",
+	//[DPST_MIXED_A] = "VLV DPST PipeA mixed event",
+	//[DPST_MIXED_B] = "VLV DPST PipeB mixed event",
 	[GSE] = "GSE",
 	[DP_A_HOTPLUG] = "DP A Hotplug",
 	[AUX_CHANNEL_A] = "AUX Channel A",
@@ -130,6 +132,8 @@ char *vgt_irq_name[EVENT_MAX] = {
 	[PRIMARY_B_FLIP_DONE] = "Primary Plane B flip done",
 	[SPRITE_A_FLIP_DONE] = "Sprite Plane A flip done",
 	[SPRITE_B_FLIP_DONE] = "Sprite Plane B flip done",
+	[SPRITE_C_FLIP_DONE] = "Sprite Plane C flip done",
+	[SPRITE_D_FLIP_DONE] = "Sprite Plane D flip done",
 
 	// PM
 	[GV_DOWN_INTERVAL] = "Render geyserville Down evaluation interval interrupt",
@@ -176,36 +180,75 @@ static u32 translate_interrupt(struct vgt_irq_host_state *irq_hstate, struct vgt
 {
 	int i = 0;
 	u32 mapped_interrupt = interrupt;
+	struct pgt_device *pdev = vgt->pdev;
 	u32 temp;
 
-	if (_REG_DEIMR == reg) {
-		mapped_interrupt |= irq_hstate->pipe_mask;
-		mapped_interrupt |= (irq_hstate->pipe_mask << 5);
-		mapped_interrupt |= (irq_hstate->pipe_mask << 10);
-		// clear the initial mask bit in DEIMR for VBLANKS, so that when pipe mapping
-		// is not valid, physically there are still vblanks generated.
-		mapped_interrupt &= ~((1 << 0) | (1 << 5) | (1 << 10));
-		for (i = 0; i < I915_MAX_PIPES; i++) {
-			if (vgt->pipe_mapping[i] == I915_MAX_PIPES)
-				continue;
-
-			mapped_interrupt &= ~(irq_hstate->pipe_mask <<
-				(vgt->pipe_mapping[i] * 5));
-
-			temp = interrupt >> (i * 5);
-			temp &= irq_hstate->pipe_mask;
-			mapped_interrupt |= temp << (vgt->pipe_mapping[i] * 5);
+	if(IS_VLV(pdev)) {
+		// For now, add all the one we get...
+		if (_REG_VLV_IMR == reg) {
+			mapped_interrupt |= (_REG_VLV_IIR_DISPLAY_PIPEA_EVENT | _REG_VLV_IIR_DISPLAY_PIPEB_EVENT);
+			// clear the initial mask bit in _REG_VLV_IMR for VBLANKS, so that when pipe mapping
+			// is not valid, physically there are still vblanks generated.
+			mapped_interrupt &= ~(_REG_VLV_IIR_DISPLAY_PIPEA_VBLANK | _REG_VLV_IIR_DISPLAY_PIPEB_VBLANK);
+			if (vgt->pipe_mapping[0] != I915_MAX_PIPES) {
+				mapped_interrupt |= (interrupt & _REG_VLV_IIR_DISPLAY_PIPEA_EVENT);
+			}
+			if (vgt->pipe_mapping[1] != I915_MAX_PIPES) {
+				mapped_interrupt |= (interrupt & _REG_VLV_IIR_DISPLAY_PIPEB_EVENT);
+			}
+		} else if (_REG_VLV_IER == reg) {
+			mapped_interrupt &= ~( _REG_VLV_IIR_DISPLAY_PIPEA_EVENT | _REG_VLV_IIR_DISPLAY_PIPEB_EVENT);
+			// ALANPREVIN: Wonder why we dont keep VBLANK valid for the "other" pipe in the case of IER
+			// like we do for the case of IMR. Adding this here for VLV anyway. I.e. (IER is active high
+			// unlike IMR active low) so we "OR-in" the initial mask bit in _REG_VLV_IER for VBLANKS,
+			// so that when pipe mapping is not valid, physically there are still vblanks generated.
+			mapped_interrupt |= (_REG_VLV_IIR_DISPLAY_PIPEA_VBLANK | _REG_VLV_IIR_DISPLAY_PIPEB_VBLANK);
+			if (vgt->pipe_mapping[0] != I915_MAX_PIPES) {
+				mapped_interrupt |= (interrupt & _REG_VLV_IIR_DISPLAY_PIPEA_EVENT);
+			}
+			if (vgt->pipe_mapping[1] != I915_MAX_PIPES) {
+				mapped_interrupt |= (interrupt & _REG_VLV_IIR_DISPLAY_PIPEB_EVENT);
+			}
+		} else if (_REG_VLV_GTLC_MIR == reg){
+		} else if (_REG_PMIMR == reg){
+		} else if (_REG_PMIER == reg){
+		} else if (_REG_IMR == reg){
+		} else if (_REG_GTIMR == reg){
+		} else if (_REG_GTIER == reg) {
+		} else if (_REG_BCS_IMR == reg){
+		} else {
+			vgt_dbg(VGT_DBG_IRQ, "IRQ VLV: trans_irq unknown reg = %x\n", reg);
 		}
-	} else if (_REG_DEIER == reg) {
-		mapped_interrupt &= ~irq_hstate->pipe_mask;
-		mapped_interrupt &= ~(irq_hstate->pipe_mask<<5);
-		mapped_interrupt &= ~(irq_hstate->pipe_mask<<10);
-		for (i = 0; i < I915_MAX_PIPES; i++) {
-			temp = interrupt >> (i * 5);
-			temp &= irq_hstate->pipe_mask;
-			if (vgt->pipe_mapping[i] != I915_MAX_PIPES) {
+	} else if (IS_SNB(pdev) || IS_IVB(pdev) ||IS_HSW(pdev)) {
+		if (_REG_DEIMR == reg) {
+			mapped_interrupt |= irq_hstate->pipe_mask;
+			mapped_interrupt |= (irq_hstate->pipe_mask << 5);
+			mapped_interrupt |= (irq_hstate->pipe_mask << 10);
+			// clear the initial mask bit in DEIMR for VBLANKS, so that when pipe mapping
+			// is not valid, physically there are still vblanks generated.
+			mapped_interrupt &= ~((1 << 0) | (1 << 5) | (1 << 10));
+			for (i = 0; i < I915_MAX_PIPES; i++) {
+				if (vgt->pipe_mapping[i] == I915_MAX_PIPES)
+					continue;
+
+				mapped_interrupt &= ~(irq_hstate->pipe_mask <<
+					(vgt->pipe_mapping[i] * 5));
+
+				temp = interrupt >> (i * 5);
+				temp &= irq_hstate->pipe_mask;
 				mapped_interrupt |= temp << (vgt->pipe_mapping[i] * 5);
 			}
+		} else if (_REG_DEIER == reg) {
+			mapped_interrupt &= ~irq_hstate->pipe_mask;
+			mapped_interrupt &= ~(irq_hstate->pipe_mask<<5);
+			mapped_interrupt &= ~(irq_hstate->pipe_mask<<10);
+			for (i = 0; i < I915_MAX_PIPES; i++) {
+				temp = interrupt >> (i * 5);
+				temp &= irq_hstate->pipe_mask;
+				if (vgt->pipe_mapping[i] != I915_MAX_PIPES) {
+					mapped_interrupt |= temp << (vgt->pipe_mapping[i] * 5);
+				}
+			}
 		}
 	}
 	return mapped_interrupt;
@@ -297,6 +340,8 @@ bool vgt_reg_imr_handler(struct vgt_device *vgt,
 	/* figure out newly masked/unmasked bits */
 	changed = __vreg(vgt, reg) ^ imr;
 	changed &= ~_REGBIT_MASTER_INTERRUPT;
+		/*ALANPREVIN - actually for VLV, the Display IMR BIT31 (_REGBIT_MASTER_INTERRUPT)
+		 * is actually for VXD - so its wrong, but shouldnt impact */
 	masked = (__vreg(vgt, reg) & changed) ^ changed;
 	unmasked = masked ^ changed;
 
@@ -321,8 +366,18 @@ void recalculate_and_update_ier(struct pgt_device *pdev, vgt_reg_t reg)
 
 	new_ier = vgt_recalculate_ier(pdev, reg);
 
-	if (device_is_reseting(pdev) && reg == _REG_DEIER)
-		new_ier &= ~_REGBIT_MASTER_INTERRUPT;
+	if (device_is_reseting(pdev)){
+		if(IS_VLV(pdev)){
+			if(reg == _REG_VLV_GTLC_MIR) {
+				new_ier &= ~_REGBIT_MASTER_INTERRUPT;
+			} else if (reg == _REG_VLV_IER) {
+				new_ier &= ~VLV_REGBIT_DISPMASTER_INTERRUPT;
+			}
+		} else if ((IS_SNB(pdev) || IS_IVB(pdev) || IS_HSW(pdev)) &&
+					reg == _REG_DEIER) {
+			new_ier &= ~_REGBIT_MASTER_INTERRUPT;
+		}
+	}
 	/*
 	 * may optimize by caching the old ier, and then only update
 	 * pReg when OR-ed value changes. but that requires link to
@@ -336,6 +391,154 @@ void recalculate_and_update_ier(struct pgt_device *pdev, vgt_reg_t reg)
 	vgt_put_irq_lock(pdev, flags);
 }
 
+#define VLV_PIPESTAT_IESR_CTRL_BITS     0x7FFF0000
+#define VLV_PIPESTAT_IESR_STATUS_BITS   0x8000FFFF
+#define VLV_PIPESTAT_IESR_MAPPED_BITS   0x3FBF3FBF
+
+#define VLV_PIPESTAT_IESR_SPR_AC_STAT   0x00004000
+#define VLV_PIPESTAT_IESR_SPR_AC_CTRL   0x00400000
+#define VLV_PIPESTAT_IESR_SPR_BD_STAT   0x00008000
+#define VLV_PIPESTAT_IESR_SPR_BD_CTRL   0x40000000
+
+#define VLV_PIPESTAT_IESR_FIFO_STATUS   0x80000000
+
+#define ENABLE_BIT_CHECKING_FOR_STATUS_CLEAR 0
+#define DELAYED_OTHER_VMS_ISER_STATUS_READ_BEFORE_HW_CLEAR 0
+#define UPDATE_ALL_VMS_DURING_ISER_READ 0
+
+bool vgt_reg_vlv_pipe_iser_handler_write(struct vgt_device *vgt,
+	unsigned int reg, void *p_data, unsigned int bytes)
+{
+	int i;
+	uint32_t iser = *(u32 *)p_data;
+	uint32_t new_vm_iser_ctrl   = (iser & VLV_PIPESTAT_IESR_CTRL_BITS);
+	uint32_t new_vm_iser_status = (iser & VLV_PIPESTAT_IESR_STATUS_BITS);
+	uint32_t new_hw_iser_ctrl, new_hw_iser_status;
+	uint32_t old_vm_iser;//, tmp;
+	struct pgt_device *pdev = vgt->pdev;
+
+	vgt_dbg(VGT_DBG_IRQ, "IRQ: capture PIPEXSTAT write on reg (%x) with val (%x)\n",
+		reg, iser);
+
+	vgt_dbg(VGT_DBG_IRQ, "IRQ: old VM%d vPIPEXSTAT (%x), pPIPEXSTAT(%x)\n",
+		 vgt->vm_id, __vreg(vgt, reg), VGT_MMIO_READ(pdev, reg));
+
+	/* Do the status updates first!
+
+	 * For status bit writes, just clear the bits in this VM's virt registers
+	 * However, the "other" VM may have not yet read any new status bits and may
+	 * not be aware of bits to clear and so we have to capture those "new status"
+	 * bits from HW into the other VMs first */
+	if (new_vm_iser_status) {
+
+		/* OTHER VM STATUS UPDATE?? */
+		if (DELAYED_OTHER_VMS_ISER_STATUS_READ_BEFORE_HW_CLEAR) {
+			new_hw_iser_status = (VGT_MMIO_READ(pdev, reg) & VLV_PIPESTAT_IESR_STATUS_BITS);
+			/* Handle the other VM's first in case they havent received the
+			 * updated status bits from HW yet. Here we want to "add" status bits that are
+			 * about to get cleared, if they have been enabled by other VMs
+			 */
+			for (i = 0; i < VGT_MAX_VMS; i++) {
+				if (pdev->device[i]) {
+					if(pdev->device[i] != vgt) {
+						old_vm_iser = __vreg(vgt, reg);
+						old_vm_iser |= new_hw_iser_status;
+
+						__vreg(vgt, reg) |= old_vm_iser;
+					} else {
+						/* Do nothing */
+					}
+				}
+			}
+		}
+		{ /* CURRENT VM STATUS CLEAR */
+			/* Now lets handle the "write-1-clear" for the current VM based
+			 * Do we need to do this based on the enabled bits that this VM turned on?
+			 */
+			if(ENABLE_BIT_CHECKING_FOR_STATUS_CLEAR) {
+				old_vm_iser = __vreg(vgt, reg);
+				old_vm_iser &= ~(new_vm_iser_status);
+				__vreg(vgt, reg) = old_vm_iser;
+			} else {
+				/* skip  any verification - just simulate "write-1-clear" for all status bits */
+				old_vm_iser = __vreg(vgt, reg);
+				old_vm_iser &= ~(new_vm_iser_status);
+				__vreg(vgt, reg) = old_vm_iser;
+			}
+		}
+	}
+
+	/* figure out newly enabled/disable bits that this VM wants to enable */
+	/* We really also should only allow display owner or foreground VM to apply these modifications to HW later */
+	new_hw_iser_ctrl = 0;
+	/*if (new_vm_iser_ctrl) */
+	{
+		for (i = 0; i < VGT_MAX_VMS; i++) {
+			if (pdev->device[i]) {
+				if(pdev->device[i] == vgt) {
+					if( is_current_display_owner(pdev->device[i]) || (current_foreground_vm(pdev) == pdev->device[i]) )
+						new_hw_iser_ctrl |= new_vm_iser_ctrl;
+
+					old_vm_iser = __vreg(vgt, reg) & VLV_PIPESTAT_IESR_STATUS_BITS;
+					__vreg(vgt, reg) = old_vm_iser | new_vm_iser_ctrl;
+				} else {
+					if( is_current_display_owner(pdev->device[i]) || (current_foreground_vm(pdev) == pdev->device[i]) )
+						new_hw_iser_ctrl |= (__vreg(pdev->device[i], reg) & VLV_PIPESTAT_IESR_CTRL_BITS);
+				}
+			}
+		}
+	}
+
+	VGT_MMIO_WRITE(pdev, reg, new_hw_iser_ctrl);
+	/* Notice that we only write the new "control" bits, not the "write-1-to-clear" status bits
+	 * Thats coz VMs dont need to clear status bits in HW, vgt_handle_events already does that*/
+
+	vgt_dbg(VGT_DBG_IRQ, "IRQ: new VM%d vPIPEXSTAT (%x), pPIPEXSTAT(%x)\n",
+		 vgt->vm_id, __vreg(vgt, reg), VGT_MMIO_READ(pdev, reg));
+
+	return true;
+}
+
+bool vgt_reg_vlv_pipe_iser_handler_read(struct vgt_device *vgt,
+	unsigned int reg, void *p_data, unsigned int bytes)
+{
+	int i;
+	uint32_t new_hw_iser_status, new_vm_iser;
+	uint32_t old_vm_iser;//, tmp;
+	struct pgt_device *pdev = vgt->pdev;
+
+	vgt_dbg(VGT_DBG_IRQ, "IRQ: capture PIPEXSTAT read on reg (%x)\n",reg);
+
+	vgt_dbg(VGT_DBG_IRQ, "IRQ: old VM%d vPIPEXSTAT (%x), pPIPEXSTAT(%x)\n",
+		 vgt->vm_id, __vreg(vgt, reg), VGT_MMIO_READ(pdev, reg));
+
+	new_hw_iser_status = (VGT_MMIO_READ(pdev, reg) & VLV_PIPESTAT_IESR_STATUS_BITS);
+
+	/* We should we update ALL VMs vregs during any status read? */
+	if (UPDATE_ALL_VMS_DURING_ISER_READ) {
+		/* Handle all the VM's first in case they havent received the
+		 * updated status bits from HW yet. Here we want to "add" status bits that are
+		 * about to get cleared, if they have been enabled by other VMs
+		 */
+		for (i = 0; i < VGT_MAX_VMS; i++) {
+			if (pdev->device[i]) {
+				old_vm_iser = __vreg(vgt, reg);
+				old_vm_iser |= new_hw_iser_status;
+				__vreg(vgt, reg) |= old_vm_iser;
+			}
+		}
+	}
+
+	new_vm_iser = __vreg(vgt, reg);
+	memcpy(p_data, (char *)&new_vm_iser, 4);
+
+	vgt_dbg(VGT_DBG_IRQ, "IRQ: new VM%d vPIPEXSTAT (%x), pPIPEXSTAT(%x)\n",
+		 vgt->vm_id, __vreg(vgt, reg), VGT_MMIO_READ(pdev, reg));
+
+	return true;
+}
+
+
 /* general write handler for all level-1 ier registers */
 bool vgt_reg_ier_handler(struct vgt_device *vgt,
 	unsigned int reg, void *p_data, unsigned int bytes)
@@ -393,10 +596,20 @@ bool vgt_reg_isr_read(struct vgt_device *vgt, unsigned int reg,
 	void *p_data, unsigned int bytes)
 {
 	vgt_reg_t isr_value;
-	if (is_current_display_owner(vgt) && reg == _REG_SDEISR) {
-		isr_value = VGT_MMIO_READ(vgt->pdev, _REG_SDEISR);
-		memcpy(p_data, (char *)&isr_value, bytes);
-		return true;
+	if (is_current_display_owner(vgt)) {
+		if(IS_VLV(vgt->pdev)) {
+			vgt_err("VLV trapped isr reads targetting PCH-ISRs on Core! - Need to fix this - temporarily passed to HW!\n");
+			isr_value = VGT_MMIO_READ(vgt->pdev, reg);
+			memcpy(p_data, (char *)&isr_value, bytes);
+			return true;
+		} else if ((IS_SNB(vgt->pdev) || IS_IVB(vgt->pdev) || IS_HSW(vgt->pdev)) &&
+					reg == _REG_SDEISR) {
+			isr_value = VGT_MMIO_READ(vgt->pdev, _REG_SDEISR);
+			memcpy(p_data, (char *)&isr_value, bytes);
+			return true;
+		} else {
+			return default_mmio_read(vgt, reg, p_data, bytes);
+		}
 	} else {
 		return default_mmio_read(vgt, reg, p_data, bytes);
 	}
@@ -646,6 +859,51 @@ static int vgt_inject_virtual_interrupt(struct vgt_device *vgt)
 	return 0;
 }
 
+static void vgt_vlv_propagate_event(struct vgt_irq_host_state *hstate,
+	enum vgt_event_type event, struct vgt_device *vgt)
+{
+	int bit;
+	struct vgt_irq_info *info;
+	unsigned int reg_base;
+
+	info = vgt_get_irq_info(hstate, event);
+	if (!info) {
+		vgt_err("IRQ(%d): virt-inject: no irq reg info!!!\n",
+			vgt->vm_id);
+		return;
+	}
+
+	reg_base = info->reg_base;
+	bit = hstate->events[event].bit;
+
+	/*
+	 * this function call is equivalent to a rising edge ISR
+     * TODO: need check 2nd level IMR for render events
+     */
+	if(reg_base == _REG_VLV_ISR) {
+		if (!test_bit(bit, (void*)vgt_vreg(vgt, vlv_regbase_to_imr(reg_base)))) {
+			vgt_dbg(VGT_DBG_IRQ, "IRQ: set bit (%d) for (%s) for VM (%d)\n",
+				bit, vgt_irq_name[event], vgt->vm_id);
+			set_bit(bit, (void*)vgt_vreg(vgt, vlv_regbase_to_iir(reg_base)));
+		}
+	} else { /* for GT, PM etc.. */
+		if (!test_bit(bit, (void*)vgt_vreg(vgt, regbase_to_imr(reg_base)))) {
+			vgt_dbg(VGT_DBG_IRQ, "IRQ: set bit (%d) for (%s) for VM (%d)\n",
+				bit, vgt_irq_name[event], vgt->vm_id);
+			set_bit(bit, (void*)vgt_vreg(vgt, regbase_to_iir(reg_base)));
+
+			/* TO-DO ALANPREVIN - we still havent handled PCH events for VLV DisplayPorts
+			 * But we do handle for the CRT / HDMI ports. For DP, its currently 
+			 * flowing thru to below code that handles like Core
+			 */
+			/* enabled PCH events needs queue in level-1 display */
+			if (info == hstate->info[IRQ_INFO_PCH] &&
+				test_bit(bit, (void*)vgt_vreg(vgt, regbase_to_ier(reg_base))))
+				vgt_vlv_propagate_event(hstate, PCH_IRQ, vgt);
+				/* not sure why the recursive here? */
+		}
+	}
+}
 static void vgt_propagate_event(struct vgt_irq_host_state *hstate,
 	enum vgt_event_type event, struct vgt_device *vgt)
 {
@@ -689,7 +947,10 @@ static void vgt_handle_default_event_virt(struct vgt_irq_host_state *hstate,
 			vgt->vm_id, vgt_irq_name[event]);
 		vgt_irq_warn_once[vgt->vgt_id][event] = 1;
 	}
-	vgt_propagate_event(hstate, event, vgt);
+	if(IS_VLV(vgt->pdev))
+		vgt_vlv_propagate_event(hstate, event, vgt);
+	else 
+		vgt_propagate_event(hstate, event, vgt);
 	vgt->stat.events[event]++;
 }
 
@@ -710,21 +971,40 @@ static void vgt_handle_histogram_virt(struct vgt_irq_host_state *hstate,
 static void vgt_handle_crt_hotplug_virt(struct vgt_irq_host_state *hstate,
 	enum vgt_event_type event, struct vgt_device *vgt)
 {
+	struct pgt_device *pdev = vgt->pdev;
+
 	/* update channel status */
-	if (__vreg(vgt, _REG_PCH_ADPA) & _REGBIT_ADPA_CRT_HOTPLUG_ENABLE) {
-
-		__vreg(vgt, _REG_PCH_ADPA) &=
-				~_REGBIT_ADPA_CRT_HOTPLUG_MONITOR_MASK;
-		if (is_current_display_owner(vgt)) {
-			__vreg(vgt, _REG_PCH_ADPA) |=
-					vgt_get_event_val(hstate, event) &
-					_REGBIT_ADPA_CRT_HOTPLUG_MONITOR_MASK;
-		} else if (test_bit(VGT_CRT, vgt->presented_ports)) {
-				__vreg(vgt, _REG_PCH_ADPA) |=
-					_REGBIT_ADPA_CRT_HOTPLUG_MONITOR_MASK;
+	if(IS_VLV(pdev)) {
+		if (__vreg(vgt, _REG_VLV_PCH_ADPA) & _REGBIT_ADPA_CRT_HOTPLUG_ENABLE) {
+
+			__vreg(vgt, _REG_VLV_PCH_ADPA) &=
+					~_REGBIT_ADPA_CRT_HOTPLUG_MONITOR_MASK;
+			if (is_current_display_owner(vgt)) {
+				__vreg(vgt, _REG_VLV_PCH_ADPA) |=
+						vgt_get_event_val(hstate, event) &
+						_REGBIT_ADPA_CRT_HOTPLUG_MONITOR_MASK;
+			} else if (test_bit(VGT_CRT, vgt->presented_ports)) {
+					__vreg(vgt, _REG_VLV_PCH_ADPA) |=
+						_REGBIT_ADPA_CRT_HOTPLUG_MONITOR_MASK;
+			}
+			vgt_handle_default_event_virt(hstate, event, vgt);
 		}
+	} else {
+		if (__vreg(vgt, _REG_PCH_ADPA) & _REGBIT_ADPA_CRT_HOTPLUG_ENABLE) {
+
+			__vreg(vgt, _REG_PCH_ADPA) &=
+					~_REGBIT_ADPA_CRT_HOTPLUG_MONITOR_MASK;
+			if (is_current_display_owner(vgt)) {
+				__vreg(vgt, _REG_PCH_ADPA) |=
+						vgt_get_event_val(hstate, event) &
+						_REGBIT_ADPA_CRT_HOTPLUG_MONITOR_MASK;
+			} else if (test_bit(VGT_CRT, vgt->presented_ports)) {
+					__vreg(vgt, _REG_PCH_ADPA) |=
+						_REGBIT_ADPA_CRT_HOTPLUG_MONITOR_MASK;
+			}
 
-		vgt_handle_default_event_virt(hstate, event, vgt);
+			vgt_handle_default_event_virt(hstate, event, vgt);
+		}
 	}
 }
 
@@ -732,30 +1012,49 @@ static void vgt_handle_port_hotplug_virt(struct vgt_irq_host_state *hstate,
 	enum vgt_event_type event, struct vgt_device *vgt)
 {
 	vgt_reg_t enable_mask, status_mask;
+	struct pgt_device *pdev = vgt->pdev;
 
-	if (event == DP_B_HOTPLUG) {
-		enable_mask = _REGBIT_DP_B_ENABLE;
-		status_mask = _REGBIT_DP_B_STATUS;
-	} else if (event == DP_C_HOTPLUG) {
-		enable_mask = _REGBIT_DP_C_ENABLE;
-		status_mask = _REGBIT_DP_C_STATUS;
+	if(IS_VLV(pdev)) {
+		if (event == DP_B_HOTPLUG) {
+			enable_mask = VLV_HPEN_DPB;
+			status_mask = VLV_HPSTAT_DPB_EVENT;
+		} else {
+			enable_mask = VLV_HPEN_DPC;
+			status_mask = VLV_HPSTAT_DPC_EVENT;
+		}
+		if (__vreg(vgt, _REG_VLV_PORT_HOTPLUG_EN) & enable_mask) {
+			__vreg(vgt, _REG_VLV_PORT_HOTPLUG_STAT) &= ~status_mask;
+			if (is_current_display_owner(vgt)) {
+				__vreg(vgt, _REG_VLV_PORT_HOTPLUG_STAT) |=
+					vgt_get_event_val(hstate, event) & status_mask;
+			} else {
+				__vreg(vgt, _REG_VLV_PORT_HOTPLUG_STAT) |= status_mask;
+			}
+			vgt_handle_default_event_virt(hstate, event, vgt);
+		}
 	} else {
-		ASSERT(event == DP_D_HOTPLUG);
-		enable_mask = _REGBIT_DP_D_ENABLE;
-		status_mask = _REGBIT_DP_D_STATUS;
-	}
-
-	if (__vreg(vgt, _REG_SHOTPLUG_CTL) & enable_mask) {
-
-		__vreg(vgt, _REG_SHOTPLUG_CTL) &= ~status_mask;
-		if (is_current_display_owner(vgt)) {
-			__vreg(vgt, _REG_SHOTPLUG_CTL) |=
-				vgt_get_event_val(hstate, event) & status_mask;
+		if (event == DP_B_HOTPLUG) {
+			enable_mask = _REGBIT_DP_B_ENABLE;
+			status_mask = _REGBIT_DP_B_STATUS;
+		} else if (event == DP_C_HOTPLUG) {
+			enable_mask = _REGBIT_DP_C_ENABLE;
+			status_mask = _REGBIT_DP_C_STATUS;
 		} else {
-			__vreg(vgt, _REG_SHOTPLUG_CTL) |= status_mask;
+			ASSERT(event == DP_D_HOTPLUG);
+			enable_mask = _REGBIT_DP_D_ENABLE;
+			status_mask = _REGBIT_DP_D_STATUS;
+		}
+		if (__vreg(vgt, _REG_SHOTPLUG_CTL) & enable_mask) {
+
+			__vreg(vgt, _REG_SHOTPLUG_CTL) &= ~status_mask;
+			if (is_current_display_owner(vgt)) {
+				__vreg(vgt, _REG_SHOTPLUG_CTL) |=
+					vgt_get_event_val(hstate, event) & status_mask;
+			} else {
+				__vreg(vgt, _REG_SHOTPLUG_CTL) |= status_mask;
+			}
+			vgt_handle_default_event_virt(hstate, event, vgt);
 		}
-
-		vgt_handle_default_event_virt(hstate, event, vgt);
 	}
 }
 
@@ -766,6 +1065,7 @@ static enum vgt_event_type translate_physical_event(struct vgt_device *vgt,
 	enum vgt_pipe virtual_pipe = I915_MAX_PIPES;
 	enum vgt_pipe physical_pipe = I915_MAX_PIPES;
 	enum vgt_event_type virtual_event = event;
+	struct pgt_device *pdev = vgt->pdev;
 	int i;
 
 	switch (event) {
@@ -773,7 +1073,6 @@ static enum vgt_event_type translate_physical_event(struct vgt_device *vgt,
 	case PIPE_A_LINE_COMPARE:
 	case PIPE_A_VBLANK:
 	case PRIMARY_A_FLIP_DONE:
-	case SPRITE_A_FLIP_DONE:
 		physical_pipe = PIPE_A;
 		break;
 
@@ -781,7 +1080,6 @@ static enum vgt_event_type translate_physical_event(struct vgt_device *vgt,
 	case PIPE_B_LINE_COMPARE:
 	case PIPE_B_VBLANK:
 	case PRIMARY_B_FLIP_DONE:
-	case SPRITE_B_FLIP_DONE:
 		physical_pipe = PIPE_B;
 		break;
 
@@ -789,9 +1087,36 @@ static enum vgt_event_type translate_physical_event(struct vgt_device *vgt,
 	case PIPE_C_LINE_COMPARE:
 	case PIPE_C_VBLANK:
 	case PRIMARY_C_FLIP_DONE:
-	case SPRITE_C_FLIP_DONE:
 		physical_pipe = PIPE_C;
 		break;
+	case SPRITE_A_FLIP_DONE:
+		if(IS_VLV(pdev)) {
+			physical_pipe = PIPE_A;
+		} else if (IS_SNB(pdev) || IS_IVB(pdev) ||IS_HSW(pdev)) {
+			physical_pipe = PIPE_A;
+		}
+		break;
+	case SPRITE_B_FLIP_DONE:
+		if(IS_VLV(pdev)) {
+			physical_pipe = PIPE_A;
+		} else if (IS_SNB(pdev) || IS_IVB(pdev) ||IS_HSW(pdev)) {
+			physical_pipe = PIPE_B;
+		}
+		break;
+	case SPRITE_C_FLIP_DONE:
+		if(IS_VLV(pdev)) {
+			physical_pipe = PIPE_B;
+		} else if (IS_SNB(pdev) || IS_IVB(pdev) ||IS_HSW(pdev)) {
+			physical_pipe = PIPE_C;
+		}
+		break;
+	case SPRITE_D_FLIP_DONE:
+		if(IS_VLV(pdev)) {
+			physical_pipe = PIPE_B;
+		} else if (IS_SNB(pdev) || IS_IVB(pdev) ||IS_HSW(pdev)) {
+			// HUH?!
+		}
+		break;
 	default:
 		physical_pipe = I915_MAX_PIPES;
 	}
@@ -823,6 +1148,7 @@ static void vgt_handle_default_event_phys(struct vgt_irq_host_state *hstate,
 	}
 }
 
+/* TO-DO: This function has not been ported for Baytrail */
 static void vgt_handle_phase_in_phys(struct vgt_irq_host_state *hstate,
 	enum vgt_event_type event)
 {
@@ -836,6 +1162,7 @@ static void vgt_handle_phase_in_phys(struct vgt_irq_host_state *hstate,
 	vgt_handle_default_event_phys(hstate, event);
 }
 
+/* TO-DO: This function has not been ported for Baytrail */
 static void vgt_handle_histogram_phys(struct vgt_irq_host_state *hstate,
 	enum vgt_event_type event)
 {
@@ -861,13 +1188,21 @@ static void vgt_handle_crt_hotplug_phys(struct vgt_irq_host_state *hstate,
 	vgt_reg_t adpa_ctrl;
 	struct pgt_device *pdev = hstate->pdev;
 
-	adpa_ctrl = VGT_MMIO_READ(pdev, _REG_PCH_ADPA);
+	if(IS_VLV(pdev)) {
+		adpa_ctrl = VGT_MMIO_READ(pdev, _REG_VLV_PCH_ADPA);
+	} else {
+		adpa_ctrl = VGT_MMIO_READ(pdev, _REG_PCH_ADPA);
+	}
 	if (!(adpa_ctrl & _REGBIT_ADPA_DAC_ENABLE)) {
 		vgt_warn("IRQ: captured CRT hotplug event when CRT is disabled\n");
 	}
 
 	/* write back value to clear channel status */
-	VGT_MMIO_WRITE(pdev, _REG_PCH_ADPA, adpa_ctrl);
+	if(IS_VLV(pdev)) {
+		VGT_MMIO_WRITE(pdev, _REG_VLV_PCH_ADPA, adpa_ctrl);
+	} else {
+		VGT_MMIO_WRITE(pdev, _REG_PCH_ADPA, adpa_ctrl);
+	}
 
 	/* check blue/green channel status for attachment status */
 	if (adpa_ctrl & _REGBIT_ADPA_CRT_HOTPLUG_MONITOR_MASK) {
@@ -893,33 +1228,61 @@ static void vgt_handle_port_hotplug_phys(struct vgt_irq_host_state *hstate,
 	enum vgt_uevent_type hotplug_event;
 	struct pgt_device *pdev = hstate->pdev;
 
-	if (event == DP_B_HOTPLUG) {
-		enable_mask = _REGBIT_DP_B_ENABLE;
-		status_mask = _REGBIT_DP_B_STATUS;
-		hotplug_event = PORT_B_HOTPLUG_IN;
-	} else if (event == DP_C_HOTPLUG) {
-		enable_mask = _REGBIT_DP_C_ENABLE;
-		status_mask = _REGBIT_DP_C_STATUS;
-		hotplug_event = PORT_C_HOTPLUG_IN;
+
+	if(IS_VLV(pdev)) {
+		if (event == DP_B_HOTPLUG) {
+			enable_mask = VLV_HPEN_DPB;
+			status_mask = VLV_HPSTAT_DPB_EVENT;
+			hotplug_event = PORT_B_HOTPLUG_IN;
+		} else {
+			enable_mask = VLV_HPEN_DPC;
+			status_mask = VLV_HPSTAT_DPC_EVENT;
+			hotplug_event = PORT_C_HOTPLUG_IN;
+		}
 	} else {
-		ASSERT(event == DP_D_HOTPLUG);
-		enable_mask = _REGBIT_DP_D_ENABLE;
-		status_mask = _REGBIT_DP_D_STATUS;
-		hotplug_event = PORT_D_HOTPLUG_IN;
+		if (event == DP_B_HOTPLUG) {
+			enable_mask = _REGBIT_DP_B_ENABLE;
+			status_mask = _REGBIT_DP_B_STATUS;
+			hotplug_event = PORT_B_HOTPLUG_IN;
+		} else if (event == DP_C_HOTPLUG) {
+			enable_mask = _REGBIT_DP_C_ENABLE;
+			status_mask = _REGBIT_DP_C_STATUS;
+			hotplug_event = PORT_C_HOTPLUG_IN;
+		} else {
+			ASSERT(event == DP_D_HOTPLUG);
+			enable_mask = _REGBIT_DP_D_ENABLE;
+			status_mask = _REGBIT_DP_D_STATUS;
+			hotplug_event = PORT_D_HOTPLUG_IN;
+		}
 	}
 
-	hotplug_ctrl = VGT_MMIO_READ(pdev, _REG_SHOTPLUG_CTL);
+	if(IS_VLV(pdev)) {
+		hotplug_ctrl = VGT_MMIO_READ(pdev, _REG_VLV_PORT_HOTPLUG_EN);
+	} else {
+		hotplug_ctrl = VGT_MMIO_READ(pdev, _REG_SHOTPLUG_CTL);
+	}
 
 	if (!(hotplug_ctrl & enable_mask)) {
 		vgt_warn("IRQ: captured port hotplug event when HPD is disabled\n");
 	}
 
-	tmp = hotplug_ctrl & ~(_REGBIT_DP_B_STATUS |
-				_REGBIT_DP_C_STATUS |
-				_REGBIT_DP_D_STATUS);
-	tmp |= hotplug_ctrl & status_mask;
-	/* write back value to clear specific port status */
-	VGT_MMIO_WRITE(pdev, _REG_SHOTPLUG_CTL, tmp);
+	if(IS_VLV(pdev)) {
+		/* for VLV the status bits are not the same */
+		hotplug_ctrl = VGT_MMIO_READ(pdev, _REG_VLV_PORT_HOTPLUG_STAT);
+		tmp = hotplug_ctrl & ~(VLV_HPSTAT_DPB_EVENT |
+					VLV_HPSTAT_DPC_EVENT);
+		tmp |= hotplug_ctrl & status_mask;
+		/* write back value to clear specific port status */
+		VGT_MMIO_WRITE(pdev, _REG_VLV_PORT_HOTPLUG_STAT, tmp);
+	} else {
+		tmp = hotplug_ctrl & ~(_REGBIT_DP_B_STATUS |
+					_REGBIT_DP_C_STATUS |
+					_REGBIT_DP_D_STATUS);
+		tmp |= hotplug_ctrl & status_mask;
+		/* write back value to clear specific port status */
+		VGT_MMIO_WRITE(pdev, _REG_SHOTPLUG_CTL, tmp);
+	}
+
 
 	if (hotplug_ctrl & status_mask) {
 		vgt_info("IRQ: detect monitor insert event on port!\n");
@@ -946,19 +1309,46 @@ static void vgt_handle_port_hotplug_phys(struct vgt_irq_host_state *hstate,
 static void vgt_base_check_pending_irq(struct vgt_device *vgt)
 {
 	struct vgt_irq_host_state *hstate = vgt->pdev->irq_hstate;
+	struct pgt_device *pdev = vgt->pdev;
 
-	if (!(__vreg(vgt, _REG_DEIER) & _REGBIT_MASTER_INTERRUPT))
-		return;
+	if(IS_VLV(pdev)) {
+		/* on VLV, the GTLC_MIR is a re-use from Gen7Core's DE_IER and bit31 has the
+		 * same role but excludes Display IRQ's so we need to also check the seperate
+		 * display interrupt enabling register
+		 */
+		if (   !(__vreg(vgt, _REG_VLV_GTLC_MIR) & _REGBIT_MASTER_INTERRUPT) &&
+		       !(__vreg(vgt, _REG_VLV_IER) & VLV_REGBIT_DISPMASTER_INTERRUPT) )
+			return;
+	} else {
+		if (!(__vreg(vgt, _REG_DEIER) & _REGBIT_MASTER_INTERRUPT))
+			return;
+	}
 
-	/* first try 2nd level PCH pending events */
-	if ((__vreg(vgt, _REG_SDEIIR) & __vreg(vgt, _REG_SDEIER)))
-		vgt_propagate_event(hstate, PCH_IRQ, vgt);
+	if(IS_VLV(pdev)) {
+		/* ALANPREVIN - need to grep thru the usage of this code.
+		 * Understand why PCH was propogated but others were injected!
+		 */
+		/* first try 2nd level Port pending events */
+		if ((__vreg(vgt, _REG_VLV_PORT_HOTPLUG_STAT) & _REG_VLV_IIR_HOTPLUG_EVENT))
+			vgt_vlv_propagate_event(hstate, PCH_IRQ, vgt);
+
+		/* then check 1st level pending events */
+		if ((__vreg(vgt, _REG_VLV_IIR) & __vreg(vgt, _REG_VLV_IER)) ||
+			(__vreg(vgt, _REG_GTIIR) & __vreg(vgt, _REG_GTIER)) ||
+			(__vreg(vgt, _REG_PMIIR) & __vreg(vgt, _REG_PMIER))) {
+			vgt_inject_virtual_interrupt(vgt);
+		}
+	} else if (IS_SNB(pdev) || IS_IVB(pdev) || IS_HSW(pdev)){
+		/* first try 2nd level PCH pending events */
+		if ((__vreg(vgt, _REG_SDEIIR) & __vreg(vgt, _REG_SDEIER)))
+			vgt_propagate_event(hstate, PCH_IRQ, vgt);
 
-	/* then check 1st level pending events */
-	if ((__vreg(vgt, _REG_DEIIR) & __vreg(vgt, _REG_DEIER)) ||
-	    (__vreg(vgt, _REG_GTIIR) & __vreg(vgt, _REG_GTIER)) ||
-	    (__vreg(vgt, _REG_PMIIR) & __vreg(vgt, _REG_PMIER))) {
-		vgt_inject_virtual_interrupt(vgt);
+		/* then check 1st level pending events */
+		if ((__vreg(vgt, _REG_DEIIR) & __vreg(vgt, _REG_DEIER)) ||
+			(__vreg(vgt, _REG_GTIIR) & __vreg(vgt, _REG_GTIER)) ||
+			(__vreg(vgt, _REG_PMIIR) & __vreg(vgt, _REG_PMIER))) {
+			vgt_inject_virtual_interrupt(vgt);
+		}
 	}
 }
 
@@ -967,42 +1357,101 @@ static void vgt_base_check_pending_irq(struct vgt_device *vgt)
 /* base interrupt handler, for snb/ivb/hsw */
 static irqreturn_t vgt_base_irq_handler(struct vgt_irq_host_state *hstate)
 {
-	u32 gt_iir, pm_iir, de_iir, pch_iir, de_iir_tmp;
+	u32 gt_iir, pm_iir, de_iir=0, pch_iir, de_iir_tmp, de_iir_hotplug_vlv;
 	int pch_bit;
 	int count = 0;
 	struct pgt_device *pdev = hstate->pdev;
+	static int dbg_threshold = 0;
+	static int dbg_enter = 0;
+	static int dbg_none = 0;
+	static int dbg_disp = 0;
+	static int dbg_hplug = 0;
+	static int dbg_gt = 0;
+	static int dbg_pm = 0;
+
+	++dbg_threshold;
+	++dbg_enter;
+
+	if(IS_VLV(pdev)){
+		/* read physical IIRs */
+		gt_iir = VGT_MMIO_READ(pdev, _REG_GTIIR); //same as IVB/HSW
+		de_iir = VGT_MMIO_READ(pdev, _REG_VLV_IIR); // VLV specific multi-level IIR
+		pm_iir = VGT_MMIO_READ(pdev, _REG_PMIIR); //same as IVB/HSW
+	} else if (IS_SNB(pdev) || IS_IVB(pdev) || IS_HSW(pdev)){
+		/* read physical IIRs */
+		gt_iir = VGT_MMIO_READ(pdev, _REG_GTIIR);
+		de_iir = VGT_MMIO_READ(pdev, _REG_DEIIR);
+		pm_iir = VGT_MMIO_READ(pdev, _REG_PMIIR);
 
-	/* read physical IIRs */
-	gt_iir = VGT_MMIO_READ(pdev, _REG_GTIIR);
-	de_iir = VGT_MMIO_READ(pdev, _REG_DEIIR);
-	pm_iir = VGT_MMIO_READ(pdev, _REG_PMIIR);
+	}
 
-	if (!gt_iir && !de_iir && !pm_iir)
+	if (!gt_iir && !de_iir && !pm_iir) {
+		++dbg_none;
+		if(!(dbg_threshold%DBG_IRQ_DISP_THRESHOLD)) {
+			vgt_dbg(VGT_DBG_IRQ, "VGT_DBG_IRQ, irq_handler total=%d | none=%d | hplug=%d | disp=%d | gt=%d | pm=%d\n",
+				dbg_enter, dbg_none, dbg_hplug, dbg_disp, dbg_gt, dbg_pm);
+		}
 		return IRQ_NONE;
+	}
+	if(pm_iir) ++dbg_pm;
+	if(gt_iir) ++dbg_gt;
 
 	vgt_handle_events(hstate, &gt_iir, IRQ_INFO_GT);
 
-	pch_bit = hstate->events[PCH_IRQ].bit;
-	ASSERT(hstate->events[PCH_IRQ].info);
-	de_iir_tmp = de_iir & (~(1 << pch_bit));
-	vgt_handle_events(hstate, &de_iir_tmp, IRQ_INFO_DPY);
+	if(IS_VLV(pdev)){
+		/* for PCH vs DPY, check 2nd level IIRs */
+		if (de_iir & ( _REG_VLV_IIR_DISPLAY_PIPEA_EVENT | _REG_VLV_IIR_DISPLAY_PIPEB_EVENT)){
+			++dbg_disp;
+			if(!(dbg_threshold%DBG_IRQ_DISP_THRESHOLD)) {
+				vgt_dbg(VGT_DBG_IRQ, "VGT_DBG_IRQ, irq_handler total=%d | none=%d | hplug=%d | disp=%d | gt=%d | pm=%d\n",
+					dbg_enter, dbg_none, dbg_hplug, dbg_disp, dbg_gt, dbg_pm);
+			}
+			vgt_handle_events(hstate, &de_iir, IRQ_INFO_DPY);
+		}
+		if (de_iir & _REG_VLV_IIR_HOTPLUG_EVENT) {
+			++dbg_hplug;
+			if(!(dbg_threshold%DBG_IRQ_DISP_THRESHOLD)) {
+				vgt_dbg(VGT_DBG_IRQ, "VGT_DBG_IRQ, irq_handler total=%d | none=%d | hplug=%d | disp=%d | gt=%d | pm=%d\n",
+					dbg_enter, dbg_none, dbg_hplug, dbg_disp, dbg_gt, dbg_pm);
+			}
+			de_iir_hotplug_vlv = VGT_MMIO_READ(pdev, _REG_VLV_PORT_HOTPLUG_STAT);
+			VGT_MMIO_WRITE(pdev, _REG_VLV_PORT_HOTPLUG_STAT, de_iir_hotplug_vlv);
+			de_iir_hotplug_vlv &= VLV_HPSTAT_EVENTS;
+			vgt_handle_events(hstate, &de_iir_hotplug_vlv, IRQ_INFO_PCH);
+		}
+
+		vgt_handle_events(hstate, &pm_iir, IRQ_INFO_PM);
 
-	vgt_handle_events(hstate, &pm_iir, IRQ_INFO_PM);
+	} else if (IS_SNB(pdev) || IS_IVB(pdev) || IS_HSW(pdev)){
+		/* read physical IIRs */
+		pch_bit = hstate->events[PCH_IRQ].bit;
+		ASSERT(hstate->events[PCH_IRQ].info);
+		de_iir_tmp = de_iir & (~(1 << pch_bit));
+		vgt_handle_events(hstate, &de_iir_tmp, IRQ_INFO_DPY);
 
-	if (de_iir & (1 << pch_bit)) {
-		pch_iir = VGT_MMIO_READ(pdev, _REG_SDEIIR);
-		vgt_handle_events(hstate, &pch_iir, IRQ_INFO_PCH);
+		vgt_handle_events(hstate, &pm_iir, IRQ_INFO_PM);
 
-		while((count < IIR_WRITE_MAX) && (pch_iir != 0)) {
-			VGT_MMIO_WRITE(pdev, _REG_SDEIIR, pch_iir);
+		if (de_iir & (1 << pch_bit)) {
 			pch_iir = VGT_MMIO_READ(pdev, _REG_SDEIIR);
-			count ++;
+			vgt_handle_events(hstate, &pch_iir, IRQ_INFO_PCH);
+
+			while((count < IIR_WRITE_MAX) && (pch_iir != 0)) {
+				VGT_MMIO_WRITE(pdev, _REG_SDEIIR, pch_iir);
+				pch_iir = VGT_MMIO_READ(pdev, _REG_SDEIIR);
+				count ++;
+			}
 		}
 	}
 
-	VGT_MMIO_WRITE(pdev, _REG_GTIIR, gt_iir);
-	VGT_MMIO_WRITE(pdev, _REG_PMIIR, pm_iir);
-	VGT_MMIO_WRITE(pdev, _REG_DEIIR, de_iir);
+	if(IS_VLV(pdev)){
+		VGT_MMIO_WRITE(pdev, _REG_GTIIR,   gt_iir); // same as IVB/HSW
+		VGT_MMIO_WRITE(pdev, _REG_PMIIR,   pm_iir); // same as IVB/HSW
+		VGT_MMIO_WRITE(pdev, _REG_VLV_IIR, de_iir);
+	} else if (IS_SNB(pdev) || IS_IVB(pdev) || IS_HSW(pdev)){
+		VGT_MMIO_WRITE(pdev, _REG_GTIIR, gt_iir);
+		VGT_MMIO_WRITE(pdev, _REG_PMIIR, pm_iir);
+		VGT_MMIO_WRITE(pdev, _REG_DEIIR, de_iir);
+	}
 
 	return IRQ_HANDLED;
 }
@@ -1019,13 +1468,23 @@ static struct vgt_irq_info vgt_base_dpy_info = {
 	.reg_base = _REG_DEISR,
 	.bit_to_event = {[0 ... VGT_IRQ_BITWIDTH-1] = EVENT_RESERVED},
 };
-
+static struct vgt_irq_info vgt_base_vlv_dpy_1stlevel_info = {
+	.name = "VLV-DPY-LEVEL1-IRQ",
+	.reg_base = _REG_VLV_ISR,
+	.bit_to_event = {[0 ... VGT_IRQ_BITWIDTH-1] = EVENT_RESERVED},
+};
 static struct vgt_irq_info vgt_base_pch_info = {
 	.name = "PCH-IRQ",
 	.reg_base = _REG_SDEISR,
 	.bit_to_event = {[0 ... VGT_IRQ_BITWIDTH-1] = EVENT_RESERVED},
 };
 
+static struct vgt_irq_info vgt_base_vlv_hotplug_info = {
+	.name = "VLV-HOTPLUG-IRQ",
+	.reg_base = _REG_VLV_PORT_HOTPLUG_STAT,
+	.bit_to_event = {[0 ... VGT_IRQ_BITWIDTH-1] = EVENT_RESERVED},
+};
+
 static struct vgt_irq_info vgt_base_pm_info = {
 	.name = "PM-IRQ",
 	.reg_base = _REG_PMISR,
@@ -1046,13 +1505,20 @@ static void vgt_base_init_irq(
 		s->info[i]->bit_to_event[b] = e;\
 	} while (0);
 
-	hstate->pipe_mask = REGBIT_INTERRUPT_PIPE_MASK;
-
-	hstate->info[IRQ_INFO_GT] = &vgt_base_gt_info;
-	hstate->info[IRQ_INFO_DPY] = &vgt_base_dpy_info;
-	hstate->info[IRQ_INFO_PCH] = &vgt_base_pch_info;
-	hstate->info[IRQ_INFO_PM] = &vgt_base_pm_info;
 
+	if (IS_VLV(pdev)) {
+		hstate->pipe_mask = 0;//For now, we dont use "pipe_mask" for VLV
+		hstate->info[IRQ_INFO_GT]  = &vgt_base_gt_info;
+		hstate->info[IRQ_INFO_DPY] = &vgt_base_vlv_dpy_1stlevel_info;
+		hstate->info[IRQ_INFO_PCH] = &vgt_base_vlv_hotplug_info;
+		hstate->info[IRQ_INFO_PM]  = &vgt_base_pm_info;
+	} else if (IS_SNB(pdev) || IS_IVB(pdev) || IS_HSW(pdev)){
+		hstate->pipe_mask = REGBIT_INTERRUPT_PIPE_MASK;
+		hstate->info[IRQ_INFO_GT]  = &vgt_base_gt_info;
+		hstate->info[IRQ_INFO_DPY] = &vgt_base_dpy_info;
+		hstate->info[IRQ_INFO_PCH] = &vgt_base_pch_info;
+		hstate->info[IRQ_INFO_PM]  = &vgt_base_pm_info;
+	}
 	/* Render events */
 	SET_BIT_INFO(hstate, 0, RCS_MI_USER_INTERRUPT, IRQ_INFO_GT);
 	SET_BIT_INFO(hstate, 4, RCS_PIPE_CONTROL, IRQ_INFO_GT);
@@ -1064,7 +1530,42 @@ static void vgt_base_init_irq(
 	SET_BIT_INFO(hstate, 13, VECS_MI_FLUSH_DW, IRQ_INFO_PM);
 
 	/* Display events */
-	if (IS_IVB(pdev) || IS_HSW(pdev)) {
+	if (IS_VLV(pdev)) {
+		/* FOR VLV, its a bit interesting because :
+		 * display pipe A events are indicated in a seperate PIPEASTATUS register
+		 * display pipe B events are indicated in a seperate PIPEBSTATUS register
+		 * display hotplug events are indicated in a seperate hotplug status register
+		 * Thus, below will see duplicating bits re-occuring for different events
+		 * but this is okay since the main vgt handler will read different registers
+		 * and make seperate calls vgt_handle_events with new seperate IRQ register
+		 * group types specific for VLV (not sure if this is an overkill)
+		 */
+		 /* All the Pipe-A events : */
+
+		SET_BIT_INFO(hstate,  7, PIPE_A_VBLANK, IRQ_INFO_DPY);
+		SET_BIT_INFO(hstate,  6, PRIMARY_A_FLIP_DONE, IRQ_INFO_DPY);
+		SET_BIT_INFO(hstate,  6, SPRITE_A_FLIP_DONE, IRQ_INFO_DPY);
+		//SET_BIT_INFO(hstate,  6, SPRITE_B_FLIP_DONE, IRQ_INFO_VLV_DPYA);
+		/*GMBUS bit is lost in pipe-a-stat :( */
+		//SET_BIT_INFO(hstate, 11, GMBUS, IRQ_INFO_VLV_DPYA);
+		 /* All the Pipe-B events : */
+		SET_BIT_INFO(hstate,  5, PIPE_B_VBLANK, IRQ_INFO_DPY);
+		SET_BIT_INFO(hstate,  4, PRIMARY_B_FLIP_DONE, IRQ_INFO_DPY);
+		SET_BIT_INFO(hstate,  4, SPRITE_C_FLIP_DONE, IRQ_INFO_DPY);
+		//SET_BIT_INFO(hstate,  4, SPRITE_D_FLIP_DONE, IRQ_INFO_VLV_DPYB);
+		//SET_BIT_INFO(hstate,  7, DPST_MIXED_B, IRQ_INFO_VLV_DPYB);
+
+		/* Port status events */
+		SET_BIT_INFO(hstate,  4, AUX_CHENNEL_B, IRQ_INFO_PCH);
+		SET_BIT_INFO(hstate,  5, AUX_CHENNEL_C, IRQ_INFO_PCH);
+		SET_BIT_INFO(hstate, 18, DP_B_HOTPLUG, IRQ_INFO_PCH);
+		SET_BIT_INFO(hstate, 20, DP_C_HOTPLUG, IRQ_INFO_PCH);
+		SET_BIT_INFO(hstate, 11, CRT_HOTPLUG, IRQ_INFO_PCH);
+		/* ALANPREVIN FIXME - have to investigate if we eventually we'll need to put
+		 * in ISP and VXD interrupts since those are part of IGD Master-GTLC IRQ too.
+		 */
+
+	} else if (IS_IVB(pdev) || IS_HSW(pdev)) {
 		SET_BIT_INFO(hstate, 0, PIPE_A_VBLANK, IRQ_INFO_DPY);
 		SET_BIT_INFO(hstate, 3, PRIMARY_A_FLIP_DONE, IRQ_INFO_DPY);
 		SET_BIT_INFO(hstate, 4, SPRITE_A_FLIP_DONE, IRQ_INFO_DPY);
@@ -1104,15 +1605,17 @@ static void vgt_base_init_irq(
 	SET_BIT_INFO(hstate, 24, PCU_THERMAL, IRQ_INFO_PM);
 	SET_BIT_INFO(hstate, 25, PCU_PCODE2DRIVER_MAILBOX, IRQ_INFO_PM);
 
-	/* PCH events */
-	SET_BIT_INFO(hstate, 17, GMBUS, IRQ_INFO_PCH);
-	SET_BIT_INFO(hstate, 19, CRT_HOTPLUG, IRQ_INFO_PCH);
-	SET_BIT_INFO(hstate, 21, DP_B_HOTPLUG, IRQ_INFO_PCH);
-	SET_BIT_INFO(hstate, 22, DP_C_HOTPLUG, IRQ_INFO_PCH);
-	SET_BIT_INFO(hstate, 23, DP_D_HOTPLUG, IRQ_INFO_PCH);
-	SET_BIT_INFO(hstate, 25, AUX_CHENNEL_B, IRQ_INFO_PCH);
-	SET_BIT_INFO(hstate, 26, AUX_CHENNEL_C, IRQ_INFO_PCH);
-	SET_BIT_INFO(hstate, 27, AUX_CHENNEL_D, IRQ_INFO_PCH);
+	/* Core PCH events */
+	if (!IS_VLV(pdev)) {
+		SET_BIT_INFO(hstate, 17, GMBUS, IRQ_INFO_PCH);
+		SET_BIT_INFO(hstate, 19, CRT_HOTPLUG, IRQ_INFO_PCH);
+		SET_BIT_INFO(hstate, 21, DP_B_HOTPLUG, IRQ_INFO_PCH);
+		SET_BIT_INFO(hstate, 22, DP_C_HOTPLUG, IRQ_INFO_PCH);
+		SET_BIT_INFO(hstate, 23, DP_D_HOTPLUG, IRQ_INFO_PCH);
+		SET_BIT_INFO(hstate, 25, AUX_CHENNEL_B, IRQ_INFO_PCH);
+		SET_BIT_INFO(hstate, 26, AUX_CHENNEL_C, IRQ_INFO_PCH);
+		SET_BIT_INFO(hstate, 27, AUX_CHENNEL_D, IRQ_INFO_PCH);
+	}
 }
 
 struct vgt_irq_ops vgt_base_irq_ops = {
@@ -1135,6 +1638,8 @@ void vgt_trigger_virtual_event(struct vgt_device *vgt,
 	vgt_event_virt_handler_t handler;
 	struct vgt_irq_ops *ops = vgt_get_irq_ops(pdev);
 
+	vgt_dbg(VGT_DBG_IRQ, "VGT_DBG_IRQ, IRQ: Trigger: %s\n", vgt_irq_name[event]);
+
 	ASSERT(spin_is_locked(&pdev->lock));
 
 	handler = vgt_get_event_virt_handler(hstate, event);
@@ -1279,9 +1784,57 @@ static void vgt_handle_events(struct vgt_irq_host_state *hstate, void *iir,
 	struct vgt_irq_info *info = hstate->info[type];
 	vgt_event_phys_handler_t handler;
 	struct pgt_device *pdev = hstate->pdev;
+	static int dbg_disp_threshold = 0;
+	static int dbg_gt_threshold = 0;
+	uint32_t iir_val = *((u32*)iir);
+	uint32_t ori_hw_iser, new_hw_iser_status, old_vm_iser;
+	int pipe, reg, i;
 
 	ASSERT(spin_is_locked(&pdev->irq_lock));
 
+	if((type == IRQ_INFO_DPY) || (type == IRQ_INFO_PCH))
+		++dbg_disp_threshold;
+	else
+		++dbg_gt_threshold;
+
+	if( IS_VLV(pdev) &&
+		(type==IRQ_INFO_DPY) &&
+		(iir_val & (_REG_VLV_IIR_DISPLAY_PIPEA_EVENT | _REG_VLV_IIR_DISPLAY_PIPEB_EVENT))) {
+		/* So for VLV, we need to handle the display events a bit differently from Core *
+		 * There is a multi-level IRQ scheme in VLV and the 2nd-level bits are NOT well
+		 * organized according to general IER/IMR/IIR style mappings. So lets handle that here*/
+
+	 	if(!(dbg_disp_threshold % DBG_IRQ_DISP_THRESHOLD)) {
+			vgt_dbg(VGT_DBG_IRQ, "IRQ: handle_events for 2nd level disp pipe events\n");
+		}
+		for (pipe=0; pipe<2; ++pipe) {
+			if(!pipe) {
+				if(!(iir_val & _REG_VLV_IIR_DISPLAY_PIPEA_EVENT))
+					continue;
+			} else {
+				if(!(iir_val & _REG_VLV_IIR_DISPLAY_PIPEB_EVENT))
+					continue;
+			}
+			reg = VGT_VLV_PIPESTAT(pipe);
+			ori_hw_iser = VGT_MMIO_READ(pdev, reg);
+			new_hw_iser_status = (ori_hw_iser & VLV_PIPESTAT_IESR_STATUS_BITS);
+			/* We should we update ALL VMs vregs for any future status read
+			 * and we need to "OR" in existing status bits that VM hasnt read yet.
+			 * Here we want to add "OR-in" status bits that are
+			 * about to get cleared, if they have been enabled by other VMs
+			 */
+			for (i = 0; i < VGT_MAX_VMS; i++) {
+				if (pdev->device[i]) {
+					struct vgt_device *vgt = pdev->device[i];
+					old_vm_iser  = __vreg(vgt, reg);
+					old_vm_iser |= new_hw_iser_status;
+					__vreg(vgt, reg) |= old_vm_iser;
+				}
+			}
+			VGT_MMIO_WRITE(pdev, reg, ori_hw_iser);
+		}
+	}
+
 	for_each_set_bit(bit, iir, VGT_IRQ_BITWIDTH) {
 		event = info->bit_to_event[bit];
 		pdev->stat.events[event]++;
@@ -1293,6 +1846,14 @@ static void vgt_handle_events(struct vgt_irq_host_state *hstate, void *iir,
 			continue;
 		}
 
+		if(!(dbg_gt_threshold % DBG_IRQ_GT_THRESHOLD)) {
+			int loop;
+			vgt_dbg(VGT_DBG_IRQ, "IRQ: handle_gt_events summary:\n");
+			for (loop=0; loop<EVENT_MAX; ++loop) {
+				vgt_dbg(VGT_DBG_IRQ, "     - event (%s) = %lld\n", vgt_irq_name[loop], pdev->stat.events[loop]);
+			}
+		}
+
 		handler = vgt_get_event_phys_handler(hstate, event);
 		ASSERT(handler);
 
@@ -1310,9 +1871,10 @@ static irqreturn_t vgt_interrupt(int irq, void *data)
 {
 	struct pgt_device *pdev = (struct pgt_device *)data;
 	struct vgt_irq_host_state *hstate = pdev->irq_hstate;
-	u32 de_ier;
+	u32 de_ier=0, gtlc_mir=0;
 	irqreturn_t ret;
 	int cpu;
+	static int dbg_threshold = 0;
 
 	cpu = vgt_enter();
 
@@ -1320,15 +1882,36 @@ static irqreturn_t vgt_interrupt(int irq, void *data)
 	pdev->stat.last_pirq = get_cycles();
 
 	spin_lock(&pdev->irq_lock);
-	vgt_dbg(VGT_DBG_IRQ, "IRQ: receive interrupt (de-%x, gt-%x, pch-%x, pm-%x)\n",
-		VGT_MMIO_READ(pdev, _REG_DEIIR),
-		VGT_MMIO_READ(pdev, _REG_GTIIR),
-		VGT_MMIO_READ(pdev, _REG_SDEIIR),
-		VGT_MMIO_READ(pdev, _REG_PMIIR));
+	++dbg_threshold;
+
+	if(IS_VLV(pdev)) {
+		if(!(dbg_threshold%DBG_IRQ_DISP_THRESHOLD)) {
+			vgt_dbg(VGT_DBG_IRQ, "VGT_DBG_IRQ, IRQ: receive interrupt (de-%x, gt-%x, pm-%x)\n",
+				VGT_MMIO_READ(pdev, _REG_VLV_IIR),
+				VGT_MMIO_READ(pdev, _REG_GTIIR),
+				VGT_MMIO_READ(pdev, _REG_PMIIR));
+		}
+
+		/* VLV-GT side - avoid nested handling by disabling master interrupt for GT side*/
+		gtlc_mir = VGT_MMIO_READ(pdev, _REG_VLV_GTLC_MIR);
+		VGT_MMIO_WRITE(pdev, _REG_VLV_GTLC_MIR, gtlc_mir & ~_REGBIT_MASTER_INTERRUPT);
+		/* VLV-Display side - avoid nested handling by disabling master interrupt display GT side*/
+		de_ier = VGT_MMIO_READ(pdev, _REG_VLV_IER);
+		VGT_MMIO_WRITE(pdev, _REG_VLV_IER, de_ier & ~VLV_REGBIT_DISPMASTER_INTERRUPT);
+
+	} else if (IS_SNB(pdev) || IS_IVB(pdev) ||IS_HSW(pdev)) {
+		if(!(dbg_threshold%DBG_IRQ_DISP_THRESHOLD)) {
+			vgt_dbg(VGT_DBG_IRQ, "IRQ: receive interrupt (de-%x, gt-%x, pch-%x, pm-%x)\n",
+				VGT_MMIO_READ(pdev, _REG_DEIIR),
+				VGT_MMIO_READ(pdev, _REG_GTIIR),
+				VGT_MMIO_READ(pdev, _REG_SDEIIR),
+				VGT_MMIO_READ(pdev, _REG_PMIIR));
+		}
+		/* avoid nested handling by disabling master interrupt */
+		de_ier = VGT_MMIO_READ(pdev, _REG_DEIER);
+		VGT_MMIO_WRITE(pdev, _REG_DEIER, de_ier & ~_REGBIT_MASTER_INTERRUPT);
+	}
 
-	/* avoid nested handling by disabling master interrupt */
-	de_ier = VGT_MMIO_READ(pdev, _REG_DEIER);
-	VGT_MMIO_WRITE(pdev, _REG_DEIER, de_ier & ~_REGBIT_MASTER_INTERRUPT);
 
 	ret = hstate->ops->irq_handler(hstate);
 	if (ret == IRQ_NONE) {
@@ -1340,7 +1923,12 @@ static irqreturn_t vgt_interrupt(int irq, void *data)
 
 out:
 	/* re-enable master interrupt */
-	VGT_MMIO_WRITE(pdev, _REG_DEIER, de_ier);
+	if(IS_VLV(pdev)) {
+		VGT_MMIO_WRITE(pdev, _REG_VLV_GTLC_MIR, gtlc_mir);
+		VGT_MMIO_WRITE(pdev, _REG_VLV_IER, de_ier);
+	} else if (IS_SNB(pdev) || IS_IVB(pdev) ||IS_HSW(pdev)) {
+		VGT_MMIO_WRITE(pdev, _REG_DEIER, de_ier);
+	}
 	spin_unlock(&pdev->irq_lock);
 
 	pdev->stat.pirq_cycles += get_cycles() - pdev->stat.last_pirq;
@@ -1457,7 +2045,7 @@ int vgt_irq_init(struct pgt_device *pdev)
 	if (hstate == NULL)
 		return -ENOMEM;
 
-	if (IS_SNB(pdev) || IS_IVB(pdev) || IS_HSW(pdev))
+	if (IS_SNB(pdev) || IS_IVB(pdev) || IS_HSW(pdev) || IS_VLV(pdev))
 		hstate->ops = &vgt_base_irq_ops;
 	else {
 		vgt_err("Unsupported device\n");
@@ -1577,9 +2165,21 @@ void vgt_uninstall_irq(struct pci_dev *pdev)
 		return;
 	}
 
-	/* Mask all GEN interrupts */
-	VGT_MMIO_WRITE(pgt, _REG_DEIER,
-		VGT_MMIO_READ(pgt, _REG_DEIER) & ~_REGBIT_MASTER_INTERRUPT);
+	if(IS_VLV(pgt)) {
+		/* VLV-GT Side - Mask all interrupts */
+		VGT_MMIO_WRITE(pgt, _REG_VLV_GTLC_MIR,
+			VGT_MMIO_READ(pgt, _REG_VLV_GTLC_MIR) & ~_REGBIT_MASTER_INTERRUPT);
+		/* VLV-Display side - Mask all interrupts */
+		VGT_MMIO_WRITE(pgt, _REG_VLV_IER,
+			VGT_MMIO_READ(pgt, _REG_VLV_IER) & ~VLV_REGBIT_DISPMASTER_INTERRUPT);
+
+	} else if (IS_SNB(pgt) || IS_IVB(pgt) ||IS_HSW(pgt)) {
+		/* Mask all GEN interrupts */
+		VGT_MMIO_WRITE(pgt, _REG_DEIER,
+			VGT_MMIO_READ(pgt, _REG_DEIER) & ~_REGBIT_MASTER_INTERRUPT);
+	}
+
+
 
 	hstate = pgt->irq_hstate;
 
diff --git a/drivers/xen/vgt/mmio.c b/drivers/xen/vgt/mmio.c
index cf027cb..1331036 100644
--- a/drivers/xen/vgt/mmio.c
+++ b/drivers/xen/vgt/mmio.c
@@ -346,9 +346,13 @@ bool vgt_emulate_read(struct vgt_device *vgt, uint64_t pa, void *p_data,int byte
 			goto err_mmio;
 
 	if (!reg_is_tracked(pdev, offset) && vgt->warn_untrack) {
+		unsigned int offset2 = 0;
+		if(IS_VLV(pdev)) {
+			if (offset>0x180000) offset2 = offset-0x180000;
+		}
 		vgt_warn("vGT: untracked MMIO read: vm_id(%d), offset=0x%x,"
-			"len=%d, val=0x%x!!!\n",
-			vgt->vm_id, offset, bytes, *(u32 *)p_data);
+			"len=%d, val=0x%x!!! base_off=0x%x\n",
+			vgt->vm_id, offset, bytes, *(u32 *)p_data, offset2);
 
 		if (offset == 0x206c) {
 			printk("------------------------------------------\n");
@@ -444,9 +448,13 @@ bool vgt_emulate_write(struct vgt_device *vgt, uint64_t pa,
 	}
 
 	if (!reg_is_tracked(pdev, offset) && vgt->warn_untrack) {
+		unsigned int offset2 = 0;
+		if(IS_VLV(pdev)) {
+			if (offset>0x180000) offset2 = offset-0x180000;
+		}
 		vgt_warn("vGT: untracked MMIO write: vm_id(%d), offset=0x%x,"
-			"len=%d, val=0x%x!!!\n",
-			vgt->vm_id, offset, bytes, *(u32 *)p_data);
+			"len=%d, val=0x%x!!! base_off=0x%x\n",
+			vgt->vm_id, offset, bytes, *(u32 *)p_data, offset2);
 
 		//WARN_ON(vgt->vm_id == 0); /* The call stack is meaningless for HVM */
 	}
@@ -1091,32 +1099,52 @@ bool vgt_initial_mmio_setup (struct pgt_device *pdev)
 	/* GMBUS2 has an in-use bit as the hw semaphore, and we should recover
 	 * it after the snapshot.
 	 */
-	pdev->initial_mmio_state[REG_INDEX(_REG_PCH_GMBUS2)] &= ~0x8000;
-	VGT_MMIO_WRITE(pdev, _REG_PCH_GMBUS2,
-			VGT_MMIO_READ(pdev, _REG_PCH_GMBUS2) | 0x8000);
-
-	pdev->initial_mmio_state[REG_INDEX(_REG_DDI_BUF_CTL_A)] &=
-				~_DDI_BUFCTL_DETECT_MASK;
-	pdev->initial_mmio_state[REG_INDEX(_REG_TRANS_DDI_FUNC_CTL_A)] &=
-				~_REGBIT_TRANS_DDI_FUNC_ENABLE;
-	pdev->initial_mmio_state[REG_INDEX(_REG_TRANS_DDI_FUNC_CTL_B)] &=
-				~_REGBIT_TRANS_DDI_FUNC_ENABLE;
-	pdev->initial_mmio_state[REG_INDEX(_REG_TRANS_DDI_FUNC_CTL_C)] &=
-				~_REGBIT_TRANS_DDI_FUNC_ENABLE;
-	pdev->initial_mmio_state[REG_INDEX(_REG_TRANS_DDI_FUNC_CTL_EDP)] &=
-				~_REGBIT_TRANS_DDI_FUNC_ENABLE;
-
-	pdev->initial_mmio_state[REG_INDEX(_REG_PIPEACONF)] &=
-				~_REGBIT_PIPE_ENABLE;
-	pdev->initial_mmio_state[REG_INDEX(_REG_PIPEBCONF)] &=
-				~_REGBIT_PIPE_ENABLE;
-	pdev->initial_mmio_state[REG_INDEX(_REG_PIPECCONF)] &=
-				~_REGBIT_PIPE_ENABLE;
-	pdev->initial_mmio_state[REG_INDEX(_REG_PIPE_EDP_CONF)] &=
-				~_REGBIT_PIPE_ENABLE;
-
-	pdev->initial_mmio_state[REG_INDEX(_REG_DP_TP_CTL_E)] &=
-				~_REGBIT_DP_TP_ENABLE;
+	if(IS_VLV(pdev)) {
+		pdev->initial_mmio_state[REG_INDEX(_REG_VLV_GMBUS2)] &= ~0x8000;
+		VGT_MMIO_WRITE(pdev, _REG_VLV_GMBUS2,
+				VGT_MMIO_READ(pdev, _REG_VLV_GMBUS2) | 0x8000);
+
+		pdev->initial_mmio_state[REG_INDEX(_REG_VLV_PIPEACONF)] &=
+					~_REGBIT_PIPE_ENABLE;
+		pdev->initial_mmio_state[REG_INDEX(_REG_VLV_PIPEBCONF)] &=
+					~_REGBIT_PIPE_ENABLE;
+		/* ALANPREVIN - for now we're not dealing with DP/eDP */
+		/*
+		pdev->initial_mmio_state[REG_INDEX(_REG_PIPE_EDP_CONF)] &=
+					~_REGBIT_PIPE_ENABLE;
+		pdev->initial_mmio_state[REG_INDEX(_REG_DP_TP_CTL_E)] &=
+					~_REGBIT_DP_TP_ENABLE;
+		*/
+
+	} else {
+		pdev->initial_mmio_state[REG_INDEX(_REG_PCH_GMBUS2)] &= ~0x8000;
+		VGT_MMIO_WRITE(pdev, _REG_PCH_GMBUS2,
+				VGT_MMIO_READ(pdev, _REG_PCH_GMBUS2) | 0x8000);
+
+		pdev->initial_mmio_state[REG_INDEX(_REG_DDI_BUF_CTL_A)] &=
+					~_DDI_BUFCTL_DETECT_MASK;
+		pdev->initial_mmio_state[REG_INDEX(_REG_TRANS_DDI_FUNC_CTL_A)] &=
+					~_REGBIT_TRANS_DDI_FUNC_ENABLE;
+		pdev->initial_mmio_state[REG_INDEX(_REG_TRANS_DDI_FUNC_CTL_B)] &=
+					~_REGBIT_TRANS_DDI_FUNC_ENABLE;
+		pdev->initial_mmio_state[REG_INDEX(_REG_TRANS_DDI_FUNC_CTL_C)] &=
+					~_REGBIT_TRANS_DDI_FUNC_ENABLE;
+		pdev->initial_mmio_state[REG_INDEX(_REG_TRANS_DDI_FUNC_CTL_EDP)] &=
+					~_REGBIT_TRANS_DDI_FUNC_ENABLE;
+
+		pdev->initial_mmio_state[REG_INDEX(_REG_PIPEACONF)] &=
+					~_REGBIT_PIPE_ENABLE;
+		pdev->initial_mmio_state[REG_INDEX(_REG_PIPEBCONF)] &=
+					~_REGBIT_PIPE_ENABLE;
+		pdev->initial_mmio_state[REG_INDEX(_REG_PIPECCONF)] &=
+					~_REGBIT_PIPE_ENABLE;
+		pdev->initial_mmio_state[REG_INDEX(_REG_PIPE_EDP_CONF)] &=
+					~_REGBIT_PIPE_ENABLE;
+
+		pdev->initial_mmio_state[REG_INDEX(_REG_DP_TP_CTL_E)] &=
+					~_REGBIT_DP_TP_ENABLE;
+	}
+
 
 	return true;
 }
diff --git a/drivers/xen/vgt/reg.h b/drivers/xen/vgt/reg.h
index a3e338f..17762ed 100644
--- a/drivers/xen/vgt/reg.h
+++ b/drivers/xen/vgt/reg.h
@@ -510,6 +510,7 @@
 #define    _REGBIT_GEN6_GRDOM_RENDER		(1 << 1)
 #define    _REGBIT_GEN6_GRDOM_MEDIA		(1 << 2)
 #define    _REGBIT_GEN6_GRDOM_BLT		(1 << 3)
+#define    _REGBIT_GEN6_GRDOM_VECS		(1 << 4)
 
 #define _REG_GT_THREAD_STATUS	0x13805C
 #define _REG_GT_CORE_STATUS	0x138060
@@ -1815,4 +1816,311 @@ static inline int port_type_to_port(int port_sel)
 #define _REG_FPGA_DBG				0x42300
 #define _REGBIT_FPGA_DBG_RM_NOCLAIM		(1 << 31)
 
+#define _REG_IVB_CHICKEN3                       0x4200C
+#define _REG_GEN7_HALF_SLICE_CHICKEN1           0xE100
+#define _REG_GEN7_L3SQCREG4                     0xB034
+#define _REG_GEN7_ROW_CHICKEN2                  0xE4F4
+#define _REG_GEN6_GT_GFX_RC6_LOCKED             0x138104
+
+/* Baytrail specific register offsets that are different from IVB/HSW */
+/* Cant use runtime "mmio_display_base + " because of the hundreds of    *
+ * register address constants used in static tables or switch statements */ 
+
+#define _REG_VLV_DISPLAY_BASE       0x180000
+
+#define _REG_VLV_FORCEWAKE                      0x1300b0
+#define _REG_VLV_FORCEWAKE_ACK                  0x1300b4
+#define _REG_VLV_FORCEWAKE_MEDIA                0x1300b8
+#define _REG_VLV_FORCEWAKE_MEDIA_ACK            0x1300bc
+
+#define _REG_VLV_GTLC_WAKE_CTRL                 0x130090
+#define _REG_VLV_GTLC_PW_STATUS                 0x130094
+
+#define _REG_VLV_GMBUS0                  (_REG_VLV_DISPLAY_BASE + 0x5100)
+#define _REG_VLV_GMBUS1                  (_REG_VLV_DISPLAY_BASE + 0x5104)
+#define _REG_VLV_GMBUS2                  (_REG_VLV_DISPLAY_BASE + 0x5108)
+#define _REG_VLV_GMBUS3                  (_REG_VLV_DISPLAY_BASE + 0x510c)
+#define _REG_VLV_GMBUS4                  (_REG_VLV_DISPLAY_BASE + 0x5110)
+#define _REG_VLV_GMBUS5                  (_REG_VLV_DISPLAY_BASE + 0x5120)
+
+#define _REG_VLV_GEN4_HDMIB              (_REG_VLV_DISPLAY_BASE + 0x61140)
+#define _REG_VLV_DP_C                    (_REG_VLV_DISPLAY_BASE + 0x64200)
+#define _REG_VLV_VGACNTRL                (_REG_VLV_DISPLAY_BASE + 0x71400)
+
+#define _REG_VLV_PIPEA_PP_STATUS         (_REG_VLV_DISPLAY_BASE + 0x61200)
+#define _REG_VLV_PIPEA_PP_CONTROL        (_REG_VLV_DISPLAY_BASE + 0x61204)
+#define _REG_VLV_PIPEA_PP_ON_DELAYS      (_REG_VLV_DISPLAY_BASE + 0x61208)
+#define _REG_VLV_PIPEA_PP_OFF_DELAYS     (_REG_VLV_DISPLAY_BASE + 0x6120c)
+#define _REG_VLV_PIPEA_PP_DIVISOR        (_REG_VLV_DISPLAY_BASE + 0x61210)
+
+#define _REG_VLV_PIPEB_PP_STATUS         (_REG_VLV_DISPLAY_BASE + 0x61300)
+#define _REG_VLV_PIPEB_PP_CONTROL        (_REG_VLV_DISPLAY_BASE + 0x61304)
+#define _REG_VLV_PIPEB_PP_ON_DELAYS      (_REG_VLV_DISPLAY_BASE + 0x61308)
+#define _REG_VLV_PIPEB_PP_OFF_DELAYS     (_REG_VLV_DISPLAY_BASE + 0x6130c)
+#define _REG_VLV_PIPEB_PP_DIVISOR        (_REG_VLV_DISPLAY_BASE + 0x61310)
+
+#define _REG_VLV_DPINVGTT                (_REG_VLV_DISPLAY_BASE + 0x7002c)
+#define _REG_VLV_PORT_HOTPLUG_EN		 (_REG_VLV_DISPLAY_BASE + 0x61110)
+	#define VLV_HPEN_DPB                 (1<<29)
+	#define VLV_HPEN_DPC                 (1<<28)
+	#define VLV_HPEN_DPD                 (1<<27)
+
+#define _REG_VLV_PORT_HOTPLUG_STAT	     (_REG_VLV_DISPLAY_BASE + 0x61114)
+	#define VLV_HPSTAT_CRT_EVENT         (1<<11)
+	#define VLV_HPSTAT_AUX_B_EVENT       (1<<4)
+	#define VLV_HPSTAT_AUX_C_EVENT       (1<<5)
+	#define VLV_HPSTAT_DPB_EVENT         (1<<18) /* FIXME! excluded DP short pulse */
+	#define VLV_HPSTAT_DPC_EVENT         (1<<20) /* FIXME! excluded DP short pulse */
+	#define VLV_HPSTAT_EVENTS            (VLV_HPSTAT_CRT_EVENT | \
+											VLV_HPSTAT_AUX_B_EVENT | VLV_HPSTAT_AUX_C_EVENT | \
+											VLV_HPSTAT_DPB_EVENT   | VLV_HPSTAT_DPC_EVENT)
+
+#define _REG_VLV_GTLC_MIR                0x4400C
+#define _REG_VLV_IIR_RW	                 (_REG_VLV_DISPLAY_BASE + 0x2084)
+#define _REG_VLV_IER                     (_REG_VLV_DISPLAY_BASE + 0x20a0)
+#define _REG_VLV_IIR                     (_REG_VLV_DISPLAY_BASE + 0x20a4)
+#define _REG_VLV_IMR                     (_REG_VLV_DISPLAY_BASE + 0x20a8)
+#define _REG_VLV_ISR                     (_REG_VLV_DISPLAY_BASE + 0x20ac)
+	#define _REG_VLV_IIR_HOTPLUG_EVENT       (0x1 << 17) //BIT17
+	#define _REG_VLV_IIR_DISPLAY_PIPEA_VBLANK (1 << 7) //BIT7 | BIT6
+	#define _REG_VLV_IIR_DISPLAY_PIPEA_EVENT (0x3 << 6) //BIT7 | BIT6
+	#define _REG_VLV_IIR_DISPLAY_PIPEB_VBLANK (1 << 5) //BIT7 | BIT6
+	#define _REG_VLV_IIR_DISPLAY_PIPEB_EVENT (0x3 << 4) //BIT5 | BIT4
+	#define VLV_REGBIT_DISPMASTER_INTERRUPT  (_REG_VLV_IIR_HOTPLUG_EVENT | \
+											_REG_VLV_IIR_DISPLAY_PIPEA_EVENT | \
+											_REG_VLV_IIR_DISPLAY_PIPEB_EVENT)
+#define _REG_VLV_DPFLIPSTAT              (_REG_VLV_DISPLAY_BASE + 0x70028)
+
+#define _REG_VLV_PCBR                    (_REG_VLV_DISPLAY_BASE + 0x2120)
+#define _REG_VLV_DSPARB                  (_REG_VLV_DISPLAY_BASE + 0x70030)
+#define _REG_VLV_DSPARB2                 (_REG_VLV_DISPLAY_BASE + 0x70060)
+
+#define _REG_VLV_DPC_AUX_CH_CTL			 (_REG_VLV_DISPLAY_BASE + 0x64210)
+#define _REG_VLV_DPC_AUX_CH_DATA1		 (_REG_VLV_DISPLAY_BASE + 0x64214)
+
+#define _REG_VLV_PIPEACONF               (_REG_VLV_DISPLAY_BASE + 0x70008)
+#define _REG_VLV_PIPEADSL                (_REG_VLV_DISPLAY_BASE + 0x70000)
+#define _REG_VLV_PIPEA_FRMCOUNT          (_REG_VLV_DISPLAY_BASE + 0x70040)
+#define _REG_VLV_PIPEASTAT               (_REG_VLV_DISPLAY_BASE + 0x70024)
+
+#define _REG_VLV_PIPEBCONF               (_REG_VLV_DISPLAY_BASE + 0x71008)
+#define _REG_VLV_PIPEBDSL                (_REG_VLV_DISPLAY_BASE + 0x71000)
+#define _REG_VLV_PIPEB_FRMCOUNT          (_REG_VLV_DISPLAY_BASE + 0x71040)
+#define _REG_VLV_PIPEBSTAT               (_REG_VLV_DISPLAY_BASE + 0x71024)
+
+	/* BIT masks for _REG_VLV_PIPEXSTAT_VLV */
+	#define VLV_PIPESTATUS_ALLEVENTS     0x8000ffff
+	#define VLV_PIPESTATUS_VBLANK        (1<<2)
+	#define VLV_PIPESTATUS_DSPPLANE_FLIP (1<<10)
+	#define VLV_PIPESTATUS_SPRITEAC_FLIP (1<<14)
+	#define VLV_PIPESTATUS_SPRITEBD_FLIP (1<<15)
+	#define VLV_PIPESTATUS_DPST          (1<<7)
+	#define VLV_PIPESTATUS_GMBUS         (1<<11)
+	#define VLV_PIPESTATUS_EVENTS        ( VLV_PIPESTATUS_VBLANK  | VLV_PIPESTATUS_DSPPLANE_FLIP | \
+											VLV_PIPESTATUS_SPRITEAC_FLIP | VLV_PIPESTATUS_SPRITEBD_FLIP | \
+											VLV_PIPESTATUS_DPST | VLV_PIPESTATUS_GMBUS )
+
+#define _REG_VLV_CURABASE                (_REG_VLV_DISPLAY_BASE + 0x70084)
+#define _REG_VLV_CURASURFLIVE            (_REG_VLV_DISPLAY_BASE + 0x700AC)
+#define _REG_VLV_CURACNTR                (_REG_VLV_DISPLAY_BASE + 0x70080)
+#define _REG_VLV_CURAPOS                 (_REG_VLV_DISPLAY_BASE + 0x70088)
+#define _REG_VLV_CURAPALET_0             (_REG_VLV_DISPLAY_BASE + 0x70090)
+#define _REG_VLV_CURAPALET_1             (_REG_VLV_DISPLAY_BASE + 0x70094)
+#define _REG_VLV_CURAPALET_2             (_REG_VLV_DISPLAY_BASE + 0x70098)
+#define _REG_VLV_CURAPALET_3             (_REG_VLV_DISPLAY_BASE + 0x7009c)
+
+#define _REG_VLV_CURBBASE                (_REG_VLV_DISPLAY_BASE + 0x700C4)
+#define _REG_VLV_CURBSURFLIVE            (_REG_VLV_DISPLAY_BASE + 0x700EC)
+#define _REG_VLV_CURBCNTR                (_REG_VLV_DISPLAY_BASE + 0x700C0)
+#define _REG_VLV_CURBPOS                 (_REG_VLV_DISPLAY_BASE + 0x700C8)
+#define _REG_VLV_CURBPALET_0             (_REG_VLV_DISPLAY_BASE + 0x700D0)
+#define _REG_VLV_CURBPALET_1             (_REG_VLV_DISPLAY_BASE + 0x700D4)
+#define _REG_VLV_CURBPALET_2             (_REG_VLV_DISPLAY_BASE + 0x700D8)
+#define _REG_VLV_CURBPALET_3             (_REG_VLV_DISPLAY_BASE + 0x700Dc)
+
+#define VGT_VLV_CURCNTR(pipe)	         _VGT_PIPE(pipe, _REG_VLV_CURACNTR, _REG_VLV_CURBCNTR)
+#define VGT_VLV_CURBASE(pipe)	         _VGT_PIPE(pipe, _REG_VLV_CURABASE, _REG_VLV_CURBBASE)
+#define VGT_VLV_CURPOS(pipe)	         _VGT_PIPE(pipe, _REG_VLV_CURAPOS,  _REG_VLV_CURBPOS)
+
+
+#define _REG_VLV_DSPACNTR                (_REG_VLV_DISPLAY_BASE + 0x70180)
+#define _REG_VLV_DSPAASYNCFLIPADDR       (_REG_VLV_DISPLAY_BASE + 0x7017c)
+#define _REG_VLV_DSPASURF                (_REG_VLV_DISPLAY_BASE + 0x7019c)
+#define _REG_VLV_DSPASURFLIVE            (_REG_VLV_DISPLAY_BASE + 0x701ac)
+#define _REG_VLV_DSPALINOFF              (_REG_VLV_DISPLAY_BASE + 0x70184)
+#define _REG_VLV_DSPASTRIDE              (_REG_VLV_DISPLAY_BASE + 0x70188)
+#define _REG_VLV_DSPATILEOFF             (_REG_VLV_DISPLAY_BASE + 0x701a4)
+
+#define _REG_VLV_DSPBCNTR                (_REG_VLV_DISPLAY_BASE + 0x71180)
+#define _REG_VLV_DSPBASYNCFLIPADDR       (_REG_VLV_DISPLAY_BASE + 0x7117c)
+#define _REG_VLV_DSPBSURF                (_REG_VLV_DISPLAY_BASE + 0x7119c)
+#define _REG_VLV_DSPBSURFLIVE            (_REG_VLV_DISPLAY_BASE + 0x711ac)
+#define _REG_VLV_DSPBLINOFF              (_REG_VLV_DISPLAY_BASE + 0x71184)
+#define _REG_VLV_DSPBSTRIDE              (_REG_VLV_DISPLAY_BASE + 0x71188)
+#define _REG_VLV_DSPBTILEOFF             (_REG_VLV_DISPLAY_BASE + 0x711a4)
+
+#define VGT_VLV_PIPEDSL(pipe)	         _VGT_PIPE(pipe, _REG_VLV_PIPEADSL,       _REG_VLV_PIPEBDSL)
+#define VGT_VLV_PIPECONF(pipe)	         _VGT_PIPE(pipe, _REG_VLV_PIPEACONF,      _REG_VLV_PIPEBCONF)
+#define VGT_VLV_PIPESTAT(pipe)	         _VGT_PIPE(pipe, _REG_VLV_PIPEASTAT,      _REG_VLV_PIPEBSTAT)
+#define VGT_VLV_PIPE_FRMCOUNT(pipe)      _VGT_PIPE(pipe, _REG_VLV_PIPEA_FRMCOUNT, _REG_VLV_PIPEB_FRMCOUNT)
+#define VGT_VLV_DSPSURF(pipe)	         _VGT_PIPE(pipe, _REG_VLV_DSPASURF,       _REG_VLV_DSPBSURF)
+#define VGT_VLV_DSPCNTR(pipe)	         _VGT_PIPE(pipe, _REG_VLV_DSPACNTR,       _REG_VLV_DSPBCNTR)
+#define VGT_VLV_DSPLINOFF(plane)         _VGT_PIPE(plane, _REG_VLV_DSPALINOFF,    _REG_VLV_DSPBLINOFF)
+#define VGT_VLV_DSPSTRIDE(plane)         _VGT_PIPE(plane, _REG_VLV_DSPASTRIDE,    _REG_VLV_DSPBSTRIDE)
+#define VGT_VLV_DSPTILEOFF(plane)        _VGT_PIPE(plane, _REG_VLV_DSPATILEOFF,   _REG_VLV_DSPBTILEOFF)
+#define VGT_VLV_DSPSURFLIVE(pipe)        _VGT_PIPE(pipe, _REG_VLV_DSPASURFLIVE,   _REG_VLV_DSPBSURFLIVE)
+#define VGT_VLV_CURSURF(pipe)	         _VGT_PIPE(pipe, _REG_VLV_CURABASE,       _REG_VLV_CURBBASE)
+
+#define VGT_VLV_FRMCOUNTPIPE(frmcount)   _VGT_GET_PIPE(frmcount, _REG_VLV_PIPEA_FRMCOUNT, _REG_VLV_PIPEB_FRMCOUNT)
+#define VGT_VLV_PIPECONFPIPE(pipeconf)   _VGT_GET_PIPE(pipeconf, _REG_VLV_PIPEACONF,      _REG_VLV_PIPEBCONF)
+#define VGT_VLV_DSPCNTRPIPE(dspcntr)     _VGT_GET_PIPE(dspcntr,  _REG_VLV_DSPACNTR,       _REG_VLV_DSPBCNTR)
+#define VGT_VLV_DSPSURFPIPE(dspsurf)     _VGT_GET_PIPE(dspsurf,  _REG_VLV_DSPASURF,       _REG_VLV_DSPBSURF)
+#define VGT_VLV_DSPSURFLIVEPIPE(dspsurf) _VGT_GET_PIPE(dspsurf,  _REG_VLV_DSPASURFLIVE,   _REG_VLV_DSPBSURFLIVE)
+#define VGT_VLV_CURSURFPIPE(cursurf)     _VGT_GET_PIPE(cursurf,  _REG_VLV_CURABASE,       _REG_VLV_CURBBASE)
+#define VGT_VLV_CURCNTRPIPE(curcntr)     _VGT_GET_PIPE(curcntr,  _REG_VLV_CURACNTR,       _REG_VLV_CURBCNTR)
+
+#define _VLV_SPRITE_FMT_SHIFT             26
+#define _VLV_SPRITE_STRIDE_MASK		 (0xffff << _SPRITE_STRIDE_SHIFT)
+#define _REG_VLV_SPRA_CTL                (_REG_VLV_DISPLAY_BASE + 0x72180)
+#define _REG_VLV_SPRASURF                (_REG_VLV_DISPLAY_BASE + 0x7219c)
+#define _REG_VLV_SPRASURFLIVE            (_REG_VLV_DISPLAY_BASE + 0x721ac)
+#define _REG_VLV_SPRA_STRIDE             (_REG_VLV_DISPLAY_BASE + 0x72188)
+#define _REG_VLV_SPRA_SIZE               (_REG_VLV_DISPLAY_BASE + 0x72190)
+#define _REG_VLV_SPRA_POS                (_REG_VLV_DISPLAY_BASE + 0x7218c)
+#define _REG_VLV_SPRA_OFFSET             (_REG_VLV_DISPLAY_BASE + 0x721a4)
+
+#define _REG_VLV_SPRB_CTL                (_REG_VLV_DISPLAY_BASE + 0x72280)
+#define _REG_VLV_SPRBSURF                (_REG_VLV_DISPLAY_BASE + 0x7229c)
+#define _REG_VLV_SPRBSURFLIVE            (_REG_VLV_DISPLAY_BASE + 0x722ac)
+#define _REG_VLV_SPRB_STRIDE             (_REG_VLV_DISPLAY_BASE + 0x72288)
+#define _REG_VLV_SPRB_SIZE               (_REG_VLV_DISPLAY_BASE + 0x72290)
+#define _REG_VLV_SPRB_POS                (_REG_VLV_DISPLAY_BASE + 0x7228c)
+#define _REG_VLV_SPRB_OFFSET             (_REG_VLV_DISPLAY_BASE + 0x722a4)
+
+#define _REG_VLV_SPRC_CTL                (_REG_VLV_DISPLAY_BASE + 0x72380)
+#define _REG_VLV_SPRCSURF                (_REG_VLV_DISPLAY_BASE + 0x7239c)
+#define _REG_VLV_SPRCSURFLIVE            (_REG_VLV_DISPLAY_BASE + 0x723ac)
+#define _REG_VLV_SPRC_STRIDE             (_REG_VLV_DISPLAY_BASE + 0x72388)
+#define _REG_VLV_SPRC_SIZE               (_REG_VLV_DISPLAY_BASE + 0x72390)
+#define _REG_VLV_SPRC_POS                (_REG_VLV_DISPLAY_BASE + 0x7238c)
+#define _REG_VLV_SPRC_OFFSET             (_REG_VLV_DISPLAY_BASE + 0x723a4)
+
+#define _REG_VLV_SPRD_CTL                (_REG_VLV_DISPLAY_BASE + 0x72480)
+#define _REG_VLV_SPRDSURF                (_REG_VLV_DISPLAY_BASE + 0x7249c)
+#define _REG_VLV_SPRDSURFLIVE            (_REG_VLV_DISPLAY_BASE + 0x724ac)
+#define _REG_VLV_SPRD_STRIDE             (_REG_VLV_DISPLAY_BASE + 0x72488)
+#define _REG_VLV_SPRD_SIZE               (_REG_VLV_DISPLAY_BASE + 0x72490)
+#define _REG_VLV_SPRD_POS                (_REG_VLV_DISPLAY_BASE + 0x7248c)
+#define _REG_VLV_SPRD_OFFSET             (_REG_VLV_DISPLAY_BASE + 0x724a4)
+
+
+/* ALANPREVIN - for now, only support first sprites of each VLV pipe. This needs to be fixed later.
+ * Design of some lower layer interfaces within handlers.c cant cater for 2 sprites per pipe yet.
+ */
+#define VGT_VLV_SPRCNTRPIPE(sprcntr)     _VGT_GET_PIPE(sprcntr, _REG_VLV_SPRA_CTL, _REG_VLV_SPRC_CTL)
+#define VGT_VLV_SPRSURFPIPE(sprsurf)     _VGT_GET_PIPE(sprsurf, _REG_VLV_SPRASURF, _REG_VLV_SPRCSURF)
+
+#define VGT_VLV_SPRSURF(pipe)            _VGT_PIPE(pipe, _REG_VLV_SPRASURF,        _REG_VLV_SPRCSURF)
+#define VGT_VLV_SPRCTL(pipe)             _VGT_PIPE(pipe, _REG_VLV_SPRA_CTL,        _REG_VLV_SPRC_CTL)
+#define VGT_VLV_SPRSTRIDE(pipe)          _VGT_PIPE(pipe, _REG_VLV_SPRA_STRIDE,     _REG_VLV_SPRC_STRIDE)
+#define VGT_VLV_SPRPOS(pipe)             _VGT_PIPE(pipe, _REG_VLV_SPRA_POS,        _REG_VLV_SPRC_POS)
+#define VGT_VLV_SPRSIZE(pipe)            _VGT_PIPE(pipe, _REG_VLV_SPRA_SIZE,       _REG_VLV_SPRC_SIZE)
+#define VGT_VLV_SPROFFSET(pipe)          _VGT_PIPE(pipe, _REG_VLV_SPRA_OFFSET,     _REG_VLV_SPRC_OFFSET)
+//#define VGT_VLV_SPRSURFLIVE(pipe)        _VGT_PIPE(pipe, _REG_VLV_SPRASURFLIVE, _REG_VLV_SPRCSURFLIVE)
+
+#define _REG_VLV_LGC_PALETTE_A           (_REG_VLV_DISPLAY_BASE + 0xA000)
+#define _REG_VLV_LGC_PALETTE_B           (_REG_VLV_DISPLAY_BASE + 0xA800)
+
+#define _REG_VLV_HTOTAL_A                (_REG_VLV_DISPLAY_BASE + 0x60000)
+#define _REG_VLV_HBLANK_A                (_REG_VLV_DISPLAY_BASE + 0x60004)
+#define _REG_VLV_HSYNC_A                 (_REG_VLV_DISPLAY_BASE + 0x60008)
+#define _REG_VLV_VTOTAL_A                (_REG_VLV_DISPLAY_BASE + 0x6000C)
+#define _REG_VLV_VBLANK_A                (_REG_VLV_DISPLAY_BASE + 0x60010)
+#define _REG_VLV_VSYNC_A                 (_REG_VLV_DISPLAY_BASE + 0x60014)
+#define _REG_VLV_PIPEASRC                (_REG_VLV_DISPLAY_BASE + 0x6001C)
+#define _REG_VLV_BCLRPAT_A               (_REG_VLV_DISPLAY_BASE + 0x60020)
+#define _REG_VLV_VSYNCSHIFT_A            (_REG_VLV_DISPLAY_BASE + 0x60028)
+#define _REG_VLV_PCH_DPLL_A                  (_REG_VLV_DISPLAY_BASE + 0x6014)
+
+#define _REG_VLV_HTOTAL_B                (_REG_VLV_DISPLAY_BASE + 0x61000)
+#define _REG_VLV_HBLANK_B                (_REG_VLV_DISPLAY_BASE + 0x61004)
+#define _REG_VLV_HSYNC_B                 (_REG_VLV_DISPLAY_BASE + 0x61008)
+#define _REG_VLV_VTOTAL_B                (_REG_VLV_DISPLAY_BASE + 0x6100C)
+#define _REG_VLV_VBLANK_B                (_REG_VLV_DISPLAY_BASE + 0x61010)
+#define _REG_VLV_VSYNC_B                 (_REG_VLV_DISPLAY_BASE + 0x61014)
+#define _REG_VLV_PIPEBSRC                (_REG_VLV_DISPLAY_BASE + 0x6101C)
+#define _REG_VLV_BCLRPAT_B               (_REG_VLV_DISPLAY_BASE + 0x61020)
+#define _REG_VLV_VSYNCSHIFT_B            (_REG_VLV_DISPLAY_BASE + 0x61028)
+#define _REG_VLV_PCH_DPLL_B              (_REG_VLV_DISPLAY_BASE + 0x6018)
+
+#define VGT_VLV_HTOTAL(pipe)	         _VGT_PIPE(pipe, _REG_VLV_HTOTAL_A,    _REG_VLV_HTOTAL_B)
+#define VGT_VLV_HBLANK(pipe)	         _VGT_PIPE(pipe, _REG_VLV_HBLANK_A,    _REG_VLV_HBLANK_B)
+#define VGT_VLV_HSYNC(pipe)		         _VGT_PIPE(pipe, _REG_VLV_HSYNC_A,     _REG_VLV_HSYNC_B)
+#define VGT_VLV_VTOTAL(pipe)	         _VGT_PIPE(pipe, _REG_VLV_VTOTAL_A,    _REG_VLV_VTOTAL_B)
+#define VGT_VLV_VBLANK(pipe)	         _VGT_PIPE(pipe, _REG_VLV_VBLANK_A,    _REG_VLV_VBLANK_B)
+#define VGT_VLV_VSYNC(pipe)		         _VGT_PIPE(pipe, _REG_VLV_VSYNC_A,     _REG_VLV_VSYNC_B)
+#define VGT_VLV_BCLRPAT(pipe)	         _VGT_PIPE(pipe, _REG_VLV_BCLRPAT_A,   _REG_VLV_BCLRPAT_B)
+#define VGT_VLV_VSYNCSHIFT(pipe)	     _VGT_PIPE(pipe, _REG_VLV_VSYNCSHIFT_A,_REG_VLV_VSYNCSHIFT_B)
+#define VGT_VLV_PIPESRC(pipe)	         _VGT_PIPE(pipe, _REG_VLV_PIPEASRC,    _REG_VLV_PIPEBSRC)
+
+
+#define _REG_VLV_IOSF_DOORBELL_REQ       (_REG_VLV_DISPLAY_BASE + 0x2100)
+#define _REG_VLV_IOSF_DATA               (_REG_VLV_DISPLAY_BASE + 0x2104)
+#define _REG_VLV_IOSF_ADDR               (_REG_VLV_DISPLAY_BASE + 0x2108)
+
+#define _REG_VLV_PFIT_CTL                (_REG_VLV_DISPLAY_BASE + 0x61230)
+#define _REG_VLV_PFIT_PGM_RATIOS         (_REG_VLV_DISPLAY_BASE + 0x61234)
+
+#define _REG_VLV_FW1                     (_REG_VLV_DISPLAY_BASE + 0x70034)
+#define _REG_VLV_FW2                     (_REG_VLV_DISPLAY_BASE + 0x70038)
+#define _REG_VLV_FW3                     (_REG_VLV_DISPLAY_BASE + 0x7003C)
+#define _REG_VLV_FW4                     (_REG_VLV_DISPLAY_BASE + 0x70070)
+#define _REG_VLV_FW5                     (_REG_VLV_DISPLAY_BASE + 0x70074)
+#define _REG_VLV_FW6                     (_REG_VLV_DISPLAY_BASE + 0x70078)
+#define _REG_VLV_FW7                     (_REG_VLV_DISPLAY_BASE + 0x7007C)
+#define _REG_VLV_DDL1                    (_REG_VLV_DISPLAY_BASE + 0x70050)
+#define _REG_VLV_DDL2                    (_REG_VLV_DISPLAY_BASE + 0x70054)
+#define _REG_VLV_DSPHOWM                 (_REG_VLV_DISPLAY_BASE + 0x70064)
+#define _REG_VLV_DSPHOWM1                (_REG_VLV_DISPLAY_BASE + 0x70068)
+
+#define _REG_VLV_PCH_ADPA                (_REG_VLV_DISPLAY_BASE + 0x61100)
+#define _REG_VLV_DP_B_CTL                (_REG_VLV_DISPLAY_BASE + 0x64100)
+#define _REG_VLV_DP_C_CTL                (_REG_VLV_DISPLAY_BASE + 0x64200)
+#define _REG_VLV_HDMI_B_CTL              (_REG_VLV_DISPLAY_BASE + 0x61140)
+#define _REG_VLV_HDMI_C_CTL              (_REG_VLV_DISPLAY_BASE + 0x61160)
+#define _REG_VLV_DPB_AUX_CH_CTL          (_REG_VLV_DISPLAY_BASE + 0x64110)
+#define _REG_VLV_DPC_AUX_CH_CTL          (_REG_VLV_DISPLAY_BASE + 0x64210)
+
+#define _REG_VLV_DSPCLK_GATE_D	         (_REG_VLV_DISPLAY_BASE + 0x6200)
+
+#define _REG_VLV_MI_ARB                  (_REG_VLV_DISPLAY_BASE + 0x6504)
+#define _REG_VLV_GUNIT_CLOCK_GATE	     (_REG_VLV_DISPLAY_BASE + 0x2060)
+#define _REG_VLV_DPLL_A_MD               (_REG_VLV_DISPLAY_BASE + 0x601c)
+#define _REG_VLV_DPLL_B_MD               (_REG_VLV_DISPLAY_BASE + 0x6020)
+
+#define _REG_VLV_DSPASIZE           (_REG_VLV_DISPLAY_BASE + 0x70190)
+#define _REG_VLV_DSPAPOS           (_REG_VLV_DISPLAY_BASE + 0x7018c)
+#define _REG_VLV_DSPBSIZE           (_REG_VLV_DISPLAY_BASE + 0x71190)
+#define _REG_VLV_DSPBPOS           (_REG_VLV_DISPLAY_BASE + 0x7118c)
+
+#define _REG_VLV_GEN7_UCGCTL4            0x940c
+#define _REG_VLV_9408                    0x9408
+#define _REG_VLV_940c                    0x940c
+#define _REG_VLV_9410                    0x9410
+#define _REG_VLV_9414                    0x9414
+#define _REG_VLV_9418                    0x9418
+
+#define _REG_VLV_GPIOA                   (_REG_VLV_DISPLAY_BASE + 0x5010)
+#define _REG_VLV_GPIOB                   (_REG_VLV_DISPLAY_BASE + 0x5014)
+#define _REG_VLV_GPIOC                   (_REG_VLV_DISPLAY_BASE + 0x5018)
+#define _REG_VLV_GPIOD                   (_REG_VLV_DISPLAY_BASE + 0x501c)
+#define _REG_VLV_GPIOE                   (_REG_VLV_DISPLAY_BASE + 0x5020)
+#define _REG_VLV_GPIOF                   (_REG_VLV_DISPLAY_BASE + 0x5024)
+
+#define _REG_VLV_FW_BLC_SELF_VLV		(_REG_VLV_DISPLAY_BASE + 0x6500)
+#define _REG_VLV_VIDEO_DIP_CTL_A		 (_REG_VLV_DISPLAY_BASE +0x60200)
+#define _REG_VLV_VIDEO_DIP_CTL_B		 (_REG_VLV_DISPLAY_BASE +0x61170)
+
+#define   _SDVO_DETECTED				(1 << 2)
+
 #endif	/* _VGT_REG_H_ */
diff --git a/drivers/xen/vgt/render.c b/drivers/xen/vgt/render.c
index ab68e3b..4a1cdc0 100644
--- a/drivers/xen/vgt/render.c
+++ b/drivers/xen/vgt/render.c
@@ -119,13 +119,17 @@ static bool ring_is_stopped(struct pgt_device *pdev, int id)
 static bool ring_wait_for_completion(struct pgt_device *pdev, int id)
 {
 	u32 *ptr;
+	unsigned int timeout = VGT_RING_TIMEOUT;
 
 	/* now a single magic number, because only RCS supports hw switch */
 	if (id != RING_BUFFER_RCS)
 		return true;
 
+	if (IS_VLV(pdev)) {
+		timeout = VGT_RING_TIMEOUT * 5;
+	}
 	ptr = (u32 *)(phys_aperture_vbase(pdev) + vgt_data_ctx_magic(pdev));
-	if (wait_for_atomic((*ptr == pdev->magic), VGT_RING_TIMEOUT) != 0) {
+	if (wait_for_atomic((*ptr == pdev->magic), timeout) != 0) {
 		vgt_err("Timeout %d ms for CMD comletion on ring %d\n",
 			VGT_RING_TIMEOUT, id);
 		vgt_err("expected(%d), actual(%d)\n", pdev->magic, *ptr);
@@ -138,7 +142,7 @@ static bool ring_wait_for_completion(struct pgt_device *pdev, int id)
 /* make a render engine idle */
 bool idle_render_engine(struct pgt_device *pdev, int id)
 {
-	if (wait_for_atomic(ring_is_empty(pdev, id), VGT_RING_TIMEOUT) != 0) {
+	if (wait_for_atomic_tightmicrosec(ring_is_empty(pdev, id), VGT_RING_TIMEOUT) != 0) {
 		int i, busy = 1;
 		vgt_reg_t acthd1, acthd2;
 		vgt_warn("Timeout wait %d ms for ring(%d) empty\n",
@@ -159,7 +163,7 @@ bool idle_render_engine(struct pgt_device *pdev, int id)
 		 * multi-iteration logic simpler
 		 */
 		acthd1 = VGT_MMIO_READ(pdev, VGT_ACTHD(id));
-		busy = wait_for_atomic(ring_is_empty(pdev, id), 50);
+		busy = wait_for_atomic_tightmicrosec(ring_is_empty(pdev, id), 50);
 		for (i = 0; i < 3; i++) {
 			if (!busy)
 				break;
@@ -173,7 +177,7 @@ bool idle_render_engine(struct pgt_device *pdev, int id)
 			}
 
 			vgt_info("trigger another wait...\n");
-			busy = wait_for_atomic(ring_is_empty(pdev, id),
+			busy = wait_for_atomic_tightmicrosec(ring_is_empty(pdev, id),
 				VGT_RING_TIMEOUT);
 		}
 
@@ -347,7 +351,9 @@ void vgt_kick_ringbuffers(struct vgt_device *vgt)
 }
 
 /* FIXME: need audit all render resources carefully */
-vgt_reg_t vgt_render_regs[] = {
+
+/* For SNB Gen6 */
+vgt_reg_t vgt_gen6_render_regs[] = {
 	/* mode ctl regs. sync with vgt_mode_ctl_regs */
 	_REG_ARB_MODE,
 
@@ -393,6 +399,69 @@ vgt_reg_t vgt_render_regs[] = {
 	_REG_VRSYNC,
 };
 
+/* Verified on VLV Gen7 */
+vgt_reg_t vgt_gen7_atom_render_regs[] = {
+	/* Add IVB register, so they all got pass-through */
+
+	_REG_ARB_MODE,
+
+	_REG_BCS_HWS_PGA_GEN7,
+	_REG_RCS_HWS_PGA,
+	_REG_VCS_HWS_PGA,
+
+	_REG_BCS_MI_MODE,
+	_REG_BCS_BLT_MODE_IVB,
+	_REG_BCS_INSTPM,
+	_REG_BCS_HWSTAM,
+	_REG_BCS_EXCC,
+	_REG_BCS_UHPTR,
+	_REG_BRSYNC,
+	_REG_BVSYNC,
+
+	_REG_RCS_GFX_MODE_IVB,
+	_REG_RCS_HWSTAM,
+	_REG_RCS_UHPTR,
+	_REG_RBSYNC,
+	_REG_RVSYNC,
+
+	_REG_VCS_MI_MODE,
+	_REG_VCS_MFX_MODE_IVB,
+	_REG_VCS_INSTPM,
+	_REG_VCS_HWSTAM,
+	_REG_VCS_EXCC,
+	_REG_VCS_UHPTR,
+	_REG_VBSYNC,
+	_REG_VRSYNC,
+
+	0x2450,
+	0x7034,
+	0x4040,
+
+	_REG_ECOCHK,
+
+	0x2450,
+	_REG_3D_CHICKEN3,
+	0x2088,
+	0x20e4,
+	_REG_GEN7_COMMON_SLICE_CHICKEN1,
+	_REG_GEN7_L3CNTLREG1,
+	_REG_GEN7_L3_CHICKEN_MODE_REGISTER,
+	_REG_GEN7_SQ_CHICKEN_MBCUNIT_CONFIG,
+	0x20a0,
+	0x20e8,
+
+
+	_REG_GT_MODE_IVB,
+	_REG_CACHE_MODE_0_IVB,
+	_REG_CACHE_MODE_1_IVB,
+	_REG_RCS_MI_MODE,
+	_REG_RCS_INSTPM,
+	_REG_RCS_EXCC,
+	_REG_TILECTL,
+
+};
+
+/* Verified on HSW/IVB Gen7 */
 vgt_reg_t vgt_gen7_render_regs[] = {
 	/* Add IVB register, so they all got pass-through */
 
@@ -518,9 +587,12 @@ static void vgt_rendering_save_mmio(struct vgt_device *vgt)
 	 */
 	pdev->in_ctx_switch = 1;
 	if (IS_SNB(pdev))
-		__vgt_rendering_save(vgt, ARRAY_NUM(vgt_render_regs), &vgt_render_regs[0]);
+		__vgt_rendering_save(vgt, ARRAY_NUM(vgt_gen6_render_regs), &vgt_gen6_render_regs[0]);
 	else if (IS_IVB(pdev) || IS_HSW(pdev))
 		__vgt_rendering_save(vgt, ARRAY_NUM(vgt_gen7_render_regs), &vgt_gen7_render_regs[0]);
+	else if (IS_VLV(pdev))
+		__vgt_rendering_save(vgt, ARRAY_NUM(vgt_gen7_atom_render_regs), &vgt_gen7_atom_render_regs[0]);
+
 	pdev->in_ctx_switch = 0;
 }
 
@@ -572,9 +644,11 @@ static void vgt_rendering_restore_mmio(struct vgt_device *vgt)
 	struct pgt_device *pdev = vgt->pdev;
 
 	if (IS_SNB(pdev))
-		__vgt_rendering_restore(vgt, ARRAY_NUM(vgt_render_regs), &vgt_render_regs[0]);
+		__vgt_rendering_restore(vgt, ARRAY_NUM(vgt_gen6_render_regs), &vgt_gen6_render_regs[0]);
 	else if (IS_IVB(pdev) || IS_HSW(pdev))
 		__vgt_rendering_restore(vgt, ARRAY_NUM(vgt_gen7_render_regs), &vgt_gen7_render_regs[0]);
+	else if (IS_VLV(pdev))
+		__vgt_rendering_restore(vgt, ARRAY_NUM(vgt_gen7_atom_render_regs), &vgt_gen7_atom_render_regs[0]);
 }
 
 /*
@@ -899,11 +973,9 @@ static bool vgt_init_null_context(struct pgt_device *pdev, int id)
 {
 	struct vgt_rsvd_ring *ring = &pdev->ring_buffer[id];
 	int i;
+	u32 flags;
 	vgt_reg_t	ccid;
 
-	if (!IS_HSW(pdev))
-		return false;
-
 	/* only RCS support HW context on HSW */
 	if ((id != RING_BUFFER_RCS) || ring->null_context)
 		return true;
@@ -919,11 +991,13 @@ static bool vgt_init_null_context(struct pgt_device *pdev, int id)
 
 	ring->null_context = aperture_2_gm(pdev,
 			rsvd_aperture_alloc(pdev, SZ_CONTEXT_AREA_PER_RING));
-	ring->indirect_state = aperture_2_gm(pdev,
-			rsvd_aperture_alloc(pdev, SZ_INDIRECT_STATE));
-	memcpy((char *)v_aperture(pdev, ring->indirect_state),
-	       (char *)hsw_null_indirect_state,
-	       sizeof(hsw_null_indirect_state));
+	if (IS_HSW(pdev)) {
+		ring->indirect_state = aperture_2_gm(pdev,
+				rsvd_aperture_alloc(pdev, SZ_INDIRECT_STATE));
+		memcpy((char *)v_aperture(pdev, ring->indirect_state),
+				(char *)hsw_null_indirect_state,
+				sizeof(hsw_null_indirect_state));
+	}
 
 	/* Make NULL context active */
 	vgt_ring_emit(ring, MI_ARB_ON_OFF | MI_ARB_DISABLE);
@@ -938,28 +1012,17 @@ static bool vgt_init_null_context(struct pgt_device *pdev, int id)
 	for (i = 5; i < 16; i++)
 		vgt_ring_emit(ring, MI_NOOP);
 
-	hsw_null_context_cmds[0x18/4] = 0x12400001;
-	hsw_null_context_cmds[(0x18 + 0x4)/4] = 0x138064;
-	hsw_null_context_cmds[(0x18 + 0x8)/4] = ring->indirect_state + 0x124;
-	hsw_null_context_cmds[(0x684 + 0x4)/4] = ring->indirect_state | 0x1;
-	hsw_null_context_cmds[(0x684 + 0x8)/4] = ring->indirect_state | 0x1;
-	hsw_null_context_cmds[(0x684 + 0xc)/4] = ring->indirect_state | 0x1;
-	hsw_null_context_cmds[(0x684 + 0x14)/4] = ring->indirect_state | 0x1;
-	vgt_ring_emit_cmds(ring, (char *)hsw_null_context_cmds,
-		sizeof(hsw_null_context_cmds));
-
-#if 0
-	{
-		char *p_contents = ring->virtual_start;
-		int i;
-		for (i = 0; i < ring->tail/4; i++) {
-			if (!(i % 8))
-				printk("\n[%08x]:", i * 4);
-			printk(" %8x", *((u32*)p_contents + i));
-		}
-		printk("\n");
+	if(IS_HSW(pdev)) {
+		hsw_null_context_cmds[0x18/4] = 0x12400001;
+		hsw_null_context_cmds[(0x18 + 0x4)/4] = 0x138064;
+		hsw_null_context_cmds[(0x18 + 0x8)/4] = ring->indirect_state + 0x124;
+		hsw_null_context_cmds[(0x684 + 0x4)/4] = ring->indirect_state | 0x1;
+		hsw_null_context_cmds[(0x684 + 0x8)/4] = ring->indirect_state | 0x1;
+		hsw_null_context_cmds[(0x684 + 0xc)/4] = ring->indirect_state | 0x1;
+		hsw_null_context_cmds[(0x684 + 0x14)/4] = ring->indirect_state | 0x1;
+		vgt_ring_emit_cmds(ring, (char *)hsw_null_context_cmds,
+			sizeof(hsw_null_context_cmds));
 	}
-#endif
 
 	vgt_ring_advance(ring);
 	if (!idle_render_engine(pdev, id)) {
@@ -967,11 +1030,28 @@ static bool vgt_init_null_context(struct pgt_device *pdev, int id)
 		goto err;
 	}
 
+	if(IS_VLV(pdev)) {
+		/* Workaround: we must issue a pipe_control with CS-stall bit
+		 * set before a pipe_control command that has the state cache
+		 * invalidate bit set. */
+		vgt_ring_emit(ring, PIPE_CONTROL(4));
+		vgt_ring_emit(ring, PIPE_CONTROL_CS_STALL |
+						PIPE_CONTROL_STALL_AT_SCOREBOARD);
+		vgt_ring_emit(ring, 0);
+		vgt_ring_emit(ring, 0);
+		vgt_ring_advance(ring);
+	}
+
 	vgt_ring_emit(ring, PIPE_CONTROL(5));
-	vgt_ring_emit(ring, PIPE_CONTROL_CS_STALL |
-			    PIPE_CONTROL_MEDIA_STATE_CLEAR |
+
+	flags = (PIPE_CONTROL_CS_STALL |
 			    PIPE_CONTROL_RENDER_TARGET_CACHE_FLUSH |
 			    PIPE_CONTROL_STATE_CACHE_INVALIDATE);
+	if(IS_SNB(pdev) || IS_IVB(pdev) || IS_HSW(pdev)) {
+		flags |= (PIPE_CONTROL_MEDIA_STATE_CLEAR);
+	}
+
+	vgt_ring_emit(ring, flags);
 	vgt_ring_emit(ring, 0);
 	vgt_ring_emit(ring, 0);
 	vgt_ring_emit(ring, 0);
@@ -1020,6 +1100,9 @@ static bool vgt_init_null_context(struct pgt_device *pdev, int id)
 	memcpy((char *)v_aperture(pdev, vgt_dom0->rb[id].context_save_area),
 	       (char *)v_aperture(pdev, ring->null_context),
 	       SZ_CONTEXT_AREA_PER_RING);
+
+	vgt_dbg(VGT_DBG_RENDER, "****  vgt_init_null_context - done\n");
+
 	return true;
 
 err:
@@ -1035,25 +1118,49 @@ static bool vgt_save_hw_context(int id, struct vgt_device *vgt)
 	vgt_state_ring_t *rb = &vgt->rb[id];
 	struct vgt_rsvd_ring *ring = &pdev->ring_buffer[id];
 	vgt_reg_t	ccid, new_ccid;
+	u32 flags;
+
 
 	/* pipeline flush */
 	vgt_ring_emit(ring, PIPE_CONTROL(5));
-	vgt_ring_emit(ring, PIPE_CONTROL_CS_STALL |
+	flags = (PIPE_CONTROL_CS_STALL |
 			    PIPE_CONTROL_TLB_INVALIDATE |
-			    PIPE_CONTROL_FLUSH_ENABLE);
+				PIPE_CONTROL_STALL_AT_SCOREBOARD |
+				PIPE_CONTROL_FLUSH_ENABLE);
+	vgt_ring_emit(ring, flags);
 	vgt_ring_emit(ring, 0);
 	vgt_ring_emit(ring, 0);
 	vgt_ring_emit(ring, 0);
+	vgt_ring_emit(ring, MI_NOOP);
+
+	if(IS_VLV(pdev)) {
+		/* Workaround: we must issue a pipe_control with CS-stall bit
+		 * set before a pipe_control command that has the state cache
+		 * invalidate bit set. */
+		vgt_ring_emit(ring, PIPE_CONTROL(5));
+		vgt_ring_emit(ring, PIPE_CONTROL_CS_STALL |
+						PIPE_CONTROL_STALL_AT_SCOREBOARD);
+		vgt_ring_emit(ring, 0);
+		vgt_ring_emit(ring, 0);
+		vgt_ring_emit(ring, 0);
+
+		vgt_ring_emit(ring, MI_NOOP);
+	}
 
 	vgt_ring_emit(ring, PIPE_CONTROL(5));
-	vgt_ring_emit(ring, PIPE_CONTROL_RENDER_TARGET_CACHE_FLUSH |
-			    PIPE_CONTROL_FLUSH_ENABLE |
+	flags = (PIPE_CONTROL_RENDER_TARGET_CACHE_FLUSH |
 			    PIPE_CONTROL_VF_CACHE_INVALIDATE |
 			    PIPE_CONTROL_CONST_CACHE_INVALIDATE |
-			    PIPE_CONTROL_STATE_CACHE_INVALIDATE);
+			    PIPE_CONTROL_STATE_CACHE_INVALIDATE |
+				PIPE_CONTROL_FLUSH_ENABLE );
+
+	vgt_ring_emit(ring, flags);
 	vgt_ring_emit(ring, 0);
 	vgt_ring_emit(ring, 0);
 	vgt_ring_emit(ring, 0);
+	vgt_ring_emit(ring, MI_NOOP);
+
+	vgt_ring_advance(ring);
 
 #if 0
 	/*
@@ -1072,18 +1179,18 @@ static bool vgt_save_hw_context(int id, struct vgt_device *vgt)
 
 	/* pipeline flush */
 	vgt_ring_emit(ring, PIPE_CONTROL(5));
-	vgt_ring_emit(ring, PIPE_CONTROL_CS_STALL |
+	flags = (PIPE_CONTROL_CS_STALL |
 			    PIPE_CONTROL_TLB_INVALIDATE |
-			    PIPE_CONTROL_FLUSH_ENABLE |
 			    PIPE_CONTROL_POST_SYNC_IMM |
-			    PIPE_CONTROL_POST_SYNC_GLOBAL_GTT);
+			    PIPE_CONTROL_POST_SYNC_GLOBAL_GTT | 
+				PIPE_CONTROL_FLUSH_ENABLE );
+	vgt_ring_emit(ring, flags);
 	vgt_ring_emit(ring, vgt_data_ctx_magic(pdev));
 	vgt_ring_emit(ring, ++pdev->magic);
 	vgt_ring_emit(ring, 0);
 
 	vgt_ring_emit(ring, MI_NOOP);
 	vgt_ring_emit(ring, MI_NOOP);
-	vgt_ring_emit(ring, MI_NOOP);
 
 	/* submit cmds */
 	vgt_ring_advance(ring);
@@ -1109,6 +1216,8 @@ static bool vgt_save_hw_context(int id, struct vgt_device *vgt)
 			    MI_FORCE_RESTORE);
 	vgt_ring_emit(ring, MI_NOOP);
 	vgt_ring_emit(ring, MI_ARB_ON_OFF | MI_ARB_ENABLE);
+
+	vgt_ring_emit(ring, MI_NOOP);
 #else
 	/* FIXME: too many CCID changes looks not working. So
 	 * fall back to original style by using guest context directly
@@ -1120,31 +1229,39 @@ static bool vgt_save_hw_context(int id, struct vgt_device *vgt)
 
 	vgt_ring_emit(ring, MI_ARB_ON_OFF | MI_ARB_DISABLE);
 	vgt_ring_emit(ring, MI_SET_CONTEXT);
-	vgt_ring_emit(ring, rb->context_save_area |
-			    MI_RESTORE_INHIBIT |
+
+	flags = ( MI_RESTORE_INHIBIT |
 			    MI_SAVE_EXT_STATE_EN |
 			    MI_RESTORE_EXT_STATE_EN);
+	if(IS_VLV(pdev))
+		flags |= MI_MM_SPACE_GTT;
+
+	vgt_ring_emit(ring, rb->context_save_area | flags);
 	vgt_ring_emit(ring, MI_NOOP);
 	vgt_ring_emit(ring, MI_ARB_ON_OFF | MI_ARB_ENABLE);
+
+	vgt_ring_emit(ring, MI_NOOP);
+
 #endif
 
 	/* pipeline flush */
 	vgt_ring_emit(ring, PIPE_CONTROL(5));
-	vgt_ring_emit(ring, PIPE_CONTROL_CS_STALL |
+	flags = (PIPE_CONTROL_CS_STALL |
 			    PIPE_CONTROL_TLB_INVALIDATE |
-			    PIPE_CONTROL_FLUSH_ENABLE |
-			    PIPE_CONTROL_MEDIA_STATE_CLEAR |
 			    PIPE_CONTROL_DC_FLUSH_ENABLE |
 			    PIPE_CONTROL_RENDER_TARGET_CACHE_FLUSH |
 			    PIPE_CONTROL_POST_SYNC_IMM |
-			    PIPE_CONTROL_POST_SYNC_GLOBAL_GTT);
+			    PIPE_CONTROL_POST_SYNC_GLOBAL_GTT |
+				PIPE_CONTROL_FLUSH_ENABLE );
+	if(IS_SNB(pdev) || IS_IVB(pdev) || IS_HSW(pdev)) {
+		flags |= PIPE_CONTROL_MEDIA_STATE_CLEAR;
+	}
+	vgt_ring_emit(ring, flags);
 	vgt_ring_emit(ring, vgt_data_ctx_magic(pdev));
 	vgt_ring_emit(ring, ++pdev->magic);
 	vgt_ring_emit(ring, 0);
 
 	vgt_ring_emit(ring, MI_NOOP);
-	vgt_ring_emit(ring, MI_NOOP);
-	vgt_ring_emit(ring, MI_NOOP);
 
 	/* submit cmds */
 	vgt_ring_advance(ring);
@@ -1174,7 +1291,7 @@ struct reg_mask_t {
 	vgt_reg_t	val;
 };
 
-static struct reg_mask_t rcs_reset_mmio[] = {
+static struct reg_mask_t rcs_reset_mmio_gen7core[] = {
 	{0x4080, 0},
 	{0x2134, 0},
 	{0x20c0, 1},
@@ -1207,9 +1324,33 @@ static struct reg_mask_t rcs_reset_mmio[] = {
 	{0x2054, 0},
 };
 
+static struct reg_mask_t rcs_reset_mmio_gen7atom[] = {
+	{0x2134, 0, 0},
+	{0x20c0, 0, 0},
+	{0x20a8, 0, 0},
+	{0x7000, 0, 0x4},
+	{0x209c, 0, 0x4001},
+	{0x2090, 0, 0x400},
+	/* conservative clock gating (all disabled) for vlv */
+	{0x9400, 0, 0xffffffff},
+	{0x9404, 0, 0xffffffff},
+	{0x9408, 0, 0xffffffff},
+	{0x940c, 0, 0xffffffff},
+	{0x9410, 0, 0xffffffff},
+	{0x9414, 0, 0xffffffff},
+	{0x9418, 0, 0xffffffff},
+	{0x4090, 0, 0},
+	{0x229c, 0, 0x28000800}, //{0x229c, 1},
+	{0x2044, 0, 0},
+	{0x20a0, 0, 0x28A01010},//{0x20a0, 0},
+	{0x7004, 0, 0x01C001C0},//{0x7004, 1},
+	{0x2180, 0, 0},
+	{0x2054, 0, 0x40}, //{0x2054, 0},
+};
+
 static bool vgt_reset_engine(struct pgt_device *pdev, int id)
 {
-	int i;
+	int i, num_regs;
 	vgt_reg_t head, tail, start, ctl;
 	vgt_reg_t val, val1;
 
@@ -1218,9 +1359,17 @@ static bool vgt_reset_engine(struct pgt_device *pdev, int id)
 		return false;
 	}
 
+	if(IS_VLV(pdev))
+		num_regs = ARRAY_NUM(rcs_reset_mmio_gen7atom);
+	else 
+		num_regs = ARRAY_NUM(rcs_reset_mmio_gen7core);
 	/* save reset context */
-	for (i = 0; i < ARRAY_NUM(rcs_reset_mmio); i++) {
-		struct reg_mask_t *r = &rcs_reset_mmio[i];
+	for (i = 0; i < num_regs; i++) {
+		struct reg_mask_t *r;
+		if(IS_VLV(pdev))
+			r = &rcs_reset_mmio_gen7atom[i];
+		else 
+			r = &rcs_reset_mmio_gen7core[i];
 
 		if (r->reg == 0x2220 || r->reg == 0x2228)
 			r->val = VGT_MMIO_READ(pdev, r->reg + 0x10000);
@@ -1231,10 +1380,12 @@ static bool vgt_reset_engine(struct pgt_device *pdev, int id)
 			r->val |= 0xFFFF0000;
 	}
 
-	head = VGT_READ_HEAD(pdev, id);
-	tail = VGT_READ_TAIL(pdev, id);
+	head  = VGT_READ_HEAD(pdev, id);
+	tail  = VGT_READ_TAIL(pdev, id);
 	start = VGT_READ_START(pdev, id);
-	ctl = VGT_READ_CTL(pdev, id);
+	ctl   = VGT_READ_CTL(pdev, id);
+	vgt_dbg(VGT_DBG_RENDER, "Before reset buffer(%d): head (0x%x) tail(0x%x), start(0x%x) ctl(0x%x)\n",
+		id, head, tail, start, ctl);
 
 	/* trigger engine specific reset */
 	VGT_MMIO_WRITE(pdev, _REG_GEN6_GDRST, _REGBIT_GEN6_GRDOM_RENDER);
@@ -1253,8 +1404,12 @@ static bool vgt_reset_engine(struct pgt_device *pdev, int id)
 	}
 
 	/* restore reset context */
-	for (i = 0; i < ARRAY_NUM(rcs_reset_mmio); i++) {
-		struct reg_mask_t *r = &rcs_reset_mmio[i];
+	for (i = 0; i < num_regs; i++) {
+		struct reg_mask_t *r;
+		if(IS_VLV(pdev))
+			r = &rcs_reset_mmio_gen7atom[i];
+		else 
+			r = &rcs_reset_mmio_gen7core[i];
 
 		VGT_MMIO_WRITE(pdev, r->reg, r->val);
 	}
@@ -1264,22 +1419,27 @@ static bool vgt_reset_engine(struct pgt_device *pdev, int id)
 	VGT_WRITE_HEAD(pdev, id, head);
 	VGT_WRITE_TAIL(pdev, id, tail);
 
-	val = VGT_MMIO_READ(pdev, 0x2214);
-	val &= 0xFFFFFFFE;
-	val1 = VGT_MMIO_READ(pdev, 0x138064);
-	if (val1 & 0x3) {
-		if (val1 & 0x1)
+	if (IS_HSW(pdev)) {
+		val = VGT_MMIO_READ(pdev, 0x2214);
+		val &= 0xFFFFFFFE;
+		val1 = VGT_MMIO_READ(pdev, 0x138064);
+		if (val1 & 0x3) {
+			if (val1 & 0x1)
+				val |= 0x1;
+		} else if (val1 & 0x8) {
 			val |= 0x1;
-	} else if (val1 & 0x8) {
-		val |= 0x1;
+		}
+		VGT_MMIO_WRITE(pdev, 0x2214, val);
 	}
-	VGT_MMIO_WRITE(pdev, 0x2214, val);
 
 	VGT_WRITE_CTL(pdev, id, ctl);
-	VGT_POST_READ_TAIL(pdev, id);
-	VGT_POST_READ_HEAD(pdev, id);
-	VGT_POST_READ_START(pdev, id);
-	VGT_POST_READ_CTL(pdev, id);
+	tail  = VGT_MMIO_READ(pdev, RB_TAIL(pdev, id));
+	head  = VGT_MMIO_READ(pdev, RB_HEAD(pdev, id));
+	start = VGT_MMIO_READ(pdev, RB_START(pdev, id));
+	ctl   = VGT_MMIO_READ(pdev, RB_CTL(pdev, id));
+	vgt_dbg(VGT_DBG_RENDER, "After reset buffer(%d): head (0x%x) tail(0x%x), start(0x%x) ctl(0x%x)\n",
+		id, head, tail, start, ctl);
+
 
 	return true;
 }
@@ -1289,15 +1449,19 @@ static bool vgt_restore_hw_context(int id, struct vgt_device *vgt)
 	struct pgt_device *pdev = vgt->pdev;
 	vgt_state_ring_t	*rb = &vgt->rb[id];
 	struct vgt_rsvd_ring *ring = &pdev->ring_buffer[id];
+	u32 flags;
 
 	/* sync between vReg and saved context */
 	//update_context(vgt, rb->context_save_area);
 
 	/* pipeline flush */
 	vgt_ring_emit(ring, PIPE_CONTROL(5));
-	vgt_ring_emit(ring, PIPE_CONTROL_CS_STALL |
+	flags = (PIPE_CONTROL_CS_STALL |
 			    PIPE_CONTROL_TLB_INVALIDATE |
-			    PIPE_CONTROL_FLUSH_ENABLE);
+				PIPE_CONTROL_STALL_AT_SCOREBOARD |
+				PIPE_CONTROL_FLUSH_ENABLE);
+
+	vgt_ring_emit(ring, flags);
 	vgt_ring_emit(ring, 0);
 	vgt_ring_emit(ring, 0);
 	vgt_ring_emit(ring, 0);
@@ -1316,11 +1480,13 @@ static bool vgt_restore_hw_context(int id, struct vgt_device *vgt)
 
 	/* pipeline flush */
 	vgt_ring_emit(ring, PIPE_CONTROL(5));
-	vgt_ring_emit(ring, PIPE_CONTROL_CS_STALL |
+	flags = (PIPE_CONTROL_CS_STALL |
 			    PIPE_CONTROL_TLB_INVALIDATE |
-			    PIPE_CONTROL_FLUSH_ENABLE |
 			    PIPE_CONTROL_POST_SYNC_IMM |
-			    PIPE_CONTROL_POST_SYNC_GLOBAL_GTT);
+			    PIPE_CONTROL_POST_SYNC_GLOBAL_GTT |
+				PIPE_CONTROL_FLUSH_ENABLE );
+
+	vgt_ring_emit(ring, flags);
 	vgt_ring_emit(ring, vgt_data_ctx_magic(pdev));
 	vgt_ring_emit(ring, ++pdev->magic);
 	vgt_ring_emit(ring, 0);
@@ -1347,11 +1513,21 @@ static bool vgt_restore_hw_context(int id, struct vgt_device *vgt)
 	/* restore HW context */
 	vgt_ring_emit(ring, MI_ARB_ON_OFF | MI_ARB_DISABLE);
 	vgt_ring_emit(ring, MI_SET_CONTEXT);
-	vgt_ring_emit(ring, rb->context_save_area |
-			    MI_MM_SPACE_GTT |
-			    MI_SAVE_EXT_STATE_EN |
-			    MI_RESTORE_EXT_STATE_EN |
-			    MI_FORCE_RESTORE);
+
+	if (IS_VLV(vgt->pdev)) {
+		vgt_ring_emit(ring, rb->context_save_area |
+				MI_MM_SPACE_GTT |
+				MI_SAVE_EXT_STATE_EN |
+				MI_RESTORE_EXT_STATE_EN |
+				MI_RESTORE_INHIBIT);
+	} else {
+		vgt_ring_emit(ring, rb->context_save_area |
+				MI_MM_SPACE_GTT |
+				MI_SAVE_EXT_STATE_EN |
+				MI_RESTORE_EXT_STATE_EN |
+				MI_FORCE_RESTORE);
+	}
+
 	vgt_ring_emit(ring, MI_NOOP);
 	vgt_ring_emit(ring, MI_ARB_ON_OFF | MI_ARB_ENABLE);
 
@@ -1368,12 +1544,15 @@ static bool vgt_restore_hw_context(int id, struct vgt_device *vgt)
 
 	/* pipeline flush */
 	vgt_ring_emit(ring, PIPE_CONTROL(5));
-	vgt_ring_emit(ring, PIPE_CONTROL_CS_STALL |
+	flags = (PIPE_CONTROL_CS_STALL |
 			    PIPE_CONTROL_TLB_INVALIDATE |
-			    PIPE_CONTROL_FLUSH_ENABLE |
-			    PIPE_CONTROL_MEDIA_STATE_CLEAR |
 			    PIPE_CONTROL_POST_SYNC_IMM |
-			    PIPE_CONTROL_POST_SYNC_GLOBAL_GTT);
+			    PIPE_CONTROL_POST_SYNC_GLOBAL_GTT |
+				PIPE_CONTROL_FLUSH_ENABLE );
+	if(IS_SNB(pdev) || IS_IVB(pdev) || IS_HSW(pdev)) {
+		flags |= PIPE_CONTROL_MEDIA_STATE_CLEAR;
+	}
+	vgt_ring_emit(ring, flags);
 	vgt_ring_emit(ring, vgt_data_ctx_magic(pdev));
 	vgt_ring_emit(ring, ++pdev->magic);
 	vgt_ring_emit(ring, 0);
@@ -1398,11 +1577,12 @@ static bool vgt_restore_hw_context(int id, struct vgt_device *vgt)
 
 	/* pipeline flush */
 	vgt_ring_emit(ring, PIPE_CONTROL(5));
-	vgt_ring_emit(ring, PIPE_CONTROL_CS_STALL |
+	flags = (PIPE_CONTROL_CS_STALL |
 			    PIPE_CONTROL_TLB_INVALIDATE |
-			    PIPE_CONTROL_FLUSH_ENABLE |
 			    PIPE_CONTROL_POST_SYNC_IMM |
-			    PIPE_CONTROL_POST_SYNC_GLOBAL_GTT);
+			    PIPE_CONTROL_POST_SYNC_GLOBAL_GTT |
+				PIPE_CONTROL_FLUSH_ENABLE );
+	vgt_ring_emit(ring, flags);
 	vgt_ring_emit(ring, vgt_data_ctx_magic(pdev));
 	vgt_ring_emit(ring, ++pdev->magic);
 	vgt_ring_emit(ring, 0);
@@ -1544,7 +1724,7 @@ bool vgt_do_render_context_switch(struct pgt_device *pdev)
 	}
 
 	vgt_dbg(VGT_DBG_RENDER, "vGT: next vgt (%d)\n", next->vgt_id);
-	
+
 
 	/* variable exported by debugfs */
 	context_switch_num ++;
diff --git a/drivers/xen/vgt/sched.c b/drivers/xen/vgt/sched.c
index 525fe3a..63f1862 100644
--- a/drivers/xen/vgt/sched.c
+++ b/drivers/xen/vgt/sched.c
@@ -645,20 +645,20 @@ static inline void vgt_sched_dump(struct vgt_device *cur_vgt, vgt_tslice_t cur_t
 {
 	struct pgt_device *pdev = cur_vgt->pdev;
 	struct vgt_device *vgt;
-	printk("------------------------------------------\n");
-	printk("     vgt scheduler dump vGT\n");
-	printk("------------------------------------------\n");
-	printk("....Current time (%llu)\n", cur_time);
-	printk("....Current render owner vgt(%d))\n", (current_render_owner(pdev))->vgt_id);
+	vgt_dbg(VGT_DBG_SCHED, "------------------------------------------\n");
+	vgt_dbg(VGT_DBG_SCHED, "     vgt scheduler dump vGT\n");
+	vgt_dbg(VGT_DBG_SCHED, "------------------------------------------\n");
+	vgt_dbg(VGT_DBG_SCHED, "....Current time (%llu)\n", cur_time);
+	vgt_dbg(VGT_DBG_SCHED, "....Current render owner vgt(%d))\n", (current_render_owner(pdev))->vgt_id);
 	list_for_each_entry(vgt, &pdev->rendering_runq_head, list) {
 		if (vgt == cur_vgt)
-			printk("....vGT(%d) [dump caller]:\n", cur_vgt->vgt_id);
+			vgt_dbg(VGT_DBG_SCHED, "....vGT(%d) [dump caller]:\n", cur_vgt->vgt_id);
 		else
-			printk("....vGT(%d):\n", vgt->vgt_id);
-		printk("........context start time (%llu)\n", ctx_start_time(vgt));
-		printk("........context end time   (%llu)\n", ctx_end_time(vgt));
-		printk("........context Remain time slice (%lld)\n", ctx_remain_time(vgt));
-		printk("\n");
+			vgt_dbg(VGT_DBG_SCHED, "....vGT(%d):\n", vgt->vgt_id);
+		vgt_dbg(VGT_DBG_SCHED, "........context start time (%llu)\n", ctx_start_time(vgt));
+		vgt_dbg(VGT_DBG_SCHED, "........context end time   (%llu)\n", ctx_end_time(vgt));
+		vgt_dbg(VGT_DBG_SCHED, "........context Remain time slice (%lld)\n", ctx_remain_time(vgt));
+		vgt_dbg(VGT_DBG_SCHED, "\n");
 	}
 }
 
diff --git a/drivers/xen/vgt/utility.c b/drivers/xen/vgt/utility.c
index 01bcd81..302f74b 100644
--- a/drivers/xen/vgt/utility.c
+++ b/drivers/xen/vgt/utility.c
@@ -142,7 +142,7 @@ void show_mode_settings(struct pgt_device *pdev)
 	SHOW_MODE(_REG_VCS_MI_MODE);
 	SHOW_MODE(_REG_BCS_MI_MODE);
 
-	if (IS_IVB(pdev) || IS_HSW(pdev)) {
+	if (IS_IVB(pdev) || IS_HSW(pdev) || IS_VLV(pdev)) {
 		SHOW_MODE(_REG_RCS_GFX_MODE_IVB);
 		SHOW_MODE(_REG_BCS_BLT_MODE_IVB);
 		SHOW_MODE(_REG_VCS_MFX_MODE_IVB);
@@ -291,7 +291,13 @@ void show_interrupt_regs(struct pgt_device *pdev,
 		else \
 			seq_printf(seq, fmt, ##args); \
 	}while(0)
-
+	if (IS_VLV(pdev)) {
+	P("vGT: VLVDEISR is %x, VLVDEIIR is %x, VLVDEIMR is %x, VLVDEIER is %x\n",
+		VGT_MMIO_READ(pdev, _REG_VLV_ISR),
+		VGT_MMIO_READ(pdev, _REG_VLV_IIR),
+		VGT_MMIO_READ(pdev, _REG_VLV_IMR),
+		VGT_MMIO_READ(pdev, _REG_VLV_IER));
+	}
 	P("vGT: DEISR is %x, DEIIR is %x, DEIMR is %x, DEIER is %x\n",
 		VGT_MMIO_READ(pdev, _REG_DEISR),
 		VGT_MMIO_READ(pdev, _REG_DEIIR),
@@ -350,13 +356,17 @@ uint32_t pci_bar_size(struct pgt_device *pdev, unsigned int bar_off)
 	return bar_size;
 }
 
-uint64_t vgt_get_gtt_size(struct pci_bus *bus)
+uint64_t vgt_get_gtt_size(struct pgt_device *pdev,struct pci_bus *bus)
 {
 	uint16_t gmch_ctrl;
-
+	unsigned int devfn = 0;
 	ASSERT(!bus->number);
 	/* GTT size is within GMCH. */
-	pci_bus_read_config_word(bus, 0, _REG_GMCH_CONTRL, &gmch_ctrl);
+	if (IS_VLV(pdev)) {
+		devfn = PCI_DEVFN(2,0);
+	}
+	pci_bus_read_config_word(bus, devfn, _REG_GMCH_CONTRL, &gmch_ctrl);
+	vgt_dbg(VGT_DBG_MEM, "GTT is %d\n",  (gmch_ctrl >> 8) & 3);
 	switch ( (gmch_ctrl >> 8) & 3 ) {
 	case	1:
 		return 1 * SIZE_1MB;
@@ -457,6 +467,18 @@ int setup_gtt(struct pgt_device *pdev)
 	dma_addr_t dma_addr;
 	u32 pte;
 
+	if (IS_VLV(pdev)) {
+		unsigned int ret;
+		vgt_dbg(VGT_DBG_MEM, "setup_gtt_hack for VLV\n");
+		/* VLVA0 (potential hack), BIOS isn't actually waking us */
+		VGT_MMIO_WRITE(pdev, _REG_VLV_GTLC_WAKE_CTRL, 1);
+		/*if (wait_for((VGT_MMIO_READ(_REG_VLV_GTLC_PW_STATUS) & 1) == 1, 10))
+				DRM_DEBUG_DRIVER("allow wake ack timed out\n");*/
+		udelay(5000);
+		ret = VGT_MMIO_READ(pdev, _REG_VLV_GTLC_PW_STATUS);
+		vgt_dbg(VGT_DBG_MEM, "_REG_VLV_GTLC_PW_STATUS=0x%x\n", ret);
+	}
+
 	check_gtt(pdev);
 
 	printk("vGT: clear all GTT entries.\n");
diff --git a/drivers/xen/vgt/vgt.c b/drivers/xen/vgt/vgt.c
index 8cc4fc5..9873fac 100644
--- a/drivers/xen/vgt/vgt.c
+++ b/drivers/xen/vgt/vgt.c
@@ -40,6 +40,10 @@ bool ignore_hvm_forcewake_req = true;
 module_param_named(ignore_hvm_forcewake_req, ignore_hvm_forcewake_req, bool, 0400);
 MODULE_PARM_DESC(ignore_hvm_forcewake_req, "ignore HVM's forwake request (default: true)");
 
+bool bypass = false;
+module_param_named(bypass, bypass, bool, 0400);
+MODULE_PARM_DESC(bypass, "bypass (default: false)");
+
 bool hvm_render_owner = false;
 module_param_named(hvm_render_owner, hvm_render_owner, bool, 0600);
 MODULE_PARM_DESC(hvm_render_owner, "Make HVM to be render owner after create (default: false)");
@@ -331,8 +335,8 @@ bool initial_phys_states(struct pgt_device *pdev)
 
 	vgt_dbg(VGT_DBG_GENERIC, "VGT: Initial_phys_states\n");
 
-	pdev->gtt_size = vgt_get_gtt_size(pdev->pbus);
-	gm_sz(pdev) = vgt_get_gtt_size(pdev->pbus) * 1024;
+	pdev->gtt_size = vgt_get_gtt_size(pdev, pdev->pbus);
+	gm_sz(pdev) = pdev->gtt_size * 1024;
 	pdev->saved_gtt = vzalloc(pdev->gtt_size);
 	if (!pdev->saved_gtt)
 		return false;
@@ -360,7 +364,9 @@ bool initial_phys_states(struct pgt_device *pdev)
 	bar1 = *(uint64_t *)&pdev->initial_cfg_space[VGT_REG_CFG_SPACE_BAR1];
 	printk("bar0: 0x%llx, Bar1: 0x%llx\n", bar0, bar1);
 
-	ASSERT ((bar0 & 7) == 4);
+	if(!IS_VLV(pdev)) /* Spec indicates Baytrail is a 32bit BAR */
+		ASSERT ((bar0 & 7) == 4);
+
 	/* memory, 64 bits bar0 */
 	pdev->gttmmio_base = bar0 & ~0xf;
 	pdev->mmio_size = VGT_MMIO_SPACE_SZ;
@@ -369,7 +375,8 @@ bool initial_phys_states(struct pgt_device *pdev)
 		pdev->gtt_size);
 	ASSERT(pdev->mmio_size + pdev->gtt_size <= pdev->bar_size[0]);
 
-	ASSERT ((bar1 & 7) == 4);
+	if(!IS_VLV(pdev))  /* BAR1 not so clear but might be a 32bit BAR too */
+		ASSERT ((bar1 & 7) == 4);
 	/* memory, 64 bits bar */
 	pdev->gmadr_base = bar1 & ~0xf;
 	printk("gttmmio: 0x%llx, gmadr: 0x%llx\n", pdev->gttmmio_base, pdev->gmadr_base);
@@ -400,10 +407,16 @@ bool initial_phys_states(struct pgt_device *pdev)
 	 * it after the snapshot. Remove this workaround after GMBUS virtualization
 	 */
 	{
-		u32 val = VGT_MMIO_READ(pdev, 0xc5108);
-		pdev->initial_mmio_state[REG_INDEX(0xc5108)] &= ~0x8000;
-		printk("vGT: GMBUS2 init value: %x, %x\n", pdev->initial_mmio_state[REG_INDEX(0xc5108)], val);
-		VGT_MMIO_WRITE(pdev, 0xc5108, val | 0x8000);
+		u32 val;
+		u32 reg = _REG_PCH_GMBUS2;
+		if(IS_VLV(pdev))
+			reg = _REG_VLV_GMBUS2;
+
+		val = VGT_MMIO_READ(pdev, reg);
+
+		pdev->initial_mmio_state[REG_INDEX(reg)] &= ~0x8000;
+		printk("vGT: GMBUS2 init value: %x, %x\n", pdev->initial_mmio_state[REG_INDEX(reg)], val);
+		VGT_MMIO_WRITE(pdev, reg, val | 0x8000);
 	}
 
 	return true;
@@ -423,6 +436,12 @@ static bool vgt_set_device_type(struct pgt_device *pdev)
 		return true;
 	}
 
+	if (_is_valleyview(pdev->pdev->device)) {
+		pdev->gen_dev_type = XEN_IGD_VLV;
+		vgt_info("Detected Valleyview\n");
+		return true;
+	}
+
 	if (_is_haswell(pdev->pdev->device)) {
 		pdev->gen_dev_type = XEN_IGD_HSW;
 		vgt_info("Detected Haswell\n");
@@ -443,13 +462,18 @@ static bool vgt_initialize_pgt_device(struct pci_dev *dev, struct pgt_device *pd
 	if (!vgt_set_device_type(pdev))
 		return false;
 
-	if (!IS_HSW(pdev)) {
-		vgt_err("Unsupported gen_dev_type(%s)!\n",
-			IS_IVB(pdev) ?
-			"IVB" : "SNB(or unknown GEN types)");
+	if (bypass) {
+		vgt_err("Force unsupported\n");
 		return false;
 	}
 
+	if (IS_IVB(pdev) || IS_HSW(pdev) || IS_VLV(pdev)) {
+		vgt_dbg(VGT_DBG_GENERIC, "Let's go with Gen7+ :-)\n");
+	}
+	else {
+		vgt_err("Unsupported device id (0x%x) !\n", pdev->pdev->device);
+		return false;
+	}
 	/* check PPGTT enabling. */
 	if (IS_IVB(pdev) || IS_HSW(pdev))
 		pdev->enable_ppgtt = 1;
@@ -532,6 +556,8 @@ static bool vgt_initialize_pgt_device(struct pci_dev *dev, struct pgt_device *pd
 		vgt_ring_init(pdev, i);
 
 	perf_pgt = pdev;
+	vgt_dbg(VGT_DBG_MEM, "enable_ppgtt=%d max_engines=%d vgt_dbg_mask=0x%x\n",  pdev->enable_ppgtt, pdev->max_engines, vgt_debug);
+
 	return true;
 }
 
@@ -559,7 +585,7 @@ int vgt_initialize(struct pci_dev *dev)
 
 	mutex_init(&pdev->hpd_work.hpd_mutex);
 	INIT_WORK(&pdev->hpd_work.work, vgt_hotplug_udev_notify_func);
-	
+
 	/* create debugfs interface */
 	if (!vgt_init_debugfs(pdev)) {
 		printk("vGT:failed to create debugfs\n");
@@ -799,22 +825,37 @@ int vgt_resume(struct pci_dev *pdev)
 
 	spin_lock(&pgt->lock);
 
-	recalculate_and_update_imr(pgt, _REG_DEIMR);
-	recalculate_and_update_imr(pgt, _REG_GTIMR);
-	recalculate_and_update_imr(pgt, _REG_PMIMR);
-	recalculate_and_update_imr(pgt, _REG_SDEIMR);
+	if(IS_VLV(pgt)) {
+		recalculate_and_update_imr(pgt, _REG_VLV_IMR);
+		recalculate_and_update_imr(pgt, _REG_GTIMR);
+		recalculate_and_update_imr(pgt, _REG_PMIMR);
+		/* ALANPREVIN - havent handled hotplug port imrs */
+
+		recalculate_and_update_imr(pgt, _REG_RCS_IMR);
+		recalculate_and_update_imr(pgt, _REG_BCS_IMR);
+		recalculate_and_update_imr(pgt, _REG_VCS_IMR);
 
-	recalculate_and_update_imr(pgt, _REG_RCS_IMR);
-	recalculate_and_update_imr(pgt, _REG_BCS_IMR);
-	recalculate_and_update_imr(pgt, _REG_VCS_IMR);
+		recalculate_and_update_ier(pgt, _REG_GTIER);
+		recalculate_and_update_ier(pgt, _REG_PMIER);
+		/* ALANPREVIN - havent handled hotplug port iers */
 
-	if (IS_HSW(pgt))
-		recalculate_and_update_imr(pgt, _REG_VECS_IMR);
+	} else if (IS_SNB(pgt) || IS_IVB(pgt) || IS_HSW(pgt)) {
+		recalculate_and_update_imr(pgt, _REG_DEIMR);
+		recalculate_and_update_imr(pgt, _REG_GTIMR);
+		recalculate_and_update_imr(pgt, _REG_PMIMR);
+		recalculate_and_update_imr(pgt, _REG_SDEIMR);
 
-	recalculate_and_update_ier(pgt, _REG_GTIER);
-	recalculate_and_update_ier(pgt, _REG_PMIER);
-	recalculate_and_update_ier(pgt, _REG_SDEIER);
+		recalculate_and_update_imr(pgt, _REG_RCS_IMR);
+		recalculate_and_update_imr(pgt, _REG_BCS_IMR);
+		recalculate_and_update_imr(pgt, _REG_VCS_IMR);
 
+		if (IS_HSW(pgt))
+			recalculate_and_update_imr(pgt, _REG_VECS_IMR);
+
+		recalculate_and_update_ier(pgt, _REG_GTIER);
+		recalculate_and_update_ier(pgt, _REG_PMIER);
+		recalculate_and_update_ier(pgt, _REG_SDEIER);
+	}
 	spin_unlock(&pgt->lock);
 
 	return 0;
@@ -825,7 +866,7 @@ static void do_device_reset(struct pgt_device *pdev)
 {
 	struct drm_device *drm_dev = pci_get_drvdata(pdev->pdev);
 	vgt_reg_t head, tail, start, ctl;
-	vgt_reg_t ier, imr, iir, isr;
+	vgt_reg_t ier=0, imr=0, iir=0, isr=0, gtlcmir=0;
 	int i;
 
 	vgt_info("Request DOM0 to reset device.\n");
@@ -861,13 +902,22 @@ static void do_device_reset(struct pgt_device *pdev)
 				i, head, tail, start, ctl);
 	}
 
-	ier = VGT_MMIO_READ(pdev, _REG_DEIER);
-	iir = VGT_MMIO_READ(pdev, _REG_DEIIR);
-	imr = VGT_MMIO_READ(pdev, _REG_DEIMR);
-	isr = VGT_MMIO_READ(pdev, _REG_DEISR);
+	if(IS_VLV(pdev)) {
+		gtlcmir = VGT_MMIO_READ(pdev, _REG_VLV_GTLC_MIR);
+		ier = VGT_MMIO_READ(pdev, _REG_VLV_IER);
+		iir = VGT_MMIO_READ(pdev, _REG_VLV_IIR);
+		imr = VGT_MMIO_READ(pdev, _REG_VLV_IMR);
+		isr = VGT_MMIO_READ(pdev, _REG_VLV_ISR);
+	} else if (IS_SNB(pdev) || IS_IVB(pdev) ||IS_HSW(pdev)) {
+		gtlcmir = 0;
+		ier = VGT_MMIO_READ(pdev, _REG_DEIER);
+		iir = VGT_MMIO_READ(pdev, _REG_DEIIR);
+		imr = VGT_MMIO_READ(pdev, _REG_DEIMR);
+		isr = VGT_MMIO_READ(pdev, _REG_DEISR);
+	}
 
-	vgt_info("DE: ier: %x iir: %x imr: %x isr: %x.\n",
-			ier, iir, imr, isr);
+	vgt_info("DE: ier: %x iir: %x imr: %x isr: %x gtlcmir: %x.\n",
+			ier, iir, imr, isr, gtlcmir);
 
 	vgt_info("Finish.\n");
 
@@ -908,7 +958,7 @@ int vgt_reset_device(struct pgt_device *pdev)
 {
 	struct vgt_device *vgt;
 	struct list_head *pos, *n;
-	unsigned long ier;
+	unsigned long ier=0;
 	unsigned long flags;
 	int i;
 
@@ -957,8 +1007,15 @@ int vgt_reset_device(struct pgt_device *pdev)
 
 	vgt_get_irq_lock(pdev, flags);
 
-	VGT_MMIO_WRITE(pdev, _REG_DEIER,
-			VGT_MMIO_READ(pdev, _REG_DEIER) & ~_REGBIT_MASTER_INTERRUPT);
+	if(IS_VLV(pdev)) {
+		VGT_MMIO_WRITE(pdev, _REG_VLV_GTLC_MIR,
+				VGT_MMIO_READ(pdev, _REG_VLV_GTLC_MIR) & ~_REGBIT_MASTER_INTERRUPT);
+		VGT_MMIO_WRITE(pdev, _REG_VLV_IER,
+				VGT_MMIO_READ(pdev, _REG_VLV_IER) & ~VLV_REGBIT_DISPMASTER_INTERRUPT);
+	} else if (IS_SNB(pdev) || IS_IVB(pdev) || IS_HSW(pdev)){
+		VGT_MMIO_WRITE(pdev, _REG_DEIER,
+				VGT_MMIO_READ(pdev, _REG_DEIER) & ~_REGBIT_MASTER_INTERRUPT);
+	}
 
 	vgt_put_irq_lock(pdev, flags);
 
@@ -973,8 +1030,16 @@ int vgt_reset_device(struct pgt_device *pdev)
 	spin_lock_irqsave(&pdev->lock, flags);
 	vgt_get_irq_lock(pdev, flags);
 
-	ier = vgt_recalculate_ier(pdev, _REG_DEIER);
-	VGT_MMIO_WRITE(pdev, _REG_DEIER, ier);
+
+	if(IS_VLV(pdev)) {
+		ier = vgt_recalculate_ier(pdev, _REG_VLV_GTLC_MIR);
+		VGT_MMIO_WRITE(pdev, _REG_VLV_GTLC_MIR, ier);
+		ier = vgt_recalculate_ier(pdev, _REG_VLV_IER);
+		VGT_MMIO_WRITE(pdev, _REG_VLV_IER, ier);
+	} else if (IS_SNB(pdev) || IS_IVB(pdev) || IS_HSW(pdev)) {
+		ier = vgt_recalculate_ier(pdev, _REG_DEIER);
+		VGT_MMIO_WRITE(pdev, _REG_DEIER, ier);
+	}
 
 	vgt_put_irq_lock(pdev, flags);
 
diff --git a/drivers/xen/vgt/vgt.h b/drivers/xen/vgt/vgt.h
index 8edfe31..44a0324 100644
--- a/drivers/xen/vgt/vgt.h
+++ b/drivers/xen/vgt/vgt.h
@@ -67,7 +67,7 @@ extern bool hvm_boot_foreground;
 extern bool vgt_primary;
 extern bool vgt_track_nest;
 extern bool vgt_delay_nest;
-extern int   vgt_debug;
+extern int  vgt_debug;
 extern bool vgt_enabled;
 extern bool fastpath_dpy_switch;
 extern bool shadow_tail_based_qos;
@@ -140,9 +140,12 @@ enum vgt_event_type {
 	SPRITE_A_FLIP_DONE,	/* This is an active high pulse when a sprite plane A flip is done */
 	SPRITE_B_FLIP_DONE,	/* This is an active high pulse when a sprite plane B flip is done */
 	SPRITE_C_FLIP_DONE,	/* This is an active high pulse when a sprite plane C flip is done */
+	SPRITE_D_FLIP_DONE,	/* This is an active high pulse when a sprite plane C flip is done */
 
+	DPST_MIXED_A,   // This is an active high pulse on DPST phase in or Historgram event on PipeA
+	DPST_MIXED_B,   // This is an active high pulse on DPST phase in or Historgram event on PipeB
 	DPST_PHASE_IN,	// This is an active high pulse on the DPST phase in event
-	DPST_HISTOGRAM,	// This is an active high pulse on the AUX A done event.
+	DPST_HISTOGRAM,	// This is an active high pulse on the Histogram event.
 	GSE,
 	DP_A_HOTPLUG,
 	AUX_CHANNEL_A,	// This is an active high pulse on the AUX A done event.
@@ -197,25 +200,49 @@ enum transcoder {
 	TRANSCODER_EDP = 0xF,
 };
 
-#define vgt_info(fmt, s...)	\
-	do { printk(KERN_INFO "vGT info:(%s:%d) " fmt, __FUNCTION__, __LINE__, ##s); } while (0)
-
-#define vgt_warn(fmt, s...)	\
-	do { printk(KERN_WARNING "vGT warning:(%s:%d) " fmt, __FUNCTION__, __LINE__, ##s); } while (0)
-
-#define vgt_err(fmt, s...)	\
-	do { printk(KERN_ERR "vGT error:(%s:%d) " fmt, __FUNCTION__, __LINE__, ##s); } while (0)
-
-#define vgt_dbg(component, fmt, s...)	\
-	do { if (vgt_debug & component) printk(KERN_DEBUG "vGT debug:(%s:%d) " fmt, __FUNCTION__, __LINE__, ##s); } while (0)
-
+/* When enabling debug messages for certain types of IRQs across DOM and VMn,
+ * its preferrable to throttle down the noise a little else the entire system
+ * becomes excruciatingly slow and the debug messages generated are too noisy
+ * Thus, we are using these knobs to control the threshold count for when an
+ * actual debug message is printed after some number of IRQ occurences.
+ */
+#define DBG_IRQ_DISP_THRESHOLD  120 /* once every 2 secs for 60Hz monitor */
+#define DBG_IRQ_GT_THRESHOLD    2400
+
+#if 1 // ORIGIGNAL MACROs
+	#define vgt_info(fmt, s...)	\
+		do { printk(KERN_INFO "vGT info:(%s:%d) " fmt, __FUNCTION__, __LINE__, ##s); } while (0)
+
+	#define vgt_warn(fmt, s...)	\
+		do { printk(KERN_WARNING "vGT warning:(%s:%d) " fmt, __FUNCTION__, __LINE__, ##s); } while (0)
+
+	#define vgt_err(fmt, s...)	\
+		do { printk(KERN_ERR "vGT error:(%s:%d) " fmt, __FUNCTION__, __LINE__, ##s); } while (0)
+
+	#define vgt_dbg(component, fmt, s...)	\
+		do { if (vgt_debug & component) printk(KERN_DEBUG "vGT debug:(%s:%d) " fmt, __FUNCTION__, __LINE__, ##s); } while (0)
+#else // VERY QUIET AND COMPILED OUT FOR PERFORMANCE 
+		#define NO_DEBUGS
+		#define vgt_info(fmt, s...)	\
+			do { } while(0)
+		#define vgt_warn(fmt, s...)	\
+			do { } while(0)
+		#define vgt_err(fmt, s...)	\
+			do { printk(KERN_ERR "vGT_E:(%s:%s:%d) " fmt, __FUNCTION__,__FILE__, __LINE__, ##s); } while (0)
+		#define vgt_dbg(component, fmt, s...)	\
+			do { } while(0)
+#endif
 #define VGT_DBG_GENERIC   (1<<0)
-#define VGT_DBG_DPY   (1<<1)
-#define VGT_DBG_MEM   (1<<2)
-#define VGT_DBG_RENDER   (1<<3)
-#define VGT_DBG_CMD   (1<<4)
-#define VGT_DBG_IRQ   (1<<5)
-#define VGT_DBG_ALL     (0xffff)
+#define VGT_DBG_DPY       (1<<1)
+#define VGT_DBG_MEM       (1<<2)
+#define VGT_DBG_RENDER    (1<<3)
+#define VGT_DBG_CMD       (1<<4)
+#define VGT_DBG_IRQ       (1<<5)
+#define VGT_DBG_CFGSPACE  (1<<6)
+#define VGT_DBG_MMIOSPACE (1<<7)
+#define VGT_DBG_EDID      (1<<8)
+#define VGT_DBG_SCHED     (1<<9)
+#define VGT_DBG_ALL       (0xffff)
 
 /*
  * Define registers of a ring buffer per hardware register layout.
@@ -991,13 +1018,27 @@ struct pgt_device {
 	 (d->next_sched_vgt != current_render_owner(pdev)))
 #define vgt_ctx_check(d)		(d->ctx_check)
 #define vgt_ctx_switch(d)		(d->ctx_switch)
-#define vgt_has_pipe_enabled(vgt, pipe)						\
-		(vgt && ((pipe) >= PIPE_A) && ((pipe) < I915_MAX_PIPES) &&	\
-		(__vreg((vgt), VGT_PIPECONF(pipe)) & _REGBIT_PIPE_ENABLE))
-#define pdev_has_pipe_enabled(pdev, pipe)					\
-		(pdev && ((pipe) >= PIPE_A) && ((pipe) < I915_MAX_PIPES) &&	\
-		(__vreg(current_display_owner(pdev),				\
-			VGT_PIPECONF(pipe)) & _REGBIT_PIPE_ENABLE))
+#define vgt_has_pipe_enabled(vgt, pipe)                                     \
+	( (vgt) && (                                                            \
+		(                                                                   \
+			(IS_VLV(vgt->pdev)) &&                                          \
+			(((pipe) >= PIPE_A) && ((pipe) < I915_MAX_PIPES) &&	            \
+			(__vreg((vgt), VGT_VLV_PIPECONF(pipe)) & _REGBIT_PIPE_ENABLE))  \
+		) || (                                                              \
+			(((pipe) >= PIPE_A) && ((pipe) < I915_MAX_PIPES) &&	            \
+			(__vreg((vgt), VGT_PIPECONF(pipe)) & _REGBIT_PIPE_ENABLE))      \
+		) ) )
+
+#define pdev_has_pipe_enabled(pdev, pipe)					                \
+	( (pdev) && (                                                           \
+		(                                                                   \
+			(IS_VLV(pdev)) &&                                               \
+			((pipe) >= PIPE_A) && ((pipe) < I915_MAX_PIPES) &&              \
+			(__vreg(current_display_owner(pdev), VGT_VLV_PIPECONF(pipe)) & _REGBIT_PIPE_ENABLE) \
+		) || (                                                              \
+			((pipe) >= PIPE_A) && ((pipe) < I915_MAX_PIPES) &&              \
+			(__vreg(current_display_owner(pdev), VGT_PIPECONF(pipe)) & _REGBIT_PIPE_ENABLE) \
+		) ) )
 
 extern int prepare_for_display_switch(struct pgt_device *pdev);
 extern void do_vgt_fast_display_switch(struct pgt_device *pdev);
@@ -1210,15 +1251,20 @@ static inline bool reg_hw_access(struct vgt_device *vgt, unsigned int reg)
 #define IS_SNB(pdev)	((pdev)->gen_dev_type == XEN_IGD_SNB)
 #define IS_IVB(pdev)	((pdev)->gen_dev_type == XEN_IGD_IVB)
 #define IS_HSW(pdev)	((pdev)->gen_dev_type == XEN_IGD_HSW)
+#define IS_VLV(pdev)	((pdev)->gen_dev_type == XEN_IGD_VLV)
 
 #define D_SNB	(1 << 0)
 #define D_IVB	(1 << 1)
 #define D_HSW	(1 << 2)
-#define D_GEN7PLUS	(D_IVB | D_HSW)
+#define D_VLV	(1 << 3)
+#define D_GEN7	        (D_IVB | D_VLV)
+#define D_GEN7PLUS	(D_IVB | D_HSW | D_VLV)
+#define D_GEN7PLUSCORE (D_IVB | D_HSW)
 #define D_GEN75PLUS	(D_HSW)
 #define D_HSW_PLUS	(D_HSW)
-#define D_IVB_PLUS	(D_IVB | D_HSW)
-#define D_ALL	(D_SNB | D_IVB | D_HSW)
+#define D_IVB_PLUS	(D_IVB | D_HSW | D_VLV)
+#define D_ALLCORE	(D_SNB | D_IVB | D_HSW)
+#define D_ALL	 	(D_SNB | D_IVB | D_HSW | D_VLV)
 
 typedef struct {
 	u32			reg;
@@ -1259,6 +1305,8 @@ static inline unsigned int vgt_gen_dev_type(struct pgt_device *pdev)
 		return D_IVB;
 	if (IS_HSW(pdev))
 		return D_HSW;
+	if (IS_VLV(pdev))
+		return D_VLV;
 	WARN_ONCE(1, KERN_ERR "vGT: unknown GEN type!\n");
 	return 0;
 }
@@ -1285,30 +1333,68 @@ static inline enum vgt_port vgt_get_port(struct vgt_device *vgt, struct gt_port
 static inline enum vgt_pipe vgt_get_pipe_from_port(struct vgt_device *vgt,
 						enum vgt_port port)
 {
-	enum vgt_pipe pipe;
+	enum vgt_pipe pipe=I915_MAX_PIPES;
+	vgt_reg_t ddi_func_ctl;
 
 	if (port == I915_MAX_PORTS)
 		return I915_MAX_PIPES;
 
 	ASSERT (port != PORT_A);
 
-	for (pipe = PIPE_A; pipe < I915_MAX_PIPES; ++ pipe) {
-		vgt_reg_t ddi_func_ctl;
-		vgt_reg_t ddi_port_info;
-
-		ddi_func_ctl  = __vreg(vgt, _VGT_TRANS_DDI_FUNC_CTL(pipe));
-
-		if (!(ddi_func_ctl & _REGBIT_TRANS_DDI_FUNC_ENABLE))
-			continue;
-
-		ddi_port_info = (ddi_func_ctl & _REGBIT_TRANS_DDI_PORT_MASK) >>
-					_TRANS_DDI_PORT_SHIFT;
-		if (ddi_port_info == port) {
-			// pipe has the port setting same as input
-			break;
+	if(IS_VLV(vgt->pdev)){
+		switch(port) {
+			case PORT_E: /* port_to_port_type says this is CRT ??? */
+				ddi_func_ctl = __vreg(vgt, _REG_VLV_PCH_ADPA);
+				if(ddi_func_ctl & _REGBIT_TRANS_DDI_FUNC_ENABLE) /*bit31 same as ADPA */ {
+					if(ddi_func_ctl & (1<<30)){
+						pipe = PIPE_B;
+					} else {
+						pipe = PIPE_A;
+					}
+				}
+				break;
+			case PORT_B:
+			case PORT_C:
+				/* ALANPREVIN - Currently not handling DP ports for VLV */
+				if(port==PORT_B) {
+					ddi_func_ctl = __vreg(vgt, _REG_VLV_HDMI_B_CTL);
+				} else {
+					ddi_func_ctl = __vreg(vgt, _REG_VLV_HDMI_C_CTL);
+				}
+				if(ddi_func_ctl & _REGBIT_TRANS_DDI_FUNC_ENABLE) /*bit31 same as HDMI CTL*/ {
+					if(ddi_func_ctl & (1<<30)){
+						pipe = PIPE_B;
+					} else {
+						pipe = PIPE_A;
+					}
+				} else {
+
+				}
+				break;
+			default:
+				/*
+				These dont exist in VLV
+				case PORT_A:
+				case PORT_D:
+				*/
+				break;
+		}
+	} else {
+		for (pipe = PIPE_A; pipe < I915_MAX_PIPES; ++ pipe) {
+			vgt_reg_t ddi_port_info;
+			ddi_func_ctl  = __vreg(vgt, _VGT_TRANS_DDI_FUNC_CTL(pipe));
+
+			if (!(ddi_func_ctl & _REGBIT_TRANS_DDI_FUNC_ENABLE))
+				continue;
+
+			ddi_port_info = (ddi_func_ctl & _REGBIT_TRANS_DDI_PORT_MASK) >>
+						_TRANS_DDI_PORT_SHIFT;
+			if (ddi_port_info == port) {
+				// pipe has the port setting same as input
+				break;
+			}
 		}
 	}
-
 	return pipe;
 }
 
@@ -2052,6 +2138,11 @@ struct vgt_irq_host_state {
 #define regbase_to_iir(base)	(base + 0x8)
 #define regbase_to_ier(base)	(base + 0xC)
 
+#define vlv_regbase_to_isr(base)	(base)
+#define vlv_regbase_to_imr(base)	(base - 0x4)
+#define vlv_regbase_to_iir(base)	(base - 0x8)
+#define vlv_regbase_to_ier(base)	(base - 0xC)
+
 static inline void vgt_clear_all_vreg_bit(struct pgt_device *pdev, unsigned int value, unsigned int offset)
 {
 	struct vgt_device *vgt;
@@ -2166,6 +2257,11 @@ u32 vgt_recalculate_mask_bits(struct pgt_device *pdev, unsigned int reg);
 void recalculate_and_update_imr(struct pgt_device *pdev, vgt_reg_t reg);
 void recalculate_and_update_ier(struct pgt_device *pdev, vgt_reg_t reg);
 
+bool vgt_reg_vlv_pipe_iser_handler_write(struct vgt_device *vgt,
+	unsigned int reg, void *p_data, unsigned int bytes);
+bool vgt_reg_vlv_pipe_iser_handler_read(struct vgt_device *vgt,
+	unsigned int reg, void *p_data, unsigned int bytes);
+
 bool vgt_reg_imr_handler(struct vgt_device *vgt,
 	unsigned int reg, void *p_data, unsigned int bytes);
 bool vgt_reg_ier_handler(struct vgt_device *vgt,
@@ -2365,6 +2461,24 @@ void vgt_destroy_mmio_dev(struct vgt_device *vgt);
 	ret__;								\
 })
 
+#define wait_for_atomic_tightmicrosec(COND, MS) ({		\
+	unsigned long tight_cnt = 5000;				\
+	unsigned long cnt = MS*1000;				\
+	int ret__ = 0;							\
+	while (!(COND)) {						\
+		if(tight_cnt) {						\
+			--tight_cnt;					\
+			continue;						\
+		}									\
+		if (!(--cnt)) {						\
+			ret__ = -ETIMEDOUT;				\
+			break;						\
+		}							\
+		udelay(1);						\
+	}								\
+	ret__;								\
+})
+
 extern reg_attr_t vgt_base_reg_info[];
 extern reg_list_t vgt_sticky_regs[];
 extern reg_addr_sz_t vgt_reg_addr_sz[];
@@ -2389,7 +2503,7 @@ void free_gtt(struct pgt_device *pdev);
 void vgt_clear_gtt(struct vgt_device *vgt);
 void vgt_save_gtt_and_fence(struct pgt_device *pdev);
 void vgt_restore_gtt_and_fence(struct pgt_device *pdev);
-uint64_t vgt_get_gtt_size(struct pci_bus *bus);
+uint64_t vgt_get_gtt_size(struct pgt_device *pdev, struct pci_bus *bus);
 uint32_t pci_bar_size(struct pgt_device *pdev, unsigned int bar_off);
 int vgt_get_hvm_max_gpfn(int vm_id);
 int vgt_hvm_vmem_init(struct vgt_device *vgt);
diff --git a/include/xen/interface/platform.h b/include/xen/interface/platform.h
index 5e3312c..4d90e2f 100644
--- a/include/xen/interface/platform.h
+++ b/include/xen/interface/platform.h
@@ -357,7 +357,8 @@ DEFINE_GUEST_HANDLE_STRUCT(xenpf_core_parking);
 #define XEN_IGD_SNB     1
 #define XEN_IGD_IVB     2
 #define XEN_IGD_HSW     3
-#define XEN_IGD_MAX     3   /* the max GEN dev type supported */
+#define XEN_IGD_VLV     4
+#define XEN_IGD_MAX     4   /* the max GEN dev type supported */
 struct xenpf_vgt_info {
 	unsigned int gen_dev_bdf;
 	unsigned int gen_dev_type;
